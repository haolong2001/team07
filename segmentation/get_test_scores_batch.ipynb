{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b1fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import datetime\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918b3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WoundData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Read image and mask\n",
    "        im = cv2.imread(self.data[idx][0],-1)\n",
    "        mask = cv2.imread(self.data[idx][1],0)\n",
    "\n",
    "        # From np.array (HxWxC) to torch.tensor (CxHxW). From [0,255] to [0,1]\n",
    "        im = torch.from_numpy(np.float32(im/255).transpose(2,0,1))\n",
    "        mask = torch.from_numpy(np.float32(mask/255)).unsqueeze(0)\n",
    "        \n",
    "        return im, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913b43d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    }
   ],
   "source": [
    "test_folder_imgs = np.array(glob.glob(os.path.join(\"test128\", \"images\", \"*\")))\n",
    "test_folder_labs = np.array(glob.glob(os.path.join(\"test128\", \"labels\", \"*\")))\n",
    "\n",
    "print(len(test_folder_imgs))\n",
    "test_paths = []\n",
    "for i in range(len(test_folder_imgs)):\n",
    "    test_paths.append([test_folder_imgs[i], test_folder_labs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5162af32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "manytrainruns_p2psmb128_04122022-003232\\ganwoundmodel.pt\n",
      "0.791410297424617 0.8572735407240317 0.7756329450890073 0.6678306155934379\n",
      "manytrainruns_p2psmb128_04122022-003528\\ganwoundmodel.pt\n",
      "0.869752901132766 0.8215912124658615 0.8095689422405379 0.7104273787248317\n",
      "manytrainruns_p2psmb128_04122022-004143\\ganwoundmodel.pt\n",
      "0.8068472331998916 0.8768362960616659 0.7998987436118085 0.7009984317507709\n",
      "manytrainruns_p2psmb128_04122022-004612\\ganwoundmodel.pt\n",
      "0.8109040252492988 0.8519759405974515 0.7873040074896307 0.6836068000379965\n",
      "manytrainruns_p2psmb128_04122022-004903\\ganwoundmodel.pt\n",
      "0.80568725864945 0.8767315835838536 0.7993600536250811 0.6976926113246986\n",
      "manytrainruns_p2psmb128_04122022-005322\\ganwoundmodel.pt\n",
      "0.8485426000167067 0.8405931367492464 0.8098725862427693 0.7134937713911261\n",
      "manytrainruns_p2psmb128_04122022-010014\\ganwoundmodel.pt\n",
      "0.8523678541427198 0.8528296612185314 0.8180458265204578 0.7264470533343101\n",
      "manytrainruns_p2psmb128_04122022-010723\\ganwoundmodel.pt\n",
      "0.7789739213629361 0.8444608001549284 0.762347715262782 0.654661862635642\n",
      "manytrainruns_p2psmb128_04122022-011013\\ganwoundmodel.pt\n",
      "0.8234255110486605 0.867456079738914 0.8078209024638345 0.709082309973717\n",
      "manytrainruns_p2psmb128_04122022-011514\\ganwoundmodel.pt\n",
      "0.8384930226286177 0.8251706683902522 0.792999569131714 0.688875112715954\n",
      "manytrainruns_p2psmb128_04122022-011958\\ganwoundmodel.pt\n",
      "0.8746798907946592 0.809828080863512 0.8081210347961686 0.7079429667672792\n",
      "manytrainruns_p2psmb128_04122022-012357\\ganwoundmodel.pt\n",
      "0.8256058884418774 0.8583531851959335 0.8029672623979932 0.704195711563042\n",
      "manytrainruns_p2psmb128_04122022-012622\\ganwoundmodel.pt\n",
      "0.83403110925639 0.8652443787949503 0.812863992015812 0.7181742354366369\n",
      "manytrainruns_p2psmb128_04122022-012943\\ganwoundmodel.pt\n",
      "0.8580253975802761 0.8210415536534689 0.8013459982071451 0.7012253684859275\n",
      "manytrainruns_p2psmb128_04122022-013326\\ganwoundmodel.pt\n",
      "0.7685498651937444 0.897387297307641 0.7864053451669121 0.6824161140444222\n",
      "manytrainruns_p2psmb128_04122022-013747\\ganwoundmodel.pt\n",
      "0.8524738902577208 0.8385857715140498 0.8097467840316332 0.7136638864932663\n",
      "manytrainruns_p2psmb128_04122022-014412\\ganwoundmodel.pt\n",
      "0.8294078403827831 0.8567619433792025 0.8029494725200705 0.703574182482434\n",
      "manytrainruns_p2psmb128_04122022-014719\\ganwoundmodel.pt\n",
      "0.8508622484266114 0.8317660977315517 0.8033268180358832 0.7038950576499029\n",
      "manytrainruns_p2psmb128_04122022-015218\\ganwoundmodel.pt\n",
      "0.8970122004583798 0.7859934783810963 0.8118548528753202 0.7089041859693682\n",
      "manytrainruns_p2psmb128_04122022-020138\\ganwoundmodel.pt\n",
      "0.8615542005821637 0.8446474370117764 0.8196336957613315 0.724412427397379\n",
      "manytrainruns_p2psmb128_04122022-020532\\ganwoundmodel.pt\n",
      "0.8360923341146232 0.8627721943615444 0.8135786641610829 0.7155899857400033\n",
      "manytrainruns_p2psmb128_04122022-020544\\ganwoundmodel.pt\n",
      "0.8278843987616528 0.8644542380076319 0.8092824818872595 0.7117219296635272\n",
      "manytrainruns_p2psmb128_04122022-021023\\ganwoundmodel.pt\n",
      "0.831087245542386 0.8438256396013142 0.796230993570128 0.6954913952432827\n",
      "manytrainruns_p2psmb128_04122022-021116\\ganwoundmodel.pt\n",
      "0.8441472472796475 0.8672229550300272 0.8213415027619649 0.7274157867413105\n",
      "manytrainruns_p2psmb128_04122022-021440\\ganwoundmodel.pt\n",
      "0.8397074393552598 0.8492812598184133 0.8081773772625089 0.7123570411465997\n",
      "manytrainruns_p2psmb128_04122022-021806\\ganwoundmodel.pt\n",
      "0.8143317988459571 0.8650608094817581 0.8005094836683377 0.7036551348352516\n",
      "manytrainruns_p2psmb128_04122022-022139\\ganwoundmodel.pt\n",
      "0.8158980104332261 0.8653147501533431 0.7974472821603911 0.6993250947816829\n",
      "manytrainruns_p2psmb128_04122022-022413\\ganwoundmodel.pt\n",
      "0.8080030476823732 0.8630233798941154 0.7921176949290151 0.6898374437060565\n",
      "manytrainruns_p2psmb128_04122022-022526\\ganwoundmodel.pt\n",
      "0.8496428341947156 0.8586907610595018 0.820580719614581 0.7265459122890794\n",
      "manytrainruns_p2psmb128_04122022-022733\\ganwoundmodel.pt\n",
      "0.8448507005193591 0.8559224959702523 0.8146122115821018 0.7195300008816377\n",
      "manytrainruns_p2psmb128_04122022-023342\\ganwoundmodel.pt\n",
      "0.7805555772383646 0.8715804992376994 0.7801657854027723 0.6735049803669361\n",
      "manytrainruns_p2psmb128_04122022-023536\\ganwoundmodel.pt\n",
      "0.8681886253120795 0.8168654746258888 0.8063799297365928 0.7081127543475081\n",
      "manytrainruns_p2psmb128_04122022-023957\\ganwoundmodel.pt\n",
      "0.8661668548045529 0.8327522368346172 0.8147260681387793 0.7184639422652086\n",
      "manytrainruns_p2psmb128_04122022-024331\\ganwoundmodel.pt\n",
      "0.847110555417913 0.867580051184852 0.8232662038663238 0.7307908849424081\n",
      "manytrainruns_p2psmb128_04122022-024845\\ganwoundmodel.pt\n",
      "0.8463829134840014 0.840045953531069 0.8059775165805922 0.7087970434348855\n"
     ]
    }
   ],
   "source": [
    "models = glob.glob(os.path.join(\"manytrainruns_p2psmb128_04*\", \"*.pt\"))\n",
    "print(len(models))\n",
    "\n",
    "results = []\n",
    "\n",
    "for mi, model_path in enumerate(models):\n",
    "    \n",
    "    with open(os.path.join(os.path.split(model_path)[0], \"architecture.txt\"), \"r\") as f:\n",
    "        txt = f.read().split('\\n')\n",
    "        ENCODER = txt[0]\n",
    "        ENCODER_WEIGHTS = txt[1]\n",
    "        \n",
    "    CLASSES = ['vein']\n",
    "    DEVICE = 'cuda'\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=ENCODER, \n",
    "        encoder_weights=ENCODER_WEIGHTS, \n",
    "        classes=len(CLASSES), \n",
    "        in_channels=3,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(DEVICE);\n",
    "    \n",
    "    test_ds = WoundData(test_paths)\n",
    "    test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    collated_pred, collated_mask = [], []\n",
    "    collated_img = []\n",
    "    for i, (sampi, sampm) in enumerate(test_dl):\n",
    "        sampo = torch.sigmoid(model(sampi.to(DEVICE)))\n",
    "        collated_pred.append(np.array(sampo.cpu().detach()).squeeze())\n",
    "        collated_mask.append(np.array(sampm.detach()).squeeze())\n",
    "        collated_img.append(np.array(sampi.cpu().detach().squeeze()).transpose(1,2,0))\n",
    "        \n",
    "    collated_pred = np.array(collated_pred)\n",
    "    collated_mask = np.array(collated_mask)\n",
    "    collated_img = np.array(collated_img)\n",
    "    collated_pred_bin = (collated_pred > 0.5).astype(int)\n",
    "    \n",
    "    prec = []\n",
    "    rec = []\n",
    "    dice = []\n",
    "    sizes = []\n",
    "    ious = []\n",
    "\n",
    "    for pred, mask, img in zip(collated_pred_bin, collated_mask, collated_img):\n",
    "        contours, hierarchy = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)    \n",
    "        tp = np.sum((pred + mask) == 2)\n",
    "        tn = np.sum((pred + mask) == 0)\n",
    "        fp = np.sum((pred - mask) > 0)\n",
    "        fn = np.sum((pred - mask) < 0)\n",
    "\n",
    "        prec.append(tp/ (tp + fp + 0.00001))\n",
    "        rec.append(tp/ (tp + fn + 0.00001))\n",
    "        dice.append(2*tp/ (2*tp + fn + fp))\n",
    "        ious.append(tp/(tp+fp+fn))\n",
    "        sizes.append(np.sqrt(np.sum(mask)))\n",
    " \n",
    "    print(model_path)\n",
    "    print(np.mean(prec), np.mean(rec), np.mean(dice), np.mean(ious))\n",
    "    results.append([np.mean(prec), np.mean(rec), np.mean(dice), np.mean(ious)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72cbb030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "0.803058632172808 0.8691586050281312 0.7891033815743561 0.6871601246553296\n",
      "0.8037010082464845 0.8792541748676711 0.797145534242938 0.6965248315636553\n",
      "0.7556190811741358 0.8960106587987426 0.7737100131461148 0.6668245292194606\n",
      "0.7955719997945979 0.8607344487226245 0.7801414246245107 0.675082054953318\n",
      "0.7779693780142364 0.8792155272725375 0.7779064388808891 0.6715309487512774\n",
      "0.8135970575710284 0.8621475066986389 0.7950767283629437 0.6938575183540335\n",
      "0.8143727918804015 0.8677254487537023 0.7968452605862072 0.697426483241024\n",
      "0.8184265391524692 0.8745018668876844 0.8054869419003916 0.7089657502788287\n",
      "0.8441757195884152 0.8529949825938222 0.8100382387130065 0.7136231402703227\n",
      "0.8318487854690507 0.8600796222378136 0.8057103539731129 0.707634004164182\n",
      "0.8240547080108546 0.8703924689228796 0.807629743458211 0.7090998576645257\n",
      "0.7946955726093131 0.8802416777243494 0.7916581580902818 0.6901948673629796\n",
      "0.8088424381213724 0.8565405520583524 0.7874491182056488 0.6865006324175019\n",
      "0.8084530766876441 0.8711505891589127 0.7954126494921026 0.6944191804610453\n",
      "0.7675885718648979 0.888267098691225 0.7763866981618424 0.6700602996475772\n",
      "0.8324515911460405 0.8675169765581349 0.8110719462086226 0.7138855805216399\n",
      "0.8212112522939075 0.8616255454755993 0.79846551277623 0.698731213400939\n",
      "0.79800261298868 0.8643219438870682 0.7845794581383663 0.6799013243156968\n",
      "0.8137484296433366 0.8619516462140593 0.7921552839272037 0.6904623785971199\n",
      "0.7932955986314639 0.8701937557945801 0.7825214188738364 0.6769000853234801\n",
      "0.769569573516441 0.859993894096145 0.7601027285937112 0.6489033130569604\n",
      "0.7768974994822319 0.8686034694706614 0.7702309228967031 0.6625513198882722\n",
      "0.8209001416004943 0.8639869188291144 0.7992113504190875 0.7007056996530353\n",
      "0.8308246799867245 0.8575589666708325 0.8033510172113679 0.7049416779305134\n",
      "0.7721302222647657 0.8822961976261585 0.776971923790898 0.6689745911974114\n"
     ]
    }
   ],
   "source": [
    "models2 = glob.glob(os.path.join(\"manytrainruns_train128_04*\", \"*.pt\"))\n",
    "print(len(models2))\n",
    "\n",
    "results2 = []\n",
    "\n",
    "for mi, model_path in enumerate(models2):\n",
    "    \n",
    "    with open(os.path.join(os.path.split(model_path)[0], \"architecture.txt\"), \"r\") as f:\n",
    "        txt = f.read().split('\\n')\n",
    "        ENCODER = txt[0]\n",
    "        ENCODER_WEIGHTS = txt[1]\n",
    "        \n",
    "    CLASSES = ['vein']\n",
    "    DEVICE = 'cuda'\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=ENCODER, \n",
    "        encoder_weights=ENCODER_WEIGHTS, \n",
    "        classes=len(CLASSES), \n",
    "        in_channels=3,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(DEVICE);\n",
    "    \n",
    "    test_ds = WoundData(test_paths)\n",
    "    test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    collated_pred, collated_mask = [], []\n",
    "    collated_img = []\n",
    "    for i, (sampi, sampm) in enumerate(test_dl):\n",
    "        sampo = torch.sigmoid(model(sampi.to(DEVICE)))\n",
    "        collated_pred.append(np.array(sampo.cpu().detach()).squeeze())\n",
    "        collated_mask.append(np.array(sampm.detach()).squeeze())\n",
    "        collated_img.append(np.array(sampi.cpu().detach().squeeze()).transpose(1,2,0))\n",
    "        \n",
    "    collated_pred = np.array(collated_pred)\n",
    "    collated_mask = np.array(collated_mask)\n",
    "    collated_img = np.array(collated_img)\n",
    "    collated_pred_bin = (collated_pred > 0.5).astype(int)\n",
    "    \n",
    "    prec = []\n",
    "    rec = []\n",
    "    dice = []\n",
    "    sizes = []\n",
    "    ious = []\n",
    "\n",
    "    for pred, mask, img in zip(collated_pred_bin, collated_mask, collated_img):\n",
    "        contours, hierarchy = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)    \n",
    "        tp = np.sum((pred + mask) == 2)\n",
    "        tn = np.sum((pred + mask) == 0)\n",
    "        fp = np.sum((pred - mask) > 0)\n",
    "        fn = np.sum((pred - mask) < 0)\n",
    "\n",
    "        prec.append(tp/ (tp + fp + 0.00001))\n",
    "        rec.append(tp/ (tp + fn + 0.00001))\n",
    "        dice.append(2*tp/ (2*tp + fn + fp))\n",
    "        ious.append(tp/(tp+fp+fn))\n",
    "        sizes.append(np.sqrt(np.sum(mask)))\n",
    " \n",
    "    print(np.mean(prec), np.mean(rec), np.mean(dice), np.mean(ious))\n",
    "    results2.append([np.mean(prec), np.mean(rec), np.mean(dice), np.mean(ious)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9848ff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.8124564222696982 0.8421388099768795 0.7785468385872898 0.6746105914610402\n",
      "0.8061234947600389 0.8617913013421475 0.7879804979167286 0.6842950355325107\n",
      "0.8359540004784152 0.8384369227834834 0.7928516343398464 0.6949071210818776\n",
      "0.8067497859154358 0.8521900994077689 0.7810040401133524 0.6767506672455154\n",
      "0.8253651987639741 0.844597070762433 0.7891127516817881 0.6874759049133562\n",
      "0.7902150881161933 0.8595524996604994 0.7747178491928848 0.6682300245414021\n",
      "0.785904188629299 0.8540967414142092 0.7687626638552983 0.6579221220505371\n",
      "0.7889502024131986 0.8401506397032008 0.7607361592222173 0.6521076614793715\n",
      "0.8038573949377261 0.8344131009078667 0.7662622294834055 0.6566004664897152\n",
      "0.7847260118261944 0.857737550066366 0.7704619928203205 0.6620911908391585\n"
     ]
    }
   ],
   "source": [
    "models3 = glob.glob(os.path.join(\"manytrainruns_train128_FPN_*\", \"*.pt\"))\n",
    "print(len(models3))\n",
    "\n",
    "results3 = []\n",
    "\n",
    "for mi, model_path in enumerate(models3):\n",
    "    \n",
    "    with open(os.path.join(os.path.split(model_path)[0], \"architecture.txt\"), \"r\") as f:\n",
    "        txt = f.read().split('\\n')\n",
    "        ENCODER = txt[0]\n",
    "        ENCODER_WEIGHTS = txt[1]\n",
    "        \n",
    "    CLASSES = ['vein']\n",
    "    DEVICE = 'cuda'\n",
    "\n",
    "    model = smp.FPN(\n",
    "        encoder_name=ENCODER, \n",
    "        encoder_weights=ENCODER_WEIGHTS, \n",
    "        classes=len(CLASSES), \n",
    "        in_channels=3,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(DEVICE);\n",
    "    \n",
    "    test_ds = WoundData(test_paths)\n",
    "    test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    collated_pred, collated_mask = [], []\n",
    "    collated_img = []\n",
    "    for i, (sampi, sampm) in enumerate(test_dl):\n",
    "        sampo = torch.sigmoid(model(sampi.to(DEVICE)))\n",
    "        collated_pred.append(np.array(sampo.cpu().detach()).squeeze())\n",
    "        collated_mask.append(np.array(sampm.detach()).squeeze())\n",
    "        collated_img.append(np.array(sampi.cpu().detach().squeeze()).transpose(1,2,0))\n",
    "        \n",
    "    collated_pred = np.array(collated_pred)\n",
    "    collated_mask = np.array(collated_mask)\n",
    "    collated_img = np.array(collated_img)\n",
    "    collated_pred_bin = (collated_pred > 0.5).astype(int)\n",
    "    \n",
    "    prec = []\n",
    "    rec = []\n",
    "    dice = []\n",
    "    sizes = []\n",
    "    ious = []\n",
    "\n",
    "    for pred, mask, img in zip(collated_pred_bin, collated_mask, collated_img):\n",
    "        contours, hierarchy = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)    \n",
    "        tp = np.sum((pred + mask) == 2)\n",
    "        tn = np.sum((pred + mask) == 0)\n",
    "        fp = np.sum((pred - mask) > 0)\n",
    "        fn = np.sum((pred - mask) < 0)\n",
    "\n",
    "        prec.append(tp/ (tp + fp + 0.00001))\n",
    "        rec.append(tp/ (tp + fn + 0.00001))\n",
    "        dice.append(2*tp/ (2*tp + fn + fp))\n",
    "        ious.append(tp/(tp+fp+fn))\n",
    "        sizes.append(np.sqrt(np.sum(mask)))\n",
    " \n",
    "    print(np.mean(prec), np.mean(rec), np.mean(dice), np.mean(ious))\n",
    "    results3.append([np.mean(prec), np.mean(rec), np.mean(dice), np.mean(ious)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28eca248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.8652708531058912 0.7891038957778721 0.7808216206807231 0.6782985772341128\n",
      "0.868105586194172 0.7746490581355997 0.7714066047348364 0.6669115492139572\n",
      "0.8878036071185255 0.7686402781311327 0.78017262827587 0.6790334146411907\n",
      "0.8908916052717274 0.7737357451206193 0.7881035287379492 0.6917414859157733\n",
      "0.9166859757756819 0.7101707035975763 0.7565330913923681 0.6477108549886402\n",
      "0.9001761106199357 0.7617140007193388 0.7828533070703685 0.6819446164036482\n",
      "0.919782181250404 0.7320035302510569 0.7758156037056833 0.673814570211171\n",
      "0.8864835142474804 0.7851589682704124 0.7938502596662873 0.6954952753053439\n",
      "0.8989942557546244 0.7542242046193052 0.7784722594971932 0.6754683544391115\n",
      "0.8942463351582627 0.7714302397345506 0.7899137732037571 0.6910987419150264\n"
     ]
    }
   ],
   "source": [
    "models4 = glob.glob(os.path.join(\"manytrainruns_p2psmb128_FPN_0*\", \"*.pt\"))\n",
    "print(len(models4))\n",
    "\n",
    "results4 = []\n",
    "\n",
    "for mi, model_path in enumerate(models4):\n",
    "    \n",
    "    with open(os.path.join(os.path.split(model_path)[0], \"architecture.txt\"), \"r\") as f:\n",
    "        txt = f.read().split('\\n')\n",
    "        ENCODER = txt[0]\n",
    "        ENCODER_WEIGHTS = txt[1]\n",
    "        \n",
    "    CLASSES = ['vein']\n",
    "    DEVICE = 'cuda'\n",
    "\n",
    "    model = smp.FPN(\n",
    "        encoder_name=ENCODER, \n",
    "        encoder_weights=ENCODER_WEIGHTS, \n",
    "        classes=len(CLASSES), \n",
    "        in_channels=3,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(DEVICE);\n",
    "    \n",
    "    test_ds = WoundData(test_paths)\n",
    "    test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    collated_pred, collated_mask = [], []\n",
    "    collated_img = []\n",
    "    for i, (sampi, sampm) in enumerate(test_dl):\n",
    "        sampo = torch.sigmoid(model(sampi.to(DEVICE)))\n",
    "        collated_pred.append(np.array(sampo.cpu().detach()).squeeze())\n",
    "        collated_mask.append(np.array(sampm.detach()).squeeze())\n",
    "        collated_img.append(np.array(sampi.cpu().detach().squeeze()).transpose(1,2,0))\n",
    "        \n",
    "    collated_pred = np.array(collated_pred)\n",
    "    collated_mask = np.array(collated_mask)\n",
    "    collated_img = np.array(collated_img)\n",
    "    collated_pred_bin = (collated_pred > 0.5).astype(int)\n",
    "    \n",
    "    prec = []\n",
    "    rec = []\n",
    "    dice = []\n",
    "    sizes = []\n",
    "    ious = []\n",
    "\n",
    "    for pred, mask, img in zip(collated_pred_bin, collated_mask, collated_img):\n",
    "        contours, hierarchy = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)    \n",
    "        tp = np.sum((pred + mask) == 2)\n",
    "        tn = np.sum((pred + mask) == 0)\n",
    "        fp = np.sum((pred - mask) > 0)\n",
    "        fn = np.sum((pred - mask) < 0)\n",
    "\n",
    "        prec.append(tp/ (tp + fp + 0.00001))\n",
    "        rec.append(tp/ (tp + fn + 0.00001))\n",
    "        dice.append(2*tp/ (2*tp + fn + fp))\n",
    "        ious.append(tp/(tp+fp+fn))\n",
    "        sizes.append(np.sqrt(np.sum(mask)))\n",
    " \n",
    "    print(np.mean(prec), np.mean(rec), np.mean(dice), np.mean(ious))\n",
    "    results4.append([np.mean(prec), np.mean(rec), np.mean(dice), np.mean(ious)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d0478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eff1ec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842034871054116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.83424734, 0.84996917, 0.80361316, 0.70464741])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = np.mean(results, axis=0)\n",
    "print(2*stats[0]*stats[1]/(stats[0]+stats[1]))\n",
    "np.mean(results, axis=0) # unet + gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ea94e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8350701937399583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.80364028, 0.86905858, 0.79073449, 0.68859446])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = np.mean(results2, axis=0)\n",
    "print(2*stats[0]*stats[1]/(stats[0]+stats[1]))\n",
    "np.mean(results2, axis=0) # unet no gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd1d3a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8256717035278338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.80403018, 0.84851047, 0.77704367, 0.67149908])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = np.mean(results3, axis=0)\n",
    "print(2*stats[0]*stats[1]/(stats[0]+stats[1]))\n",
    "np.mean(results3, axis=0) # fpn no gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6c65751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8222976179452897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.892844  , 0.76208306, 0.77979427, 0.67815174])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = np.mean(results4, axis=0)\n",
    "print(2*stats[0]*stats[1]/(stats[0]+stats[1]))\n",
    "np.mean(results4, axis=0) # fpn + gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6be2511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prec rec dice iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "096142a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 25, 10, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results), len(results2), len(results3), len(results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415942f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
