{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import metrics # if you have trouble importing, might not need this\n",
    "from sklearn.metrics import confusion_matrix # if you have trouble importing, might not need this\n",
    "import datetime\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WoundTransformation(im, mask, p):\n",
    "\n",
    "    # Horizontal flip\n",
    "    if np.random.rand() < p:\n",
    "        im = cv2.flip(im,1)\n",
    "        mask = cv2.flip(mask,1)\n",
    "    \n",
    "    # Vertical flip\n",
    "    if np.random.rand() < p:\n",
    "        im = cv2.flip(im,0)\n",
    "        mask = cv2.flip(mask,0)\n",
    "        \n",
    "    # Gaussian noise\n",
    "    if np.random.rand() < p: # Add Gaussian noise\n",
    "        stdv = np.random.uniform(3, 12)\n",
    "        noise = np.random.normal(0, stdv, im.shape)\n",
    "        im = np.uint8(np.round(np.clip(im + noise,0,255)))\n",
    "\n",
    "    return im, mask\n",
    "\n",
    "class WoundData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Read image and mask\n",
    "        im = cv2.imread(self.data[idx][0],-1)\n",
    "        mask = cv2.imread(self.data[idx][1],0)\n",
    "        \n",
    "        if self.transform:\n",
    "            im, mask = WoundTransformation(im, mask, 0.5)\n",
    "        \n",
    "        # From np.array (HxWxC) to torch.tensor (CxHxW). From [0,255] to [0,1]\n",
    "        im = torch.from_numpy(np.float32(im/255).transpose(2,0,1))\n",
    "        mask = torch.from_numpy(np.float32(mask/255)).unsqueeze(0)\n",
    "        \n",
    "        return im, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 621\n",
      "manytrainruns_train128_FPN_04122022-091956\n",
      "Validation loss decreased (inf --> 0.00619407). Saving model ...\n",
      "Epoch 1/100, lr = 4.00e-04, train loss: 0.0153876, val loss: 0.00619407, \n",
      "time taken for epoch:  8.424843311309814\n",
      "----------\n",
      "Validation loss decreased (0.00619407 --> 0.0024079). Saving model ...\n",
      "Epoch 2/100, lr = 4.00e-04, train loss: 0.00424792, val loss: 0.0024079, \n",
      "time taken for epoch:  5.467349052429199\n",
      "----------\n",
      "Validation loss decreased (0.0024079 --> 0.00136113). Saving model ...\n",
      "Epoch 3/100, lr = 4.00e-04, train loss: 0.00222544, val loss: 0.00136113, \n",
      "time taken for epoch:  5.824371576309204\n",
      "----------\n",
      "Epoch 4/100, lr = 4.00e-04, train loss: 0.00143502, val loss: 0.00163112, \n",
      "time taken for epoch:  5.610703468322754\n",
      "----------\n",
      "Validation loss decreased (0.00136113 --> 0.00120119). Saving model ...\n",
      "Epoch 5/100, lr = 4.00e-04, train loss: 0.00123904, val loss: 0.00120119, \n",
      "time taken for epoch:  5.909543991088867\n",
      "----------\n",
      "Validation loss decreased (0.00120119 --> 0.0011827). Saving model ...\n",
      "Epoch 6/100, lr = 4.00e-04, train loss: 0.00107989, val loss: 0.0011827, \n",
      "time taken for epoch:  5.628775119781494\n",
      "----------\n",
      "Validation loss decreased (0.0011827 --> 0.000953538). Saving model ...\n",
      "Epoch 7/100, lr = 4.00e-04, train loss: 0.00100191, val loss: 0.000953538, \n",
      "time taken for epoch:  5.960845232009888\n",
      "----------\n",
      "Epoch 8/100, lr = 4.00e-04, train loss: 0.000919476, val loss: 0.00126103, \n",
      "time taken for epoch:  5.612629175186157\n",
      "----------\n",
      "Validation loss decreased (0.000953538 --> 0.000938112). Saving model ...\n",
      "Epoch 9/100, lr = 4.00e-04, train loss: 0.000794925, val loss: 0.000938112, \n",
      "time taken for epoch:  5.974047899246216\n",
      "----------\n",
      "Validation loss decreased (0.000938112 --> 0.00087832). Saving model ...\n",
      "Epoch 10/100, lr = 4.00e-04, train loss: 0.000761217, val loss: 0.00087832, \n",
      "time taken for epoch:  5.68296480178833\n",
      "----------\n",
      "Epoch 11/100, lr = 4.00e-04, train loss: 0.000729467, val loss: 0.000931656, \n",
      "time taken for epoch:  5.745232820510864\n",
      "----------\n",
      "Epoch 12/100, lr = 4.00e-04, train loss: 0.000682723, val loss: 0.000914018, \n",
      "time taken for epoch:  5.59731388092041\n",
      "----------\n",
      "Validation loss decreased (0.00087832 --> 0.000857118). Saving model ...\n",
      "Epoch 13/100, lr = 4.00e-04, train loss: 0.000611558, val loss: 0.000857118, \n",
      "time taken for epoch:  5.708251714706421\n",
      "----------\n",
      "Epoch 14/100, lr = 4.00e-04, train loss: 0.000592319, val loss: 0.000865621, \n",
      "time taken for epoch:  5.589414119720459\n",
      "----------\n",
      "Validation loss decreased (0.000857118 --> 0.000821462). Saving model ...\n",
      "Epoch 15/100, lr = 4.00e-04, train loss: 0.000520343, val loss: 0.000821462, \n",
      "time taken for epoch:  5.960808753967285\n",
      "----------\n",
      "Epoch 16/100, lr = 4.00e-04, train loss: 0.000473016, val loss: 0.000830812, \n",
      "time taken for epoch:  5.694583892822266\n",
      "----------\n",
      "Epoch 17/100, lr = 4.00e-04, train loss: 0.000713881, val loss: 0.000997191, \n",
      "time taken for epoch:  5.944339036941528\n",
      "----------\n",
      "Epoch 18/100, lr = 4.00e-04, train loss: 0.000534215, val loss: 0.000857714, \n",
      "time taken for epoch:  5.660374164581299\n",
      "----------\n",
      "Validation loss decreased (0.000821462 --> 0.000778105). Saving model ...\n",
      "Epoch 19/100, lr = 4.00e-04, train loss: 0.000482572, val loss: 0.000778105, \n",
      "time taken for epoch:  6.041574716567993\n",
      "----------\n",
      "Validation loss decreased (0.000778105 --> 0.000768321). Saving model ...\n",
      "Epoch 20/100, lr = 4.00e-04, train loss: 0.000464206, val loss: 0.000768321, \n",
      "time taken for epoch:  5.553398370742798\n",
      "----------\n",
      "Validation loss decreased (0.000768321 --> 0.000735183). Saving model ...\n",
      "Epoch 21/100, lr = 4.00e-04, train loss: 0.000428159, val loss: 0.000735183, \n",
      "time taken for epoch:  5.940330266952515\n",
      "----------\n",
      "Validation loss decreased (0.000735183 --> 0.000708406). Saving model ...\n",
      "Epoch 22/100, lr = 4.00e-04, train loss: 0.000409221, val loss: 0.000708406, \n",
      "time taken for epoch:  5.375097751617432\n",
      "----------\n",
      "Epoch 23/100, lr = 4.00e-04, train loss: 0.000439883, val loss: 0.000715206, \n",
      "time taken for epoch:  5.967214822769165\n",
      "----------\n",
      "Validation loss decreased (0.000708406 --> 0.000706661). Saving model ...\n",
      "Epoch 24/100, lr = 4.00e-04, train loss: 0.000385193, val loss: 0.000706661, \n",
      "time taken for epoch:  5.585375547409058\n",
      "----------\n",
      "Validation loss decreased (0.000706661 --> 0.000680616). Saving model ...\n",
      "Epoch 25/100, lr = 4.00e-04, train loss: 0.000371707, val loss: 0.000680616, \n",
      "time taken for epoch:  5.934526443481445\n",
      "----------\n",
      "Epoch 26/100, lr = 4.00e-04, train loss: 0.000345373, val loss: 0.000695002, \n",
      "time taken for epoch:  5.4498350620269775\n",
      "----------\n",
      "Epoch 27/100, lr = 4.00e-04, train loss: 0.000327232, val loss: 0.000715212, \n",
      "time taken for epoch:  5.483837127685547\n",
      "----------\n",
      "Epoch 28/100, lr = 4.00e-04, train loss: 0.000314665, val loss: 0.000709624, \n",
      "time taken for epoch:  5.848146677017212\n",
      "----------\n",
      "Epoch 29/100, lr = 4.00e-04, train loss: 0.000337606, val loss: 0.000736994, \n",
      "time taken for epoch:  7.826730012893677\n",
      "----------\n",
      "Epoch 30/100, lr = 4.00e-04, train loss: 0.000317041, val loss: 0.000759169, \n",
      "time taken for epoch:  8.356276750564575\n",
      "----------\n",
      "val loss stagnant for too long, stopping training\n",
      "155 621\n",
      "manytrainruns_train128_FPN_04122022-092256\n",
      "Validation loss decreased (inf --> 0.00460115). Saving model ...\n",
      "Epoch 1/100, lr = 4.00e-04, train loss: 0.00654339, val loss: 0.00460115, \n",
      "time taken for epoch:  8.523743867874146\n",
      "----------\n",
      "Validation loss decreased (0.00460115 --> 0.00159614). Saving model ...\n",
      "Epoch 2/100, lr = 4.00e-04, train loss: 0.00259736, val loss: 0.00159614, \n",
      "time taken for epoch:  7.852401256561279\n",
      "----------\n",
      "Validation loss decreased (0.00159614 --> 0.00147245). Saving model ...\n",
      "Epoch 3/100, lr = 4.00e-04, train loss: 0.00158606, val loss: 0.00147245, \n",
      "time taken for epoch:  8.463141202926636\n",
      "----------\n",
      "Epoch 4/100, lr = 4.00e-04, train loss: 0.00134966, val loss: 0.00164078, \n",
      "time taken for epoch:  8.169029235839844\n",
      "----------\n",
      "Validation loss decreased (0.00147245 --> 0.00108071). Saving model ...\n",
      "Epoch 5/100, lr = 4.00e-04, train loss: 0.0011356, val loss: 0.00108071, \n",
      "time taken for epoch:  8.500507354736328\n",
      "----------\n",
      "Validation loss decreased (0.00108071 --> 0.00095519). Saving model ...\n",
      "Epoch 6/100, lr = 4.00e-04, train loss: 0.000962547, val loss: 0.00095519, \n",
      "time taken for epoch:  8.014124631881714\n",
      "----------\n",
      "Epoch 7/100, lr = 4.00e-04, train loss: 0.000933149, val loss: 0.00105719, \n",
      "time taken for epoch:  8.453401803970337\n",
      "----------\n",
      "Epoch 8/100, lr = 4.00e-04, train loss: 0.000748908, val loss: 0.000962544, \n",
      "time taken for epoch:  7.606276512145996\n",
      "----------\n",
      "Validation loss decreased (0.00095519 --> 0.000832253). Saving model ...\n",
      "Epoch 9/100, lr = 4.00e-04, train loss: 0.000691136, val loss: 0.000832253, \n",
      "time taken for epoch:  5.728898048400879\n",
      "----------\n",
      "Validation loss decreased (0.000832253 --> 0.000826833). Saving model ...\n",
      "Epoch 10/100, lr = 4.00e-04, train loss: 0.000662401, val loss: 0.000826833, \n",
      "time taken for epoch:  5.831371545791626\n",
      "----------\n",
      "Epoch 11/100, lr = 4.00e-04, train loss: 0.00067339, val loss: 0.000871332, \n",
      "time taken for epoch:  5.960249423980713\n",
      "----------\n",
      "Validation loss decreased (0.000826833 --> 0.000783166). Saving model ...\n",
      "Epoch 12/100, lr = 4.00e-04, train loss: 0.000572189, val loss: 0.000783166, \n",
      "time taken for epoch:  5.6207239627838135\n",
      "----------\n",
      "Epoch 13/100, lr = 4.00e-04, train loss: 0.000647954, val loss: 0.000987636, \n",
      "time taken for epoch:  5.9683144092559814\n",
      "----------\n",
      "Epoch 14/100, lr = 4.00e-04, train loss: 0.00054781, val loss: 0.000957626, \n",
      "time taken for epoch:  5.778452634811401\n",
      "----------\n",
      "Validation loss decreased (0.000783166 --> 0.000766355). Saving model ...\n",
      "Epoch 15/100, lr = 4.00e-04, train loss: 0.000523852, val loss: 0.000766355, \n",
      "time taken for epoch:  6.136946201324463\n",
      "----------\n",
      "Validation loss decreased (0.000766355 --> 0.000716224). Saving model ...\n",
      "Epoch 16/100, lr = 4.00e-04, train loss: 0.000482671, val loss: 0.000716224, \n",
      "time taken for epoch:  6.082759857177734\n",
      "----------\n",
      "Validation loss decreased (0.000716224 --> 0.000687397). Saving model ...\n",
      "Epoch 17/100, lr = 4.00e-04, train loss: 0.000479248, val loss: 0.000687397, \n",
      "time taken for epoch:  6.126118898391724\n",
      "----------\n",
      "Validation loss decreased (0.000687397 --> 0.000663712). Saving model ...\n",
      "Epoch 18/100, lr = 4.00e-04, train loss: 0.000431602, val loss: 0.000663712, \n",
      "time taken for epoch:  5.644241571426392\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, lr = 4.00e-04, train loss: 0.000439302, val loss: 0.000709692, \n",
      "time taken for epoch:  6.27880072593689\n",
      "----------\n",
      "Epoch 20/100, lr = 4.00e-04, train loss: 0.000424758, val loss: 0.000732348, \n",
      "time taken for epoch:  5.7487874031066895\n",
      "----------\n",
      "Epoch 21/100, lr = 4.00e-04, train loss: 0.000426661, val loss: 0.000698431, \n",
      "time taken for epoch:  6.159924745559692\n",
      "----------\n",
      "Epoch 22/100, lr = 4.00e-04, train loss: 0.000417771, val loss: 0.000674847, \n",
      "time taken for epoch:  5.781501770019531\n",
      "----------\n",
      "Validation loss decreased (0.000663712 --> 0.000662662). Saving model ...\n",
      "Epoch 23/100, lr = 4.00e-04, train loss: 0.000395934, val loss: 0.000662662, \n",
      "time taken for epoch:  6.125070333480835\n",
      "----------\n",
      "Validation loss decreased (0.000662662 --> 0.000656624). Saving model ...\n",
      "Epoch 24/100, lr = 4.00e-04, train loss: 0.000351924, val loss: 0.000656624, \n",
      "time taken for epoch:  5.616569757461548\n",
      "----------\n",
      "Validation loss decreased (0.000656624 --> 0.000613329). Saving model ...\n",
      "Epoch 25/100, lr = 4.00e-04, train loss: 0.000346992, val loss: 0.000613329, \n",
      "time taken for epoch:  5.999633073806763\n",
      "----------\n",
      "Epoch 26/100, lr = 4.00e-04, train loss: 0.000330182, val loss: 0.000738946, \n",
      "time taken for epoch:  5.6097471714019775\n",
      "----------\n",
      "Epoch 27/100, lr = 4.00e-04, train loss: 0.000332525, val loss: 0.000633514, \n",
      "time taken for epoch:  6.008891820907593\n",
      "----------\n",
      "Epoch 28/100, lr = 4.00e-04, train loss: 0.000335523, val loss: 0.000670068, \n",
      "time taken for epoch:  5.448164463043213\n",
      "----------\n",
      "Epoch 29/100, lr = 4.00e-04, train loss: 0.000296094, val loss: 0.000632803, \n",
      "time taken for epoch:  5.996340751647949\n",
      "----------\n",
      "Epoch 30/100, lr = 4.00e-04, train loss: 0.000300566, val loss: 0.000616853, \n",
      "time taken for epoch:  5.657425880432129\n",
      "----------\n",
      "val loss stagnant for too long, stopping training\n",
      "155 621\n",
      "manytrainruns_train128_FPN_04122022-092611\n",
      "Validation loss decreased (inf --> 0.00622954). Saving model ...\n",
      "Epoch 1/100, lr = 4.00e-04, train loss: 0.0111977, val loss: 0.00622954, \n",
      "time taken for epoch:  5.658323049545288\n",
      "----------\n",
      "Validation loss decreased (0.00622954 --> 0.00342368). Saving model ...\n",
      "Epoch 2/100, lr = 4.00e-04, train loss: 0.00259136, val loss: 0.00342368, \n",
      "time taken for epoch:  5.963408470153809\n",
      "----------\n",
      "Validation loss decreased (0.00342368 --> 0.00241035). Saving model ...\n",
      "Epoch 3/100, lr = 4.00e-04, train loss: 0.00177385, val loss: 0.00241035, \n",
      "time taken for epoch:  6.000123500823975\n",
      "----------\n",
      "Epoch 4/100, lr = 4.00e-04, train loss: 0.00154625, val loss: 0.00246793, \n",
      "time taken for epoch:  5.98665189743042\n",
      "----------\n",
      "Validation loss decreased (0.00241035 --> 0.00190637). Saving model ...\n",
      "Epoch 5/100, lr = 4.00e-04, train loss: 0.0012405, val loss: 0.00190637, \n",
      "time taken for epoch:  6.2530224323272705\n",
      "----------\n",
      "Validation loss decreased (0.00190637 --> 0.00181406). Saving model ...\n",
      "Epoch 6/100, lr = 4.00e-04, train loss: 0.00103448, val loss: 0.00181406, \n",
      "time taken for epoch:  5.944992780685425\n",
      "----------\n",
      "Epoch 7/100, lr = 4.00e-04, train loss: 0.000863538, val loss: 0.00198806, \n",
      "time taken for epoch:  6.138993740081787\n",
      "----------\n",
      "Validation loss decreased (0.00181406 --> 0.00174044). Saving model ...\n",
      "Epoch 8/100, lr = 4.00e-04, train loss: 0.000753565, val loss: 0.00174044, \n",
      "time taken for epoch:  6.151277303695679\n",
      "----------\n",
      "Validation loss decreased (0.00174044 --> 0.00157143). Saving model ...\n",
      "Epoch 9/100, lr = 4.00e-04, train loss: 0.000712875, val loss: 0.00157143, \n",
      "time taken for epoch:  7.026381015777588\n",
      "----------\n",
      "Validation loss decreased (0.00157143 --> 0.00154129). Saving model ...\n",
      "Epoch 10/100, lr = 4.00e-04, train loss: 0.000648855, val loss: 0.00154129, \n",
      "time taken for epoch:  5.776645660400391\n",
      "----------\n",
      "Validation loss decreased (0.00154129 --> 0.00140381). Saving model ...\n",
      "Epoch 11/100, lr = 4.00e-04, train loss: 0.000573825, val loss: 0.00140381, \n",
      "time taken for epoch:  5.695008754730225\n",
      "----------\n",
      "Epoch 12/100, lr = 4.00e-04, train loss: 0.000622429, val loss: 0.00182545, \n",
      "time taken for epoch:  6.102961301803589\n",
      "----------\n",
      "Epoch 13/100, lr = 4.00e-04, train loss: 0.000515551, val loss: 0.00151113, \n",
      "time taken for epoch:  5.571354866027832\n",
      "----------\n",
      "Epoch 14/100, lr = 4.00e-04, train loss: 0.000538601, val loss: 0.00141103, \n",
      "time taken for epoch:  5.8812243938446045\n",
      "----------\n",
      "Validation loss decreased (0.00140381 --> 0.00136491). Saving model ...\n",
      "Epoch 15/100, lr = 4.00e-04, train loss: 0.000474018, val loss: 0.00136491, \n",
      "time taken for epoch:  5.932219982147217\n",
      "----------\n",
      "Epoch 16/100, lr = 4.00e-04, train loss: 0.000471009, val loss: 0.00142399, \n",
      "time taken for epoch:  5.93080997467041\n",
      "----------\n",
      "Epoch 17/100, lr = 4.00e-04, train loss: 0.000423863, val loss: 0.00137172, \n",
      "time taken for epoch:  5.91903829574585\n",
      "----------\n",
      "Epoch 18/100, lr = 4.00e-04, train loss: 0.000401862, val loss: 0.00141927, \n",
      "time taken for epoch:  5.785560369491577\n",
      "----------\n",
      "Epoch 19/100, lr = 4.00e-04, train loss: 0.000400099, val loss: 0.00138246, \n",
      "time taken for epoch:  5.8233466148376465\n",
      "----------\n",
      "Validation loss decreased (0.00136491 --> 0.00131356). Saving model ...\n",
      "Epoch 20/100, lr = 4.00e-04, train loss: 0.000359897, val loss: 0.00131356, \n",
      "time taken for epoch:  5.865171194076538\n",
      "----------\n",
      "Epoch 21/100, lr = 4.00e-04, train loss: 0.000361582, val loss: 0.0013485, \n",
      "time taken for epoch:  5.704595327377319\n",
      "----------\n",
      "Epoch 22/100, lr = 4.00e-04, train loss: 0.000388328, val loss: 0.00132992, \n",
      "time taken for epoch:  5.957297325134277\n",
      "----------\n",
      "Validation loss decreased (0.00131356 --> 0.00128977). Saving model ...\n",
      "Epoch 23/100, lr = 4.00e-04, train loss: 0.000358155, val loss: 0.00128977, \n",
      "time taken for epoch:  5.66631293296814\n",
      "----------\n",
      "Epoch 24/100, lr = 4.00e-04, train loss: 0.000397974, val loss: 0.00158228, \n",
      "time taken for epoch:  5.978162050247192\n",
      "----------\n",
      "Epoch 25/100, lr = 4.00e-04, train loss: 0.000411387, val loss: 0.00135695, \n",
      "time taken for epoch:  5.760100603103638\n",
      "----------\n",
      "Epoch 26/100, lr = 4.00e-04, train loss: 0.000319642, val loss: 0.00136124, \n",
      "time taken for epoch:  6.02746319770813\n",
      "----------\n",
      "Epoch 27/100, lr = 4.00e-04, train loss: 0.000303949, val loss: 0.0013237, \n",
      "time taken for epoch:  5.272590160369873\n",
      "----------\n",
      "Validation loss decreased (0.00128977 --> 0.00127313). Saving model ...\n",
      "Epoch 28/100, lr = 4.00e-04, train loss: 0.000289165, val loss: 0.00127313, \n",
      "time taken for epoch:  5.9594786167144775\n",
      "----------\n",
      "Epoch 29/100, lr = 4.00e-04, train loss: 0.000308417, val loss: 0.00128075, \n",
      "time taken for epoch:  5.81014609336853\n",
      "----------\n",
      "Epoch 30/100, lr = 4.00e-04, train loss: 0.00027406, val loss: 0.00132877, \n",
      "time taken for epoch:  5.528243064880371\n",
      "----------\n",
      "Validation loss decreased (0.00127313 --> 0.00123165). Saving model ...\n",
      "Epoch 31/100, lr = 4.00e-04, train loss: 0.000310657, val loss: 0.00123165, \n",
      "time taken for epoch:  5.623215675354004\n",
      "----------\n",
      "Epoch 32/100, lr = 4.00e-04, train loss: 0.000252682, val loss: 0.00134097, \n",
      "time taken for epoch:  6.056373834609985\n",
      "----------\n",
      "Epoch 33/100, lr = 4.00e-04, train loss: 0.000272943, val loss: 0.00123777, \n",
      "time taken for epoch:  5.649675369262695\n",
      "----------\n",
      "Validation loss decreased (0.00123165 --> 0.00122177). Saving model ...\n",
      "Epoch 34/100, lr = 4.00e-04, train loss: 0.000254464, val loss: 0.00122177, \n",
      "time taken for epoch:  6.008667707443237\n",
      "----------\n",
      "Epoch 35/100, lr = 4.00e-04, train loss: 0.000250197, val loss: 0.00133952, \n",
      "time taken for epoch:  5.797600030899048\n",
      "----------\n",
      "Epoch 36/100, lr = 4.00e-04, train loss: 0.000246718, val loss: 0.0013331, \n",
      "time taken for epoch:  5.8115808963775635\n",
      "----------\n",
      "Epoch 37/100, lr = 4.00e-04, train loss: 0.000299879, val loss: 0.0014862, \n",
      "time taken for epoch:  5.425654172897339\n",
      "----------\n",
      "Epoch 38/100, lr = 4.00e-04, train loss: 0.000279756, val loss: 0.00139266, \n",
      "time taken for epoch:  5.812483549118042\n",
      "----------\n",
      "Epoch 39/100, lr = 4.00e-04, train loss: 0.000267754, val loss: 0.00134999, \n",
      "time taken for epoch:  5.701031923294067\n",
      "----------\n",
      "val loss stagnant for too long, stopping training\n",
      "155 621\n",
      "manytrainruns_train128_FPN_04122022-093000\n",
      "Validation loss decreased (inf --> 0.0069349). Saving model ...\n",
      "Epoch 1/100, lr = 4.00e-04, train loss: 0.0175347, val loss: 0.0069349, \n",
      "time taken for epoch:  6.148316383361816\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.0069349 --> 0.00308411). Saving model ...\n",
      "Epoch 2/100, lr = 4.00e-04, train loss: 0.00460451, val loss: 0.00308411, \n",
      "time taken for epoch:  5.937627077102661\n",
      "----------\n",
      "Validation loss decreased (0.00308411 --> 0.00192921). Saving model ...\n",
      "Epoch 3/100, lr = 4.00e-04, train loss: 0.00216187, val loss: 0.00192921, \n",
      "time taken for epoch:  6.3564300537109375\n",
      "----------\n",
      "Validation loss decreased (0.00192921 --> 0.00162277). Saving model ...\n",
      "Epoch 4/100, lr = 4.00e-04, train loss: 0.00160947, val loss: 0.00162277, \n",
      "time taken for epoch:  5.970808029174805\n",
      "----------\n",
      "Validation loss decreased (0.00162277 --> 0.00139443). Saving model ...\n",
      "Epoch 5/100, lr = 4.00e-04, train loss: 0.00132304, val loss: 0.00139443, \n",
      "time taken for epoch:  6.150615692138672\n",
      "----------\n",
      "Validation loss decreased (0.00139443 --> 0.00125635). Saving model ...\n",
      "Epoch 6/100, lr = 4.00e-04, train loss: 0.00117056, val loss: 0.00125635, \n",
      "time taken for epoch:  5.74404501914978\n",
      "----------\n",
      "Epoch 7/100, lr = 4.00e-04, train loss: 0.000919742, val loss: 0.0012767, \n",
      "time taken for epoch:  6.041534423828125\n",
      "----------\n",
      "Validation loss decreased (0.00125635 --> 0.00107557). Saving model ...\n",
      "Epoch 8/100, lr = 4.00e-04, train loss: 0.000899061, val loss: 0.00107557, \n",
      "time taken for epoch:  6.476566314697266\n",
      "----------\n",
      "Epoch 9/100, lr = 4.00e-04, train loss: 0.00089439, val loss: 0.00118024, \n",
      "time taken for epoch:  6.47370457649231\n",
      "----------\n",
      "Validation loss decreased (0.00107557 --> 0.00104456). Saving model ...\n",
      "Epoch 10/100, lr = 4.00e-04, train loss: 0.000759854, val loss: 0.00104456, \n",
      "time taken for epoch:  6.1409924030303955\n",
      "----------\n",
      "Epoch 11/100, lr = 4.00e-04, train loss: 0.000746134, val loss: 0.00119169, \n",
      "time taken for epoch:  6.3212621212005615\n",
      "----------\n",
      "Validation loss decreased (0.00104456 --> 0.000982096). Saving model ...\n",
      "Epoch 12/100, lr = 4.00e-04, train loss: 0.000631953, val loss: 0.000982096, \n",
      "time taken for epoch:  5.971794843673706\n",
      "----------\n",
      "Validation loss decreased (0.000982096 --> 0.000968189). Saving model ...\n",
      "Epoch 13/100, lr = 4.00e-04, train loss: 0.000586195, val loss: 0.000968189, \n",
      "time taken for epoch:  6.027063846588135\n",
      "----------\n",
      "Validation loss decreased (0.000968189 --> 0.000909134). Saving model ...\n",
      "Epoch 14/100, lr = 4.00e-04, train loss: 0.000646928, val loss: 0.000909134, \n",
      "time taken for epoch:  5.806967735290527\n",
      "----------\n",
      "Epoch 15/100, lr = 4.00e-04, train loss: 0.000562542, val loss: 0.000931213, \n",
      "time taken for epoch:  6.088000059127808\n",
      "----------\n",
      "Epoch 16/100, lr = 4.00e-04, train loss: 0.000559274, val loss: 0.00103531, \n",
      "time taken for epoch:  5.731128454208374\n",
      "----------\n",
      "Epoch 17/100, lr = 4.00e-04, train loss: 0.000479597, val loss: 0.00106169, \n",
      "time taken for epoch:  6.027815580368042\n",
      "----------\n",
      "Epoch 18/100, lr = 4.00e-04, train loss: 0.000463049, val loss: 0.000914065, \n",
      "time taken for epoch:  5.652421236038208\n",
      "----------\n",
      "Validation loss decreased (0.000909134 --> 0.000895464). Saving model ...\n",
      "Epoch 19/100, lr = 4.00e-04, train loss: 0.000448723, val loss: 0.000895464, \n",
      "time taken for epoch:  6.202733993530273\n",
      "----------\n",
      "Epoch 20/100, lr = 4.00e-04, train loss: 0.000381718, val loss: 0.000903072, \n",
      "time taken for epoch:  5.782987594604492\n",
      "----------\n",
      "Epoch 21/100, lr = 4.00e-04, train loss: 0.000406105, val loss: 0.000903512, \n",
      "time taken for epoch:  6.177916526794434\n",
      "----------\n",
      "Validation loss decreased (0.000895464 --> 0.000884705). Saving model ...\n",
      "Epoch 22/100, lr = 4.00e-04, train loss: 0.000411069, val loss: 0.000884705, \n",
      "time taken for epoch:  5.771891355514526\n",
      "----------\n",
      "Validation loss decreased (0.000884705 --> 0.000869065). Saving model ...\n",
      "Epoch 23/100, lr = 4.00e-04, train loss: 0.000412412, val loss: 0.000869065, \n",
      "time taken for epoch:  6.079251289367676\n",
      "----------\n",
      "Validation loss decreased (0.000869065 --> 0.000840024). Saving model ...\n",
      "Epoch 24/100, lr = 4.00e-04, train loss: 0.000400297, val loss: 0.000840024, \n",
      "time taken for epoch:  5.647667169570923\n",
      "----------\n",
      "Epoch 25/100, lr = 4.00e-04, train loss: 0.000457422, val loss: 0.000926277, \n",
      "time taken for epoch:  6.097665786743164\n",
      "----------\n",
      "Epoch 26/100, lr = 4.00e-04, train loss: 0.000397004, val loss: 0.000947374, \n",
      "time taken for epoch:  5.654216766357422\n",
      "----------\n",
      "Epoch 27/100, lr = 4.00e-04, train loss: 0.000364223, val loss: 0.000855855, \n",
      "time taken for epoch:  5.731019735336304\n",
      "----------\n",
      "Epoch 28/100, lr = 4.00e-04, train loss: 0.000339258, val loss: 0.000948958, \n",
      "time taken for epoch:  5.406809329986572\n",
      "----------\n",
      "Epoch 29/100, lr = 4.00e-04, train loss: 0.000321448, val loss: 0.000889788, \n",
      "time taken for epoch:  5.993209362030029\n",
      "----------\n",
      "val loss stagnant for too long, stopping training\n",
      "155 621\n",
      "manytrainruns_train128_FPN_04122022-093254\n",
      "Validation loss decreased (inf --> 0.0038164). Saving model ...\n",
      "Epoch 1/100, lr = 4.00e-04, train loss: 0.011494, val loss: 0.0038164, \n",
      "time taken for epoch:  5.7541282176971436\n",
      "----------\n",
      "Validation loss decreased (0.0038164 --> 0.00206684). Saving model ...\n",
      "Epoch 2/100, lr = 4.00e-04, train loss: 0.00277347, val loss: 0.00206684, \n",
      "time taken for epoch:  5.829275131225586\n",
      "----------\n",
      "Epoch 3/100, lr = 4.00e-04, train loss: 0.00170367, val loss: 0.00210324, \n",
      "time taken for epoch:  6.293569803237915\n",
      "----------\n",
      "Validation loss decreased (0.00206684 --> 0.00166933). Saving model ...\n",
      "Epoch 4/100, lr = 4.00e-04, train loss: 0.00138937, val loss: 0.00166933, \n",
      "time taken for epoch:  6.357999086380005\n",
      "----------\n",
      "Validation loss decreased (0.00166933 --> 0.00147172). Saving model ...\n",
      "Epoch 5/100, lr = 4.00e-04, train loss: 0.00118143, val loss: 0.00147172, \n",
      "time taken for epoch:  6.085468530654907\n",
      "----------\n",
      "Validation loss decreased (0.00147172 --> 0.00146261). Saving model ...\n",
      "Epoch 6/100, lr = 4.00e-04, train loss: 0.00105687, val loss: 0.00146261, \n",
      "time taken for epoch:  6.051144361495972\n",
      "----------\n",
      "Validation loss decreased (0.00146261 --> 0.0014189). Saving model ...\n",
      "Epoch 7/100, lr = 4.00e-04, train loss: 0.000933802, val loss: 0.0014189, \n",
      "time taken for epoch:  5.85747218132019\n",
      "----------\n",
      "Epoch 8/100, lr = 4.00e-04, train loss: 0.000816588, val loss: 0.00142273, \n",
      "time taken for epoch:  5.826721906661987\n",
      "----------\n",
      "Validation loss decreased (0.0014189 --> 0.00110929). Saving model ...\n",
      "Epoch 9/100, lr = 4.00e-04, train loss: 0.000723435, val loss: 0.00110929, \n",
      "time taken for epoch:  5.91365647315979\n",
      "----------\n",
      "Validation loss decreased (0.00110929 --> 0.00108986). Saving model ...\n",
      "Epoch 10/100, lr = 4.00e-04, train loss: 0.000702095, val loss: 0.00108986, \n",
      "time taken for epoch:  5.905701398849487\n",
      "----------\n",
      "Validation loss decreased (0.00108986 --> 0.000986297). Saving model ...\n",
      "Epoch 11/100, lr = 4.00e-04, train loss: 0.000593424, val loss: 0.000986297, \n",
      "time taken for epoch:  6.008899927139282\n",
      "----------\n",
      "Epoch 12/100, lr = 4.00e-04, train loss: 0.000606795, val loss: 0.00109411, \n",
      "time taken for epoch:  6.081425189971924\n",
      "----------\n",
      "Epoch 13/100, lr = 4.00e-04, train loss: 0.000568563, val loss: 0.00108828, \n",
      "time taken for epoch:  6.0942018032073975\n",
      "----------\n",
      "Epoch 14/100, lr = 4.00e-04, train loss: 0.000525317, val loss: 0.00102998, \n",
      "time taken for epoch:  6.137711524963379\n",
      "----------\n",
      "Validation loss decreased (0.000986297 --> 0.000966456). Saving model ...\n",
      "Epoch 15/100, lr = 4.00e-04, train loss: 0.000499547, val loss: 0.000966456, \n",
      "time taken for epoch:  6.358443021774292\n",
      "----------\n",
      "Validation loss decreased (0.000966456 --> 0.000946478). Saving model ...\n",
      "Epoch 16/100, lr = 4.00e-04, train loss: 0.000453453, val loss: 0.000946478, \n",
      "time taken for epoch:  6.010925054550171\n",
      "----------\n",
      "Epoch 17/100, lr = 4.00e-04, train loss: 0.000437967, val loss: 0.00111225, \n",
      "time taken for epoch:  6.078976631164551\n",
      "----------\n",
      "Validation loss decreased (0.000946478 --> 0.000922398). Saving model ...\n",
      "Epoch 18/100, lr = 4.00e-04, train loss: 0.000406608, val loss: 0.000922398, \n",
      "time taken for epoch:  6.104786396026611\n",
      "----------\n",
      "Epoch 19/100, lr = 4.00e-04, train loss: 0.000408172, val loss: 0.000928213, \n",
      "time taken for epoch:  6.228454113006592\n",
      "----------\n",
      "Epoch 20/100, lr = 4.00e-04, train loss: 0.000462148, val loss: 0.00126727, \n",
      "time taken for epoch:  6.104594707489014\n",
      "----------\n",
      "Epoch 21/100, lr = 4.00e-04, train loss: 0.000429593, val loss: 0.000967833, \n",
      "time taken for epoch:  6.171430826187134\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.000922398 --> 0.000915678). Saving model ...\n",
      "Epoch 22/100, lr = 4.00e-04, train loss: 0.000401316, val loss: 0.000915678, \n",
      "time taken for epoch:  5.837769031524658\n",
      "----------\n",
      "Epoch 23/100, lr = 4.00e-04, train loss: 0.000444944, val loss: 0.00106208, \n",
      "time taken for epoch:  5.825518846511841\n",
      "----------\n",
      "Epoch 24/100, lr = 4.00e-04, train loss: 0.000356251, val loss: 0.000943954, \n",
      "time taken for epoch:  5.772834300994873\n",
      "----------\n",
      "Epoch 25/100, lr = 4.00e-04, train loss: 0.000382219, val loss: 0.00103457, \n",
      "time taken for epoch:  5.6413655281066895\n",
      "----------\n",
      "Validation loss decreased (0.000915678 --> 0.000786054). Saving model ...\n",
      "Epoch 26/100, lr = 4.00e-04, train loss: 0.000397337, val loss: 0.000786054, \n",
      "time taken for epoch:  5.929516553878784\n",
      "----------\n",
      "Epoch 27/100, lr = 4.00e-04, train loss: 0.000317382, val loss: 0.000857997, \n",
      "time taken for epoch:  5.7771666049957275\n",
      "----------\n",
      "Epoch 28/100, lr = 4.00e-04, train loss: 0.000283838, val loss: 0.00078868, \n",
      "time taken for epoch:  5.748778820037842\n",
      "----------\n",
      "Validation loss decreased (0.000786054 --> 0.000770634). Saving model ...\n",
      "Epoch 29/100, lr = 4.00e-04, train loss: 0.000298603, val loss: 0.000770634, \n",
      "time taken for epoch:  5.837677001953125\n",
      "----------\n",
      "Epoch 30/100, lr = 4.00e-04, train loss: 0.000304039, val loss: 0.000790911, \n",
      "time taken for epoch:  6.0529561042785645\n",
      "----------\n",
      "Epoch 31/100, lr = 4.00e-04, train loss: 0.000324809, val loss: 0.000801151, \n",
      "time taken for epoch:  5.893381595611572\n",
      "----------\n",
      "Epoch 32/100, lr = 4.00e-04, train loss: 0.000305423, val loss: 0.000943972, \n",
      "time taken for epoch:  5.945743799209595\n",
      "----------\n",
      "Epoch 33/100, lr = 4.00e-04, train loss: 0.000308744, val loss: 0.00106858, \n",
      "time taken for epoch:  5.870031356811523\n",
      "----------\n",
      "Epoch 34/100, lr = 4.00e-04, train loss: 0.000274587, val loss: 0.000935795, \n",
      "time taken for epoch:  6.227231740951538\n",
      "----------\n",
      "val loss stagnant for too long, stopping training\n",
      "155 621\n",
      "manytrainruns_train128_FPN_04122022-093617\n",
      "Validation loss decreased (inf --> 0.0231551). Saving model ...\n",
      "Epoch 1/100, lr = 4.00e-04, train loss: 0.0217997, val loss: 0.0231551, \n",
      "time taken for epoch:  6.1459643840789795\n",
      "----------\n",
      "Validation loss decreased (0.0231551 --> 0.00654538). Saving model ...\n",
      "Epoch 2/100, lr = 4.00e-04, train loss: 0.0171157, val loss: 0.00654538, \n",
      "time taken for epoch:  5.7826247215271\n",
      "----------\n",
      "Validation loss decreased (0.00654538 --> 0.00248381). Saving model ...\n",
      "Epoch 3/100, lr = 4.00e-04, train loss: 0.00353133, val loss: 0.00248381, \n",
      "time taken for epoch:  6.423906326293945\n",
      "----------\n",
      "Validation loss decreased (0.00248381 --> 0.00194697). Saving model ...\n",
      "Epoch 4/100, lr = 4.00e-04, train loss: 0.0018547, val loss: 0.00194697, \n",
      "time taken for epoch:  7.327436447143555\n",
      "----------\n",
      "Validation loss decreased (0.00194697 --> 0.00174739). Saving model ...\n",
      "Epoch 5/100, lr = 4.00e-04, train loss: 0.00180868, val loss: 0.00174739, \n",
      "time taken for epoch:  7.625741004943848\n",
      "----------\n",
      "Validation loss decreased (0.00174739 --> 0.00140989). Saving model ...\n",
      "Epoch 6/100, lr = 4.00e-04, train loss: 0.00132484, val loss: 0.00140989, \n",
      "time taken for epoch:  7.640485525131226\n",
      "----------\n",
      "Validation loss decreased (0.00140989 --> 0.00129186). Saving model ...\n",
      "Epoch 7/100, lr = 4.00e-04, train loss: 0.000999517, val loss: 0.00129186, \n",
      "time taken for epoch:  7.5416789054870605\n",
      "----------\n",
      "Validation loss decreased (0.00129186 --> 0.00121114). Saving model ...\n",
      "Epoch 8/100, lr = 4.00e-04, train loss: 0.000821616, val loss: 0.00121114, \n",
      "time taken for epoch:  7.497195720672607\n",
      "----------\n",
      "Epoch 9/100, lr = 4.00e-04, train loss: 0.000699307, val loss: 0.00128916, \n",
      "time taken for epoch:  7.605317115783691\n",
      "----------\n",
      "Validation loss decreased (0.00121114 --> 0.00116899). Saving model ...\n",
      "Epoch 10/100, lr = 4.00e-04, train loss: 0.000776588, val loss: 0.00116899, \n",
      "time taken for epoch:  7.241644382476807\n",
      "----------\n",
      "Epoch 11/100, lr = 4.00e-04, train loss: 0.000654467, val loss: 0.00119457, \n",
      "time taken for epoch:  7.265803813934326\n",
      "----------\n",
      "Epoch 12/100, lr = 4.00e-04, train loss: 0.000600342, val loss: 0.00118408, \n",
      "time taken for epoch:  6.945170640945435\n",
      "----------\n",
      "Validation loss decreased (0.00116899 --> 0.00113208). Saving model ...\n",
      "Epoch 13/100, lr = 4.00e-04, train loss: 0.000584937, val loss: 0.00113208, \n",
      "time taken for epoch:  7.502613067626953\n",
      "----------\n",
      "Epoch 14/100, lr = 4.00e-04, train loss: 0.000645756, val loss: 0.00115122, \n",
      "time taken for epoch:  7.416244268417358\n",
      "----------\n",
      "Validation loss decreased (0.00113208 --> 0.00102427). Saving model ...\n",
      "Epoch 15/100, lr = 4.00e-04, train loss: 0.000560688, val loss: 0.00102427, \n",
      "time taken for epoch:  7.506863832473755\n",
      "----------\n",
      "Epoch 16/100, lr = 4.00e-04, train loss: 0.000532985, val loss: 0.00108945, \n",
      "time taken for epoch:  7.267290115356445\n",
      "----------\n",
      "Validation loss decreased (0.00102427 --> 0.000955657). Saving model ...\n",
      "Epoch 17/100, lr = 4.00e-04, train loss: 0.000493388, val loss: 0.000955657, \n",
      "time taken for epoch:  7.251935720443726\n",
      "----------\n",
      "Validation loss decreased (0.000955657 --> 0.000933372). Saving model ...\n",
      "Epoch 18/100, lr = 4.00e-04, train loss: 0.000459001, val loss: 0.000933372, \n",
      "time taken for epoch:  7.672074556350708\n",
      "----------\n",
      "Epoch 19/100, lr = 4.00e-04, train loss: 0.000452458, val loss: 0.000934751, \n",
      "time taken for epoch:  7.142333984375\n",
      "----------\n",
      "Validation loss decreased (0.000933372 --> 0.000866115). Saving model ...\n",
      "Epoch 20/100, lr = 4.00e-04, train loss: 0.000387198, val loss: 0.000866115, \n",
      "time taken for epoch:  7.602476596832275\n",
      "----------\n",
      "Epoch 21/100, lr = 4.00e-04, train loss: 0.0003938, val loss: 0.000941158, \n",
      "time taken for epoch:  7.370104551315308\n",
      "----------\n",
      "Epoch 22/100, lr = 4.00e-04, train loss: 0.000383167, val loss: 0.00104075, \n",
      "time taken for epoch:  7.458025693893433\n",
      "----------\n",
      "Epoch 23/100, lr = 4.00e-04, train loss: 0.000353656, val loss: 0.000984538, \n",
      "time taken for epoch:  7.189826250076294\n",
      "----------\n",
      "Epoch 24/100, lr = 4.00e-04, train loss: 0.000380476, val loss: 0.00114571, \n",
      "time taken for epoch:  7.326386213302612\n",
      "----------\n",
      "Epoch 25/100, lr = 4.00e-04, train loss: 0.000348326, val loss: 0.000966412, \n",
      "time taken for epoch:  7.453898668289185\n",
      "----------\n",
      "val loss stagnant for too long, stopping training\n",
      "155 621\n",
      "manytrainruns_train128_FPN_04122022-093919\n",
      "Validation loss decreased (inf --> 0.00605632). Saving model ...\n",
      "Epoch 1/100, lr = 4.00e-04, train loss: 0.01642, val loss: 0.00605632, \n",
      "time taken for epoch:  7.182106018066406\n",
      "----------\n",
      "Validation loss decreased (0.00605632 --> 0.00272683). Saving model ...\n",
      "Epoch 2/100, lr = 4.00e-04, train loss: 0.00385972, val loss: 0.00272683, \n",
      "time taken for epoch:  7.724264860153198\n",
      "----------\n",
      "Validation loss decreased (0.00272683 --> 0.00204024). Saving model ...\n",
      "Epoch 3/100, lr = 4.00e-04, train loss: 0.00202797, val loss: 0.00204024, \n",
      "time taken for epoch:  7.0768327713012695\n",
      "----------\n",
      "Validation loss decreased (0.00204024 --> 0.00170502). Saving model ...\n",
      "Epoch 4/100, lr = 4.00e-04, train loss: 0.00173987, val loss: 0.00170502, \n",
      "time taken for epoch:  7.262613534927368\n",
      "----------\n",
      "Validation loss decreased (0.00170502 --> 0.00144924). Saving model ...\n",
      "Epoch 5/100, lr = 4.00e-04, train loss: 0.00124377, val loss: 0.00144924, \n",
      "time taken for epoch:  7.2130286693573\n",
      "----------\n",
      "Validation loss decreased (0.00144924 --> 0.00142666). Saving model ...\n",
      "Epoch 6/100, lr = 4.00e-04, train loss: 0.00121942, val loss: 0.00142666, \n",
      "time taken for epoch:  7.568898677825928\n",
      "----------\n",
      "Epoch 7/100, lr = 4.00e-04, train loss: 0.0010629, val loss: 0.00197467, \n",
      "time taken for epoch:  7.316066026687622\n",
      "----------\n",
      "Epoch 8/100, lr = 4.00e-04, train loss: 0.000946753, val loss: 0.00157259, \n",
      "time taken for epoch:  7.539892196655273\n",
      "----------\n",
      "Epoch 9/100, lr = 4.00e-04, train loss: 0.0007777, val loss: 0.00152748, \n",
      "time taken for epoch:  7.285660982131958\n",
      "----------\n",
      "Validation loss decreased (0.00142666 --> 0.00135901). Saving model ...\n",
      "Epoch 10/100, lr = 4.00e-04, train loss: 0.000769026, val loss: 0.00135901, \n",
      "time taken for epoch:  7.734420299530029\n",
      "----------\n",
      "Validation loss decreased (0.00135901 --> 0.00120942). Saving model ...\n",
      "Epoch 11/100, lr = 4.00e-04, train loss: 0.00067982, val loss: 0.00120942, \n",
      "time taken for epoch:  7.447281837463379\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.00120942 --> 0.00117915). Saving model ...\n",
      "Epoch 12/100, lr = 4.00e-04, train loss: 0.000644803, val loss: 0.00117915, \n",
      "time taken for epoch:  7.659735202789307\n",
      "----------\n",
      "Epoch 13/100, lr = 4.00e-04, train loss: 0.000558632, val loss: 0.00142365, \n",
      "time taken for epoch:  7.426102876663208\n",
      "----------\n",
      "Epoch 14/100, lr = 4.00e-04, train loss: 0.00060733, val loss: 0.00120497, \n",
      "time taken for epoch:  7.61640477180481\n",
      "----------\n",
      "Epoch 15/100, lr = 4.00e-04, train loss: 0.000560343, val loss: 0.00146139, \n",
      "time taken for epoch:  7.2864990234375\n",
      "----------\n",
      "Epoch 16/100, lr = 4.00e-04, train loss: 0.000557724, val loss: 0.00127563, \n",
      "time taken for epoch:  7.293992280960083\n",
      "----------\n",
      "Epoch 17/100, lr = 4.00e-04, train loss: 0.000577669, val loss: 0.0012723, \n",
      "time taken for epoch:  7.495680093765259\n",
      "----------\n",
      "val loss stagnant for too long, stopping training\n",
      "155 621\n",
      "manytrainruns_train128_FPN_04122022-094125\n",
      "Validation loss decreased (inf --> 0.00484074). Saving model ...\n",
      "Epoch 1/100, lr = 4.00e-04, train loss: 0.0132912, val loss: 0.00484074, \n",
      "time taken for epoch:  7.681623220443726\n",
      "----------\n",
      "Validation loss decreased (0.00484074 --> 0.00204332). Saving model ...\n",
      "Epoch 2/100, lr = 4.00e-04, train loss: 0.00332409, val loss: 0.00204332, \n",
      "time taken for epoch:  7.313700437545776\n",
      "----------\n",
      "Validation loss decreased (0.00204332 --> 0.0016149). Saving model ...\n",
      "Epoch 3/100, lr = 4.00e-04, train loss: 0.00178968, val loss: 0.0016149, \n",
      "time taken for epoch:  7.255039215087891\n",
      "----------\n",
      "Validation loss decreased (0.0016149 --> 0.00157407). Saving model ...\n",
      "Epoch 4/100, lr = 4.00e-04, train loss: 0.00144335, val loss: 0.00157407, \n",
      "time taken for epoch:  7.312818765640259\n",
      "----------\n",
      "Validation loss decreased (0.00157407 --> 0.00155949). Saving model ...\n",
      "Epoch 5/100, lr = 4.00e-04, train loss: 0.0011992, val loss: 0.00155949, \n",
      "time taken for epoch:  7.659337043762207\n",
      "----------\n",
      "Validation loss decreased (0.00155949 --> 0.00111139). Saving model ...\n",
      "Epoch 6/100, lr = 4.00e-04, train loss: 0.00118343, val loss: 0.00111139, \n",
      "time taken for epoch:  7.36421537399292\n",
      "----------\n",
      "Epoch 7/100, lr = 4.00e-04, train loss: 0.000995164, val loss: 0.00135948, \n",
      "time taken for epoch:  7.295778274536133\n",
      "----------\n",
      "Epoch 8/100, lr = 4.00e-04, train loss: 0.000918002, val loss: 0.00126512, \n",
      "time taken for epoch:  7.305059432983398\n",
      "----------\n",
      "Validation loss decreased (0.00111139 --> 0.00108722). Saving model ...\n",
      "Epoch 9/100, lr = 4.00e-04, train loss: 0.00072724, val loss: 0.00108722, \n",
      "time taken for epoch:  7.540199041366577\n",
      "----------\n",
      "Epoch 10/100, lr = 4.00e-04, train loss: 0.000655524, val loss: 0.00118617, \n",
      "time taken for epoch:  6.132153511047363\n",
      "----------\n",
      "Epoch 11/100, lr = 4.00e-04, train loss: 0.000655794, val loss: 0.00111536, \n",
      "time taken for epoch:  6.376280069351196\n",
      "----------\n",
      "Validation loss decreased (0.00108722 --> 0.0010701). Saving model ...\n",
      "Epoch 12/100, lr = 4.00e-04, train loss: 0.000629693, val loss: 0.0010701, \n",
      "time taken for epoch:  6.307678461074829\n",
      "----------\n",
      "Epoch 13/100, lr = 4.00e-04, train loss: 0.000554151, val loss: 0.00117184, \n",
      "time taken for epoch:  6.349686861038208\n",
      "----------\n",
      "Epoch 14/100, lr = 4.00e-04, train loss: 0.000527626, val loss: 0.00109313, \n",
      "time taken for epoch:  6.1259236335754395\n",
      "----------\n",
      "Epoch 15/100, lr = 4.00e-04, train loss: 0.00051949, val loss: 0.00114268, \n",
      "time taken for epoch:  6.294607162475586\n",
      "----------\n",
      "Epoch 16/100, lr = 4.00e-04, train loss: 0.00050676, val loss: 0.00120413, \n",
      "time taken for epoch:  6.037833213806152\n",
      "----------\n",
      "Epoch 17/100, lr = 4.00e-04, train loss: 0.000469889, val loss: 0.00130952, \n",
      "time taken for epoch:  5.939514398574829\n",
      "----------\n",
      "val loss stagnant for too long, stopping training\n",
      "155 621\n",
      "manytrainruns_train128_FPN_04122022-094322\n",
      "Validation loss decreased (inf --> 0.00369198). Saving model ...\n",
      "Epoch 1/100, lr = 4.00e-04, train loss: 0.0069019, val loss: 0.00369198, \n",
      "time taken for epoch:  5.689633131027222\n",
      "----------\n",
      "Validation loss decreased (0.00369198 --> 0.0015266). Saving model ...\n",
      "Epoch 2/100, lr = 4.00e-04, train loss: 0.00235855, val loss: 0.0015266, \n",
      "time taken for epoch:  5.953699827194214\n",
      "----------\n",
      "Validation loss decreased (0.0015266 --> 0.00144098). Saving model ...\n",
      "Epoch 3/100, lr = 4.00e-04, train loss: 0.00174655, val loss: 0.00144098, \n",
      "time taken for epoch:  5.621246099472046\n",
      "----------\n",
      "Validation loss decreased (0.00144098 --> 0.00131219). Saving model ...\n",
      "Epoch 4/100, lr = 4.00e-04, train loss: 0.00141451, val loss: 0.00131219, \n",
      "time taken for epoch:  6.06616997718811\n",
      "----------\n",
      "Validation loss decreased (0.00131219 --> 0.0011511). Saving model ...\n",
      "Epoch 5/100, lr = 4.00e-04, train loss: 0.00113456, val loss: 0.0011511, \n",
      "time taken for epoch:  6.020621061325073\n",
      "----------\n",
      "Epoch 6/100, lr = 4.00e-04, train loss: 0.000953687, val loss: 0.00119865, \n",
      "time taken for epoch:  6.176875352859497\n",
      "----------\n",
      "Validation loss decreased (0.0011511 --> 0.000994317). Saving model ...\n",
      "Epoch 7/100, lr = 4.00e-04, train loss: 0.000896857, val loss: 0.000994317, \n",
      "time taken for epoch:  6.096463203430176\n",
      "----------\n",
      "Epoch 8/100, lr = 4.00e-04, train loss: 0.000849856, val loss: 0.00100266, \n",
      "time taken for epoch:  6.03081202507019\n",
      "----------\n",
      "Validation loss decreased (0.000994317 --> 0.000982827). Saving model ...\n",
      "Epoch 9/100, lr = 4.00e-04, train loss: 0.000700032, val loss: 0.000982827, \n",
      "time taken for epoch:  6.079424858093262\n",
      "----------\n",
      "Validation loss decreased (0.000982827 --> 0.000959528). Saving model ...\n",
      "Epoch 10/100, lr = 4.00e-04, train loss: 0.000681024, val loss: 0.000959528, \n",
      "time taken for epoch:  6.080185413360596\n",
      "----------\n",
      "Validation loss decreased (0.000959528 --> 0.000921882). Saving model ...\n",
      "Epoch 11/100, lr = 4.00e-04, train loss: 0.000652437, val loss: 0.000921882, \n",
      "time taken for epoch:  6.172958612442017\n",
      "----------\n",
      "Validation loss decreased (0.000921882 --> 0.000904908). Saving model ...\n",
      "Epoch 12/100, lr = 4.00e-04, train loss: 0.000579886, val loss: 0.000904908, \n",
      "time taken for epoch:  5.70885968208313\n",
      "----------\n",
      "Validation loss decreased (0.000904908 --> 0.00080659). Saving model ...\n",
      "Epoch 13/100, lr = 4.00e-04, train loss: 0.000550422, val loss: 0.00080659, \n",
      "time taken for epoch:  5.733989953994751\n",
      "----------\n",
      "Epoch 14/100, lr = 4.00e-04, train loss: 0.000528215, val loss: 0.000830694, \n",
      "time taken for epoch:  6.43208646774292\n",
      "----------\n",
      "Epoch 15/100, lr = 4.00e-04, train loss: 0.000516636, val loss: 0.00083693, \n",
      "time taken for epoch:  6.030494451522827\n",
      "----------\n",
      "Epoch 16/100, lr = 4.00e-04, train loss: 0.000425791, val loss: 0.000892641, \n",
      "time taken for epoch:  6.2538392543792725\n",
      "----------\n",
      "Epoch 17/100, lr = 4.00e-04, train loss: 0.000453407, val loss: 0.000850103, \n",
      "time taken for epoch:  6.071003198623657\n",
      "----------\n",
      "Epoch 18/100, lr = 4.00e-04, train loss: 0.000517442, val loss: 0.000807651, \n",
      "time taken for epoch:  6.2314488887786865\n",
      "----------\n",
      "val loss stagnant for too long, stopping training\n",
      "155 621\n",
      "manytrainruns_train128_FPN_04122022-094510\n",
      "Validation loss decreased (inf --> 0.00342153). Saving model ...\n",
      "Epoch 1/100, lr = 4.00e-04, train loss: 0.00757902, val loss: 0.00342153, \n",
      "time taken for epoch:  6.181159734725952\n",
      "----------\n",
      "Validation loss decreased (0.00342153 --> 0.0021301). Saving model ...\n",
      "Epoch 2/100, lr = 4.00e-04, train loss: 0.00238262, val loss: 0.0021301, \n",
      "time taken for epoch:  5.972562313079834\n",
      "----------\n",
      "Validation loss decreased (0.0021301 --> 0.00210145). Saving model ...\n",
      "Epoch 3/100, lr = 4.00e-04, train loss: 0.0017266, val loss: 0.00210145, \n",
      "time taken for epoch:  6.106287956237793\n",
      "----------\n",
      "Validation loss decreased (0.00210145 --> 0.00182521). Saving model ...\n",
      "Epoch 4/100, lr = 4.00e-04, train loss: 0.00133522, val loss: 0.00182521, \n",
      "time taken for epoch:  6.068418979644775\n",
      "----------\n",
      "Validation loss decreased (0.00182521 --> 0.00146528). Saving model ...\n",
      "Epoch 5/100, lr = 4.00e-04, train loss: 0.00143968, val loss: 0.00146528, \n",
      "time taken for epoch:  6.019140243530273\n",
      "----------\n",
      "Validation loss decreased (0.00146528 --> 0.00139445). Saving model ...\n",
      "Epoch 6/100, lr = 4.00e-04, train loss: 0.00106246, val loss: 0.00139445, \n",
      "time taken for epoch:  5.9934892654418945\n",
      "----------\n",
      "Epoch 7/100, lr = 4.00e-04, train loss: 0.00100654, val loss: 0.00163989, \n",
      "time taken for epoch:  5.698148250579834\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, lr = 4.00e-04, train loss: 0.000793151, val loss: 0.00146374, \n",
      "time taken for epoch:  5.868404150009155\n",
      "----------\n",
      "Epoch 9/100, lr = 4.00e-04, train loss: 0.000745834, val loss: 0.00153601, \n",
      "time taken for epoch:  5.9731104373931885\n",
      "----------\n",
      "Epoch 10/100, lr = 4.00e-04, train loss: 0.000705833, val loss: 0.00156273, \n",
      "time taken for epoch:  5.833791017532349\n",
      "----------\n",
      "Validation loss decreased (0.00139445 --> 0.00130994). Saving model ...\n",
      "Epoch 11/100, lr = 4.00e-04, train loss: 0.000657543, val loss: 0.00130994, \n",
      "time taken for epoch:  6.2532854080200195\n",
      "----------\n",
      "Epoch 12/100, lr = 4.00e-04, train loss: 0.000621417, val loss: 0.00150941, \n",
      "time taken for epoch:  6.084969520568848\n",
      "----------\n",
      "Validation loss decreased (0.00130994 --> 0.00122631). Saving model ...\n",
      "Epoch 13/100, lr = 4.00e-04, train loss: 0.000552224, val loss: 0.00122631, \n",
      "time taken for epoch:  6.2061989307403564\n",
      "----------\n",
      "Validation loss decreased (0.00122631 --> 0.00112476). Saving model ...\n",
      "Epoch 14/100, lr = 4.00e-04, train loss: 0.000530588, val loss: 0.00112476, \n",
      "time taken for epoch:  6.070983409881592\n",
      "----------\n",
      "Epoch 15/100, lr = 4.00e-04, train loss: 0.00047439, val loss: 0.0012687, \n",
      "time taken for epoch:  6.23209547996521\n",
      "----------\n",
      "Epoch 16/100, lr = 4.00e-04, train loss: 0.000527389, val loss: 0.00121474, \n",
      "time taken for epoch:  6.176812410354614\n",
      "----------\n",
      "Epoch 17/100, lr = 4.00e-04, train loss: 0.000489074, val loss: 0.00124635, \n",
      "time taken for epoch:  6.323091745376587\n",
      "----------\n",
      "Epoch 18/100, lr = 4.00e-04, train loss: 0.000442771, val loss: 0.0014624, \n",
      "time taken for epoch:  5.967409372329712\n",
      "----------\n",
      "Epoch 19/100, lr = 4.00e-04, train loss: 0.000462814, val loss: 0.0011836, \n",
      "time taken for epoch:  6.442768573760986\n",
      "----------\n",
      "val loss stagnant for too long, stopping training\n"
     ]
    }
   ],
   "source": [
    "exp_run_count = 10 # on my laptop, 1 run takes ~15 min (on gpu)\n",
    "randomly_drop_percent = 0 # 0-100 # FEEL FREE TO EXPERIMENT\n",
    "\n",
    "datafolder = \"train128\" # MUST POINT PROPERLY\n",
    "ENCODER = 'timm-regnetx_006' # FEEL FREE TO EXPERIMENT\n",
    "ENCODER_WEIGHTS = 'imagenet' # FEEL FREE TO EXPERIMENT\n",
    "CLASSES = ['wound']\n",
    "DEVICE = 'cuda'\n",
    "learningrate = 4e-4 # FEEL FREE TO EXPERIMENT\n",
    "n_epochs = 100 # FEEL FREE TO EXPERIMENT\n",
    "early_stop = 5 # FEEL FREE TO EXPERIMENT\n",
    "net = \"FPN\"\n",
    "\n",
    "for exprun in range(exp_run_count):\n",
    "\n",
    "    train_folder_imgs = np.array(glob.glob(os.path.join(datafolder, \"images\", \"*\")))\n",
    "    train_folder_labs = np.array(glob.glob(os.path.join(datafolder, \"labels\", \"*\")))\n",
    "    to_keep = np.random.choice(len(train_folder_imgs), int(len(train_folder_imgs)*(100-randomly_drop_percent)/100), replace=False).astype(int)\n",
    "    train_folder_imgs = train_folder_imgs[to_keep]\n",
    "    train_folder_labs = train_folder_labs[to_keep]\n",
    "\n",
    "    val_idx = np.random.choice(len(train_folder_imgs), int(2*len(train_folder_imgs)/10), replace=False).astype(int)\n",
    "    val_paths = []\n",
    "    train_paths = []\n",
    "    for i in range(len(train_folder_imgs)):\n",
    "        if i in val_idx:\n",
    "            val_paths.append([train_folder_imgs[i], train_folder_labs[i]])\n",
    "        else:\n",
    "            train_paths.append([train_folder_imgs[i], train_folder_labs[i]])\n",
    "    print(len(val_paths), len(train_paths))\n",
    "\n",
    "    folder_name = \"manytrainruns_\" + datafolder + \"_\" + net + \"_\" + datetime.datetime.now().strftime(\"%d%m%Y-%H%M%S\")\n",
    "    print(folder_name)\n",
    "    os.mkdir(folder_name)\n",
    "    np.save(os.path.join(folder_name, 'val_names.npy'), val_paths)\n",
    "    np.save(os.path.join(folder_name, 'train_names.npy'), train_paths)\n",
    "    with open(os.path.join(folder_name, 'architecture.txt'), \"a\") as f:\n",
    "        f.write(ENCODER)\n",
    "        f.write('\\n')\n",
    "        f.write(ENCODER_WEIGHTS)\n",
    "        f.write('\\n')\n",
    "        f.write(str(learningrate))        \n",
    "        f.write('\\n')\n",
    "        f.write(str(n_epochs))     \n",
    "        f.write('\\n')\n",
    "        f.write(str(early_stop))     \n",
    "        f.write('\\n')\n",
    "        f.write(datafolder)\n",
    "        f.write('\\n')\n",
    "        f.write(net)\n",
    "\n",
    "    train_ds = WoundData(train_paths, True)\n",
    "    val_ds = WoundData(val_paths, False)\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=0)\n",
    "    val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "    # create segmentation model with pretrained encoder\n",
    "\n",
    "    if net == \"UNet\":\n",
    "        model = smp.Unet(\n",
    "            encoder_name=ENCODER, \n",
    "            encoder_weights=ENCODER_WEIGHTS, \n",
    "            classes=len(CLASSES), \n",
    "            in_channels=3,\n",
    "        )\n",
    "    elif net == \"FPN\":\n",
    "        model = smp.FPN(\n",
    "            encoder_name=ENCODER, \n",
    "            encoder_weights=ENCODER_WEIGHTS, \n",
    "            classes=len(CLASSES), \n",
    "            in_channels=3,\n",
    "        )        \n",
    "\n",
    "    model.to(DEVICE);\n",
    "\n",
    "    #PyTorch\n",
    "    ALPHA = 0.4\n",
    "    BETA = 0.6\n",
    "    GAMMA = 2\n",
    "\n",
    "    class FocalTverskyLoss(nn.Module):\n",
    "        def __init__(self, weight=None, size_average=True):\n",
    "            super(FocalTverskyLoss, self).__init__()\n",
    "\n",
    "        def forward(self, inputs, targets, smooth=1, alpha=ALPHA, beta=BETA, gamma=GAMMA):\n",
    "\n",
    "            #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "            inputs = torch.sigmoid(inputs)       \n",
    "            #flatten label and prediction tensors\n",
    "            inputs = inputs.view(-1)\n",
    "            targets = targets.view(-1)\n",
    "\n",
    "            #True Positives, False Positives & False Negatives\n",
    "            TP = (inputs * targets).sum()    \n",
    "            FP = ((1-targets) * inputs).sum()\n",
    "            FN = (targets * (1-inputs)).sum()\n",
    "\n",
    "            Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "            FocalTversky = (1 - Tversky)**gamma\n",
    "\n",
    "            return FocalTversky\n",
    "\n",
    "    ##Loss\n",
    "    loss_func = FocalTverskyLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=learningrate)\n",
    "\n",
    "    # Learning rate schedule\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt,mode='min',factor=0.1,patience=10,verbose=1)\n",
    "\n",
    "    # freeze encoder\n",
    "    #for param in model.encoder.parameters():\n",
    "    #    param.requires_grad = False\n",
    "\n",
    "    # Training loop\n",
    "    #unfreeze_epochs = 3\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    val_loss_min = np.Inf\n",
    "    stagnant = 0\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "\n",
    "        #if epoch == unfreeze_epochs:\n",
    "        #    for param in model.encoder.parameters():\n",
    "        #        param.requires_grad = True        \n",
    "\n",
    "        e_time = time.time()\n",
    "        # Get value of the current learning rate\n",
    "        current_lr = opt.param_groups[0]['lr']\n",
    "\n",
    "        # keep track of training and validation loss\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        # Train the model\n",
    "        model.train()\n",
    "        for bid, (xb, yb) in enumerate(train_dl):\n",
    "            #if bid % 10 == 0:\n",
    "            #    print(epoch, bid)\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing input to the model\n",
    "            output = model(xb)\n",
    "\n",
    "            # calculate the batch losses\n",
    "            loss = loss_func(output, yb)\n",
    "\n",
    "            # clear the gradients of all optimized variables\n",
    "            opt.zero_grad()\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            opt.step()\n",
    "\n",
    "            # Update train loss\n",
    "            train_loss += loss.item()\n",
    "\n",
    "\n",
    "        # Validate the model\n",
    "        model.eval() # Activate dropout and BatchNorm in eval mode\n",
    "        with torch.no_grad(): # Save memory bc gradients are not calculated\n",
    "            for xb, yb in val_dl:\n",
    "                xb = xb.to(DEVICE) #(n,1,120,120)\n",
    "                yb = yb.to(DEVICE) #(n,1,120,120)\n",
    "\n",
    "                # forward pass: compute predicted outputs by passing input to the model\n",
    "                output = model(xb) #(n,1,120,120)\n",
    "\n",
    "                # calculate the batch losses\n",
    "                loss = loss_func(output, yb)\n",
    "\n",
    "                # Update validation loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Calculate average losses of the epoch\n",
    "        train_loss /= len(train_ds)\n",
    "        val_loss /= len(val_ds)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Store best model\n",
    "        if val_loss < val_loss_min:\n",
    "            print(f'Validation loss decreased ({val_loss_min:.6} --> {val_loss:.6}). Saving model ...')\n",
    "            torch.save(model.state_dict(), os.path.join(folder_name, 'ganwoundmodel.pt'))\n",
    "            val_loss_min = val_loss\n",
    "            stagnant = 0\n",
    "        else:\n",
    "            stagnant += 1\n",
    "\n",
    "        # learning rate schedule\n",
    "        lr_scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{n_epochs}, lr = {current_lr:.2e}, \"\n",
    "        f\"train loss: {train_loss:.6}, val loss: {val_loss:.6}, \")\n",
    "        print(\"time taken for epoch: \", time.time() - e_time)\n",
    "        #print(\"trained parameters: \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "        print(\"-\"*10)\n",
    "\n",
    "        if stagnant >= early_stop:\n",
    "            print('val loss stagnant for too long, stopping training')\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
