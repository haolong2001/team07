{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/intern1/pixgan'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.chdir('pytorch-CycleGAN-and-pix2pix/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "----------------- Options ---------------\n",
      "               batch_size: 16                            \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_multiclass_256\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 0                             \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 4                             \t[default: 3]\n",
      "                     name: footulcer_multiclass_256      \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: n_layers                      \t[default: basic]\n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 776\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 6.964 M\n",
      "-----------------------------------------------\n",
      "create web directory ./checkpoints/footulcer_multiclass_256/web...\n",
      "/home/intern1/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 400, time: 0.023, data: 0.147) G_GAN: 2.599 G_L1: 28.913 D_real: 0.259 D_fake: 0.245 \n",
      "End of epoch 1 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 16, time: 0.014, data: 0.004) G_GAN: 3.699 G_L1: 35.242 D_real: 0.064 D_fake: 0.054 \n",
      "(epoch: 2, iters: 416, time: 0.021, data: 0.003) G_GAN: 3.218 G_L1: 28.409 D_real: 0.061 D_fake: 0.076 \n",
      "End of epoch 2 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 32, time: 0.023, data: 0.003) G_GAN: 1.924 G_L1: 30.885 D_real: 0.363 D_fake: 0.050 \n",
      "(epoch: 3, iters: 432, time: 0.024, data: 0.002) G_GAN: 3.520 G_L1: 36.868 D_real: 0.028 D_fake: 0.167 \n",
      "End of epoch 3 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 48, time: 0.025, data: 0.004) G_GAN: 1.621 G_L1: 33.956 D_real: 0.574 D_fake: 0.427 \n",
      "(epoch: 4, iters: 448, time: 0.022, data: 0.002) G_GAN: 4.192 G_L1: 38.117 D_real: 0.018 D_fake: 0.028 \n",
      "End of epoch 4 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 64, time: 0.024, data: 0.003) G_GAN: 3.387 G_L1: 30.654 D_real: 0.219 D_fake: 0.044 \n",
      "(epoch: 5, iters: 464, time: 0.021, data: 0.006) G_GAN: 1.846 G_L1: 35.759 D_real: 0.083 D_fake: 0.046 \n",
      "saving the model at the end of epoch 5, iters 3920\n",
      "End of epoch 5 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 80, time: 0.023, data: 0.003) G_GAN: 4.573 G_L1: 38.149 D_real: 0.013 D_fake: 0.021 \n",
      "(epoch: 6, iters: 480, time: 0.025, data: 0.002) G_GAN: 3.407 G_L1: 34.450 D_real: 0.030 D_fake: 0.386 \n",
      "End of epoch 6 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 96, time: 0.025, data: 0.004) G_GAN: 3.770 G_L1: 45.076 D_real: 0.006 D_fake: 0.027 \n",
      "(epoch: 7, iters: 496, time: 0.021, data: 0.002) G_GAN: 2.907 G_L1: 30.203 D_real: 0.068 D_fake: 0.366 \n",
      "End of epoch 7 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 112, time: 0.023, data: 0.004) G_GAN: 3.931 G_L1: 34.796 D_real: 0.252 D_fake: 0.467 \n",
      "(epoch: 8, iters: 512, time: 0.026, data: 0.003) G_GAN: 0.512 G_L1: 31.848 D_real: 1.519 D_fake: 0.064 \n",
      "End of epoch 8 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 128, time: 0.029, data: 0.003) G_GAN: 4.832 G_L1: 36.258 D_real: 5.174 D_fake: 0.001 \n",
      "(epoch: 9, iters: 528, time: 0.025, data: 0.004) G_GAN: 4.988 G_L1: 34.551 D_real: 0.029 D_fake: 1.276 \n",
      "End of epoch 9 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 144, time: 0.028, data: 0.005) G_GAN: 3.440 G_L1: 36.469 D_real: 0.006 D_fake: 1.227 \n",
      "(epoch: 10, iters: 544, time: 0.025, data: 0.003) G_GAN: 5.298 G_L1: 34.523 D_real: 0.610 D_fake: 0.005 \n",
      "saving the model at the end of epoch 10, iters 7840\n",
      "End of epoch 10 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 160, time: 0.028, data: 0.003) G_GAN: 1.283 G_L1: 36.295 D_real: 0.136 D_fake: 0.300 \n",
      "(epoch: 11, iters: 560, time: 0.021, data: 0.003) G_GAN: 4.823 G_L1: 38.238 D_real: 0.085 D_fake: 0.022 \n",
      "End of epoch 11 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 176, time: 0.024, data: 0.003) G_GAN: 3.185 G_L1: 40.766 D_real: 0.091 D_fake: 0.130 \n",
      "(epoch: 12, iters: 576, time: 0.024, data: 0.003) G_GAN: 2.831 G_L1: 40.650 D_real: 0.095 D_fake: 0.143 \n",
      "End of epoch 12 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 192, time: 0.024, data: 0.003) G_GAN: 1.996 G_L1: 32.795 D_real: 4.472 D_fake: 0.012 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 13, iters: 592, time: 0.025, data: 0.003) G_GAN: 4.441 G_L1: 30.826 D_real: 0.032 D_fake: 1.577 \n",
      "saving the latest model (epoch 13, total_iters 10000)\n",
      "End of epoch 13 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 208, time: 0.025, data: 0.003) G_GAN: 3.147 G_L1: 32.624 D_real: 0.137 D_fake: 0.083 \n",
      "(epoch: 14, iters: 608, time: 0.021, data: 0.003) G_GAN: 3.140 G_L1: 37.390 D_real: 0.642 D_fake: 0.022 \n",
      "End of epoch 14 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 15, iters: 224, time: 0.025, data: 0.003) G_GAN: 2.771 G_L1: 38.646 D_real: 0.604 D_fake: 0.122 \n",
      "(epoch: 15, iters: 624, time: 0.023, data: 0.004) G_GAN: 4.535 G_L1: 38.731 D_real: 0.115 D_fake: 0.012 \n",
      "saving the model at the end of epoch 15, iters 11760\n",
      "End of epoch 15 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 16, iters: 240, time: 0.027, data: 0.003) G_GAN: 1.995 G_L1: 37.005 D_real: 0.017 D_fake: 0.613 \n",
      "(epoch: 16, iters: 640, time: 0.021, data: 0.004) G_GAN: 2.318 G_L1: 33.326 D_real: 0.694 D_fake: 0.019 \n",
      "End of epoch 16 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 17, iters: 256, time: 0.024, data: 0.003) G_GAN: 1.308 G_L1: 39.548 D_real: 0.173 D_fake: 0.202 \n",
      "(epoch: 17, iters: 656, time: 0.025, data: 0.003) G_GAN: 3.052 G_L1: 33.344 D_real: 0.710 D_fake: 0.021 \n",
      "End of epoch 17 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 18, iters: 272, time: 0.026, data: 0.003) G_GAN: 3.105 G_L1: 39.777 D_real: 0.053 D_fake: 0.206 \n",
      "(epoch: 18, iters: 672, time: 0.027, data: 0.003) G_GAN: 1.871 G_L1: 36.763 D_real: 0.191 D_fake: 0.223 \n",
      "End of epoch 18 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 19, iters: 288, time: 0.028, data: 0.004) G_GAN: 1.609 G_L1: 34.145 D_real: 0.605 D_fake: 0.998 \n",
      "(epoch: 19, iters: 688, time: 0.022, data: 0.003) G_GAN: 0.272 G_L1: 36.494 D_real: 1.061 D_fake: 0.166 \n",
      "End of epoch 19 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 20, iters: 304, time: 0.024, data: 0.003) G_GAN: 3.524 G_L1: 35.941 D_real: 0.042 D_fake: 0.087 \n",
      "(epoch: 20, iters: 704, time: 0.021, data: 0.003) G_GAN: 2.085 G_L1: 37.427 D_real: 0.011 D_fake: 0.271 \n",
      "saving the model at the end of epoch 20, iters 15680\n",
      "End of epoch 20 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 21, iters: 320, time: 0.024, data: 0.003) G_GAN: 2.629 G_L1: 38.913 D_real: 0.229 D_fake: 1.107 \n",
      "(epoch: 21, iters: 720, time: 0.021, data: 0.003) G_GAN: 3.442 G_L1: 32.845 D_real: 0.100 D_fake: 0.086 \n",
      "End of epoch 21 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 22, iters: 336, time: 0.024, data: 0.003) G_GAN: 2.365 G_L1: 36.646 D_real: 0.162 D_fake: 0.166 \n",
      "(epoch: 22, iters: 736, time: 0.021, data: 0.003) G_GAN: 1.234 G_L1: 33.735 D_real: 0.866 D_fake: 0.097 \n",
      "End of epoch 22 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 23, iters: 352, time: 0.024, data: 0.002) G_GAN: 0.560 G_L1: 40.520 D_real: 1.350 D_fake: 0.062 \n",
      "(epoch: 23, iters: 752, time: 0.025, data: 0.003) G_GAN: 2.986 G_L1: 37.696 D_real: 0.152 D_fake: 0.082 \n",
      "End of epoch 23 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 24, iters: 368, time: 0.025, data: 0.003) G_GAN: 2.905 G_L1: 37.438 D_real: 0.008 D_fake: 0.130 \n",
      "(epoch: 24, iters: 768, time: 0.021, data: 0.003) G_GAN: 2.539 G_L1: 30.977 D_real: 0.099 D_fake: 0.045 \n",
      "End of epoch 24 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 25, iters: 384, time: 0.025, data: 0.003) G_GAN: 3.595 G_L1: 35.692 D_real: 0.317 D_fake: 0.021 \n",
      "(epoch: 25, iters: 784, time: 0.016, data: 0.003) G_GAN: 4.248 G_L1: 44.048 D_real: 0.002 D_fake: 1.388 \n",
      "saving the model at the end of epoch 25, iters 19600\n",
      "End of epoch 25 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 26, iters: 400, time: 0.025, data: 0.183) G_GAN: 0.307 G_L1: 33.444 D_real: 0.655 D_fake: 0.150 \n",
      "saving the latest model (epoch 26, total_iters 20000)\n",
      "End of epoch 26 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 27, iters: 16, time: 0.016, data: 0.004) G_GAN: 0.566 G_L1: 36.282 D_real: 1.029 D_fake: 0.124 \n",
      "(epoch: 27, iters: 416, time: 0.021, data: 0.004) G_GAN: 2.162 G_L1: 37.282 D_real: 0.582 D_fake: 0.973 \n",
      "End of epoch 27 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 28, iters: 32, time: 0.024, data: 0.003) G_GAN: 2.690 G_L1: 34.616 D_real: 0.041 D_fake: 0.518 \n",
      "(epoch: 28, iters: 432, time: 0.021, data: 0.002) G_GAN: 2.998 G_L1: 31.051 D_real: 0.328 D_fake: 0.079 \n",
      "End of epoch 28 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 29, iters: 48, time: 0.024, data: 0.003) G_GAN: 2.273 G_L1: 32.786 D_real: 0.252 D_fake: 0.111 \n",
      "(epoch: 29, iters: 448, time: 0.023, data: 0.003) G_GAN: 0.637 G_L1: 32.852 D_real: 0.864 D_fake: 0.121 \n",
      "End of epoch 29 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 30, iters: 64, time: 0.025, data: 0.003) G_GAN: 2.178 G_L1: 34.001 D_real: 0.279 D_fake: 0.070 \n",
      "(epoch: 30, iters: 464, time: 0.021, data: 0.004) G_GAN: 2.568 G_L1: 33.687 D_real: 0.010 D_fake: 0.372 \n",
      "saving the model at the end of epoch 30, iters 23520\n",
      "End of epoch 30 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 31, iters: 80, time: 0.027, data: 0.003) G_GAN: 3.472 G_L1: 32.514 D_real: 0.229 D_fake: 0.034 \n",
      "(epoch: 31, iters: 480, time: 0.025, data: 0.002) G_GAN: 2.106 G_L1: 37.006 D_real: 0.046 D_fake: 0.494 \n",
      "End of epoch 31 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 32, iters: 96, time: 0.025, data: 0.003) G_GAN: 2.531 G_L1: 39.542 D_real: 0.009 D_fake: 0.333 \n",
      "(epoch: 32, iters: 496, time: 0.021, data: 0.002) G_GAN: 3.639 G_L1: 32.305 D_real: 0.097 D_fake: 0.142 \n",
      "End of epoch 32 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 33, iters: 112, time: 0.025, data: 0.003) G_GAN: 2.213 G_L1: 30.298 D_real: 0.322 D_fake: 0.454 \n",
      "(epoch: 33, iters: 512, time: 0.021, data: 0.002) G_GAN: 2.286 G_L1: 34.623 D_real: 0.028 D_fake: 0.333 \n",
      "End of epoch 33 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 34, iters: 128, time: 0.025, data: 0.003) G_GAN: 0.664 G_L1: 38.221 D_real: 1.265 D_fake: 0.205 \n",
      "(epoch: 34, iters: 528, time: 0.021, data: 0.003) G_GAN: 2.700 G_L1: 38.688 D_real: 0.078 D_fake: 0.344 \n",
      "End of epoch 34 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 35, iters: 144, time: 0.025, data: 0.003) G_GAN: 2.344 G_L1: 31.832 D_real: 0.377 D_fake: 0.219 \n",
      "(epoch: 35, iters: 544, time: 0.021, data: 0.002) G_GAN: 1.874 G_L1: 40.324 D_real: 0.598 D_fake: 0.103 \n",
      "saving the model at the end of epoch 35, iters 27440\n",
      "End of epoch 35 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 36, iters: 160, time: 0.025, data: 0.003) G_GAN: 0.883 G_L1: 34.911 D_real: 0.664 D_fake: 0.537 \n",
      "(epoch: 36, iters: 560, time: 0.026, data: 0.004) G_GAN: 3.774 G_L1: 37.092 D_real: 0.028 D_fake: 0.069 \n",
      "End of epoch 36 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 37, iters: 176, time: 0.025, data: 0.003) G_GAN: 2.653 G_L1: 35.834 D_real: 0.250 D_fake: 0.201 \n",
      "(epoch: 37, iters: 576, time: 0.021, data: 0.003) G_GAN: 2.239 G_L1: 43.116 D_real: 0.008 D_fake: 0.765 \n",
      "End of epoch 37 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 38, iters: 192, time: 0.025, data: 0.003) G_GAN: 2.415 G_L1: 37.177 D_real: 0.083 D_fake: 0.789 \n",
      "(epoch: 38, iters: 592, time: 0.021, data: 0.003) G_GAN: 1.771 G_L1: 40.131 D_real: 0.200 D_fake: 0.514 \n",
      "End of epoch 38 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 39, iters: 208, time: 0.026, data: 0.003) G_GAN: 1.631 G_L1: 30.190 D_real: 2.736 D_fake: 0.059 \n",
      "saving the latest model (epoch 39, total_iters 30000)\n",
      "(epoch: 39, iters: 608, time: 0.025, data: 0.003) G_GAN: 1.154 G_L1: 35.299 D_real: 0.758 D_fake: 0.062 \n",
      "End of epoch 39 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 40, iters: 224, time: 0.028, data: 0.003) G_GAN: 2.236 G_L1: 35.257 D_real: 0.434 D_fake: 0.097 \n",
      "(epoch: 40, iters: 624, time: 0.024, data: 0.003) G_GAN: 1.878 G_L1: 30.784 D_real: 0.540 D_fake: 0.058 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model at the end of epoch 40, iters 31360\n",
      "End of epoch 40 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 41, iters: 240, time: 0.027, data: 0.005) G_GAN: 0.568 G_L1: 34.324 D_real: 1.039 D_fake: 0.111 \n",
      "(epoch: 41, iters: 640, time: 0.026, data: 0.005) G_GAN: 2.890 G_L1: 35.431 D_real: 0.041 D_fake: 1.090 \n",
      "End of epoch 41 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 42, iters: 256, time: 0.027, data: 0.003) G_GAN: 0.568 G_L1: 31.287 D_real: 1.264 D_fake: 0.124 \n",
      "(epoch: 42, iters: 656, time: 0.022, data: 0.003) G_GAN: 2.399 G_L1: 37.320 D_real: 0.011 D_fake: 0.793 \n",
      "End of epoch 42 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 43, iters: 272, time: 0.025, data: 0.003) G_GAN: 0.625 G_L1: 29.061 D_real: 0.671 D_fake: 0.440 \n",
      "(epoch: 43, iters: 672, time: 0.022, data: 0.003) G_GAN: 1.727 G_L1: 34.074 D_real: 0.001 D_fake: 0.877 \n",
      "End of epoch 43 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 44, iters: 288, time: 0.026, data: 0.003) G_GAN: 2.753 G_L1: 40.012 D_real: 0.011 D_fake: 0.295 \n",
      "(epoch: 44, iters: 688, time: 0.021, data: 0.003) G_GAN: 0.521 G_L1: 30.915 D_real: 0.640 D_fake: 0.588 \n",
      "End of epoch 44 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 45, iters: 304, time: 0.026, data: 0.003) G_GAN: 2.362 G_L1: 29.398 D_real: 0.004 D_fake: 0.649 \n",
      "(epoch: 45, iters: 704, time: 0.021, data: 0.003) G_GAN: 2.428 G_L1: 34.421 D_real: 0.004 D_fake: 1.865 \n",
      "saving the model at the end of epoch 45, iters 35280\n",
      "End of epoch 45 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 46, iters: 320, time: 0.026, data: 0.003) G_GAN: 1.330 G_L1: 28.262 D_real: 0.357 D_fake: 0.109 \n",
      "(epoch: 46, iters: 720, time: 0.029, data: 0.004) G_GAN: 1.028 G_L1: 36.456 D_real: 0.335 D_fake: 0.249 \n",
      "End of epoch 46 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 47, iters: 336, time: 0.026, data: 0.003) G_GAN: 2.714 G_L1: 32.258 D_real: 0.289 D_fake: 0.083 \n",
      "(epoch: 47, iters: 736, time: 0.021, data: 0.003) G_GAN: 1.042 G_L1: 32.099 D_real: 1.118 D_fake: 0.099 \n",
      "End of epoch 47 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 48, iters: 352, time: 0.026, data: 0.003) G_GAN: 1.421 G_L1: 30.454 D_real: 0.849 D_fake: 0.104 \n",
      "(epoch: 48, iters: 752, time: 0.021, data: 0.003) G_GAN: 1.798 G_L1: 31.907 D_real: 0.013 D_fake: 0.717 \n",
      "End of epoch 48 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 49, iters: 368, time: 0.027, data: 0.003) G_GAN: 2.964 G_L1: 33.243 D_real: 0.036 D_fake: 0.286 \n",
      "(epoch: 49, iters: 768, time: 0.021, data: 0.003) G_GAN: 0.973 G_L1: 30.841 D_real: 2.089 D_fake: 0.039 \n",
      "End of epoch 49 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 50, iters: 384, time: 0.027, data: 0.003) G_GAN: 2.813 G_L1: 40.986 D_real: 0.004 D_fake: 0.225 \n",
      "(epoch: 50, iters: 784, time: 0.016, data: 0.003) G_GAN: 0.816 G_L1: 29.988 D_real: 0.620 D_fake: 0.337 \n",
      "saving the model at the end of epoch 50, iters 39200\n",
      "End of epoch 50 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 51, iters: 400, time: 0.027, data: 0.206) G_GAN: 2.000 G_L1: 32.690 D_real: 0.307 D_fake: 2.143 \n",
      "End of epoch 51 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 52, iters: 16, time: 0.018, data: 0.003) G_GAN: 0.589 G_L1: 29.935 D_real: 1.635 D_fake: 0.149 \n",
      "saving the latest model (epoch 52, total_iters 40000)\n",
      "(epoch: 52, iters: 416, time: 0.021, data: 0.005) G_GAN: 3.312 G_L1: 34.712 D_real: 0.240 D_fake: 0.092 \n",
      "End of epoch 52 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 53, iters: 32, time: 0.027, data: 0.003) G_GAN: 2.054 G_L1: 29.420 D_real: 0.059 D_fake: 0.143 \n",
      "(epoch: 53, iters: 432, time: 0.021, data: 0.002) G_GAN: 2.175 G_L1: 34.374 D_real: 1.444 D_fake: 0.048 \n",
      "End of epoch 53 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 54, iters: 48, time: 0.027, data: 0.003) G_GAN: 2.938 G_L1: 39.147 D_real: 0.022 D_fake: 0.148 \n",
      "(epoch: 54, iters: 448, time: 0.026, data: 0.003) G_GAN: 1.888 G_L1: 38.552 D_real: 0.005 D_fake: 0.816 \n",
      "End of epoch 54 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 55, iters: 64, time: 0.026, data: 0.003) G_GAN: 2.209 G_L1: 34.268 D_real: 0.029 D_fake: 0.190 \n",
      "(epoch: 55, iters: 464, time: 0.021, data: 0.005) G_GAN: 1.236 G_L1: 36.932 D_real: 0.436 D_fake: 0.396 \n",
      "saving the model at the end of epoch 55, iters 43120\n",
      "End of epoch 55 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 56, iters: 80, time: 0.027, data: 0.003) G_GAN: 2.451 G_L1: 37.480 D_real: 0.006 D_fake: 0.263 \n",
      "(epoch: 56, iters: 480, time: 0.023, data: 0.002) G_GAN: 0.545 G_L1: 31.565 D_real: 2.742 D_fake: 0.206 \n",
      "End of epoch 56 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 57, iters: 96, time: 0.028, data: 0.003) G_GAN: 1.887 G_L1: 28.627 D_real: 2.307 D_fake: 0.038 \n",
      "(epoch: 57, iters: 496, time: 0.022, data: 0.002) G_GAN: 2.639 G_L1: 34.559 D_real: 0.010 D_fake: 0.521 \n",
      "End of epoch 57 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 58, iters: 112, time: 0.027, data: 0.003) G_GAN: 0.250 G_L1: 33.273 D_real: 1.023 D_fake: 0.172 \n",
      "(epoch: 58, iters: 512, time: 0.021, data: 0.002) G_GAN: 2.444 G_L1: 43.823 D_real: 0.045 D_fake: 0.214 \n",
      "End of epoch 58 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 59, iters: 128, time: 0.032, data: 0.003) G_GAN: 2.651 G_L1: 30.263 D_real: 0.121 D_fake: 0.345 \n",
      "(epoch: 59, iters: 528, time: 0.027, data: 0.003) G_GAN: 3.032 G_L1: 44.659 D_real: 0.004 D_fake: 0.272 \n",
      "End of epoch 59 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 60, iters: 144, time: 0.027, data: 0.003) G_GAN: 0.479 G_L1: 31.595 D_real: 2.102 D_fake: 0.715 \n",
      "(epoch: 60, iters: 544, time: 0.021, data: 0.002) G_GAN: 1.485 G_L1: 36.585 D_real: 0.079 D_fake: 0.354 \n",
      "saving the model at the end of epoch 60, iters 47040\n",
      "End of epoch 60 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 61, iters: 160, time: 0.027, data: 0.003) G_GAN: 1.451 G_L1: 34.013 D_real: 0.648 D_fake: 0.335 \n",
      "(epoch: 61, iters: 560, time: 0.021, data: 0.003) G_GAN: 2.020 G_L1: 31.060 D_real: 0.447 D_fake: 0.053 \n",
      "End of epoch 61 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 62, iters: 176, time: 0.028, data: 0.003) G_GAN: 2.470 G_L1: 29.110 D_real: 0.824 D_fake: 0.040 \n",
      "(epoch: 62, iters: 576, time: 0.021, data: 0.003) G_GAN: 3.118 G_L1: 33.092 D_real: 0.072 D_fake: 0.095 \n",
      "End of epoch 62 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 63, iters: 192, time: 0.027, data: 0.003) G_GAN: 1.043 G_L1: 28.362 D_real: 0.661 D_fake: 0.664 \n",
      "(epoch: 63, iters: 592, time: 0.021, data: 0.003) G_GAN: 1.584 G_L1: 25.887 D_real: 1.578 D_fake: 0.083 \n",
      "End of epoch 63 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 64, iters: 208, time: 0.027, data: 0.003) G_GAN: 1.461 G_L1: 32.924 D_real: 0.201 D_fake: 0.709 \n",
      "(epoch: 64, iters: 608, time: 0.028, data: 0.006) G_GAN: 1.697 G_L1: 30.119 D_real: 0.220 D_fake: 0.788 \n",
      "saving the latest model (epoch 64, total_iters 50000)\n",
      "End of epoch 64 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 65, iters: 224, time: 0.028, data: 0.003) G_GAN: 2.327 G_L1: 30.141 D_real: 0.044 D_fake: 0.233 \n",
      "(epoch: 65, iters: 624, time: 0.021, data: 0.003) G_GAN: 1.737 G_L1: 27.209 D_real: 0.392 D_fake: 0.126 \n",
      "saving the model at the end of epoch 65, iters 50960\n",
      "End of epoch 65 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 66, iters: 240, time: 0.028, data: 0.003) G_GAN: 2.504 G_L1: 36.179 D_real: 0.048 D_fake: 0.229 \n",
      "(epoch: 66, iters: 640, time: 0.024, data: 0.003) G_GAN: 2.426 G_L1: 36.346 D_real: 0.010 D_fake: 0.346 \n",
      "End of epoch 66 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 67, iters: 256, time: 0.029, data: 0.003) G_GAN: 2.224 G_L1: 29.743 D_real: 0.202 D_fake: 0.085 \n",
      "(epoch: 67, iters: 656, time: 0.022, data: 0.003) G_GAN: 2.754 G_L1: 38.306 D_real: 0.077 D_fake: 0.387 \n",
      "End of epoch 67 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 68, iters: 272, time: 0.028, data: 0.003) G_GAN: 2.059 G_L1: 31.713 D_real: 0.073 D_fake: 0.253 \n",
      "(epoch: 68, iters: 672, time: 0.021, data: 0.003) G_GAN: 3.101 G_L1: 34.418 D_real: 0.118 D_fake: 0.755 \n",
      "End of epoch 68 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 69, iters: 288, time: 0.032, data: 0.003) G_GAN: 3.035 G_L1: 31.412 D_real: 0.027 D_fake: 0.939 \n",
      "(epoch: 69, iters: 688, time: 0.027, data: 0.003) G_GAN: 2.909 G_L1: 28.360 D_real: 0.119 D_fake: 0.993 \n",
      "End of epoch 69 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 70, iters: 304, time: 0.029, data: 0.003) G_GAN: 2.272 G_L1: 36.192 D_real: 0.090 D_fake: 0.252 \n",
      "(epoch: 70, iters: 704, time: 0.023, data: 0.003) G_GAN: 2.915 G_L1: 28.712 D_real: 0.036 D_fake: 0.171 \n",
      "saving the model at the end of epoch 70, iters 54880\n",
      "End of epoch 70 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 71, iters: 320, time: 0.028, data: 0.003) G_GAN: 0.670 G_L1: 33.390 D_real: 0.769 D_fake: 0.553 \n",
      "(epoch: 71, iters: 720, time: 0.024, data: 0.003) G_GAN: 1.705 G_L1: 34.055 D_real: 0.206 D_fake: 0.900 \n",
      "End of epoch 71 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 72, iters: 336, time: 0.028, data: 0.003) G_GAN: 2.170 G_L1: 31.158 D_real: 0.011 D_fake: 0.266 \n",
      "(epoch: 72, iters: 736, time: 0.021, data: 0.003) G_GAN: 2.344 G_L1: 32.933 D_real: 0.019 D_fake: 0.368 \n",
      "End of epoch 72 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 73, iters: 352, time: 0.031, data: 0.003) G_GAN: 3.072 G_L1: 34.793 D_real: 0.010 D_fake: 1.861 \n",
      "(epoch: 73, iters: 752, time: 0.021, data: 0.003) G_GAN: 1.974 G_L1: 35.856 D_real: 0.090 D_fake: 0.172 \n",
      "End of epoch 73 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 74, iters: 368, time: 0.030, data: 0.004) G_GAN: 2.272 G_L1: 31.323 D_real: 0.026 D_fake: 0.172 \n",
      "(epoch: 74, iters: 768, time: 0.031, data: 0.003) G_GAN: 1.377 G_L1: 29.996 D_real: 0.454 D_fake: 0.259 \n",
      "End of epoch 74 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 75, iters: 384, time: 0.031, data: 0.003) G_GAN: 2.249 G_L1: 29.773 D_real: 0.262 D_fake: 0.076 \n",
      "(epoch: 75, iters: 784, time: 0.018, data: 0.004) G_GAN: 2.454 G_L1: 25.708 D_real: 0.002 D_fake: 1.231 \n",
      "saving the model at the end of epoch 75, iters 58800\n",
      "End of epoch 75 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 76, iters: 400, time: 0.030, data: 0.270) G_GAN: 1.008 G_L1: 26.539 D_real: 0.840 D_fake: 0.224 \n",
      "End of epoch 76 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 77, iters: 16, time: 0.031, data: 0.004) G_GAN: 2.227 G_L1: 36.802 D_real: 0.059 D_fake: 0.601 \n",
      "(epoch: 77, iters: 416, time: 0.031, data: 0.002) G_GAN: 1.532 G_L1: 32.732 D_real: 0.383 D_fake: 0.191 \n",
      "saving the latest model (epoch 77, total_iters 60000)\n",
      "End of epoch 77 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 78, iters: 32, time: 0.032, data: 0.004) G_GAN: 2.687 G_L1: 29.836 D_real: 0.032 D_fake: 0.876 \n",
      "(epoch: 78, iters: 432, time: 0.022, data: 0.003) G_GAN: 3.227 G_L1: 34.861 D_real: 0.109 D_fake: 1.368 \n",
      "End of epoch 78 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 79, iters: 48, time: 0.030, data: 0.003) G_GAN: 3.082 G_L1: 37.723 D_real: 0.024 D_fake: 0.421 \n",
      "(epoch: 79, iters: 448, time: 0.022, data: 0.004) G_GAN: 1.503 G_L1: 29.881 D_real: 0.278 D_fake: 0.317 \n",
      "End of epoch 79 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 80, iters: 64, time: 0.032, data: 0.003) G_GAN: 2.003 G_L1: 29.287 D_real: 0.635 D_fake: 0.694 \n",
      "(epoch: 80, iters: 464, time: 0.026, data: 0.007) G_GAN: 1.190 G_L1: 33.144 D_real: 1.125 D_fake: 0.166 \n",
      "saving the model at the end of epoch 80, iters 62720\n",
      "End of epoch 80 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 81, iters: 80, time: 0.030, data: 0.004) G_GAN: 1.424 G_L1: 37.775 D_real: 0.518 D_fake: 0.202 \n",
      "(epoch: 81, iters: 480, time: 0.026, data: 0.003) G_GAN: 0.445 G_L1: 37.401 D_real: 1.107 D_fake: 0.186 \n",
      "End of epoch 81 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 82, iters: 96, time: 0.029, data: 0.003) G_GAN: 1.721 G_L1: 28.239 D_real: 0.288 D_fake: 0.226 \n",
      "(epoch: 82, iters: 496, time: 0.030, data: 0.003) G_GAN: 2.921 G_L1: 36.924 D_real: 0.039 D_fake: 0.896 \n",
      "End of epoch 82 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 83, iters: 112, time: 0.031, data: 0.004) G_GAN: 3.156 G_L1: 27.987 D_real: 0.010 D_fake: 0.155 \n",
      "(epoch: 83, iters: 512, time: 0.022, data: 0.002) G_GAN: 0.932 G_L1: 24.567 D_real: 0.377 D_fake: 0.354 \n",
      "End of epoch 83 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 84, iters: 128, time: 0.035, data: 0.003) G_GAN: 2.277 G_L1: 33.339 D_real: 0.198 D_fake: 0.295 \n",
      "(epoch: 84, iters: 528, time: 0.021, data: 0.004) G_GAN: 2.216 G_L1: 38.247 D_real: 0.003 D_fake: 0.329 \n",
      "End of epoch 84 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 85, iters: 144, time: 0.031, data: 0.004) G_GAN: 2.117 G_L1: 30.870 D_real: 0.251 D_fake: 1.067 \n",
      "(epoch: 85, iters: 544, time: 0.024, data: 0.003) G_GAN: 3.240 G_L1: 30.374 D_real: 0.044 D_fake: 0.070 \n",
      "saving the model at the end of epoch 85, iters 66640\n",
      "End of epoch 85 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 86, iters: 160, time: 0.029, data: 0.006) G_GAN: 1.367 G_L1: 28.350 D_real: 1.083 D_fake: 0.200 \n",
      "(epoch: 86, iters: 560, time: 0.021, data: 0.003) G_GAN: 1.753 G_L1: 33.041 D_real: 0.214 D_fake: 0.895 \n",
      "End of epoch 86 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 87, iters: 176, time: 0.030, data: 0.003) G_GAN: 1.077 G_L1: 30.129 D_real: 0.775 D_fake: 0.160 \n",
      "(epoch: 87, iters: 576, time: 0.030, data: 0.003) G_GAN: 1.548 G_L1: 29.349 D_real: 0.586 D_fake: 0.143 \n",
      "End of epoch 87 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 88, iters: 192, time: 0.030, data: 0.003) G_GAN: 1.717 G_L1: 30.492 D_real: 0.498 D_fake: 0.178 \n",
      "(epoch: 88, iters: 592, time: 0.021, data: 0.003) G_GAN: 1.799 G_L1: 31.421 D_real: 0.036 D_fake: 0.428 \n",
      "End of epoch 88 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 89, iters: 208, time: 0.029, data: 0.003) G_GAN: 2.028 G_L1: 26.148 D_real: 0.270 D_fake: 0.148 \n",
      "(epoch: 89, iters: 608, time: 0.022, data: 0.003) G_GAN: 2.030 G_L1: 35.002 D_real: 0.240 D_fake: 0.500 \n",
      "End of epoch 89 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 90, iters: 224, time: 0.031, data: 0.003) G_GAN: 1.625 G_L1: 26.430 D_real: 0.215 D_fake: 0.504 \n",
      "saving the latest model (epoch 90, total_iters 70000)\n",
      "(epoch: 90, iters: 624, time: 0.022, data: 0.003) G_GAN: 2.030 G_L1: 31.734 D_real: 0.197 D_fake: 0.280 \n",
      "saving the model at the end of epoch 90, iters 70560\n",
      "End of epoch 90 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 91, iters: 240, time: 0.033, data: 0.004) G_GAN: 3.466 G_L1: 35.541 D_real: 0.071 D_fake: 0.075 \n",
      "(epoch: 91, iters: 640, time: 0.021, data: 0.003) G_GAN: 1.182 G_L1: 36.120 D_real: 0.291 D_fake: 0.652 \n",
      "End of epoch 91 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 92, iters: 256, time: 0.029, data: 0.003) G_GAN: 1.855 G_L1: 33.458 D_real: 0.079 D_fake: 0.871 \n",
      "(epoch: 92, iters: 656, time: 0.029, data: 0.003) G_GAN: 0.633 G_L1: 26.770 D_real: 0.847 D_fake: 0.161 \n",
      "End of epoch 92 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 93, iters: 272, time: 0.029, data: 0.003) G_GAN: 0.932 G_L1: 27.365 D_real: 0.898 D_fake: 0.087 \n",
      "(epoch: 93, iters: 672, time: 0.021, data: 0.003) G_GAN: 2.269 G_L1: 31.781 D_real: 0.035 D_fake: 1.527 \n",
      "End of epoch 93 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 94, iters: 288, time: 0.029, data: 0.003) G_GAN: 2.607 G_L1: 31.294 D_real: 0.059 D_fake: 1.677 \n",
      "(epoch: 94, iters: 688, time: 0.021, data: 0.003) G_GAN: 1.151 G_L1: 28.036 D_real: 2.101 D_fake: 0.107 \n",
      "End of epoch 94 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 95, iters: 304, time: 0.029, data: 0.003) G_GAN: 0.760 G_L1: 29.311 D_real: 0.925 D_fake: 0.170 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 95, iters: 704, time: 0.021, data: 0.003) G_GAN: 2.427 G_L1: 29.695 D_real: 0.003 D_fake: 0.444 \n",
      "saving the model at the end of epoch 95, iters 74480\n",
      "End of epoch 95 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 96, iters: 320, time: 0.029, data: 0.003) G_GAN: 1.468 G_L1: 33.299 D_real: 0.194 D_fake: 0.506 \n",
      "(epoch: 96, iters: 720, time: 0.021, data: 0.003) G_GAN: 0.551 G_L1: 29.379 D_real: 0.808 D_fake: 0.160 \n",
      "End of epoch 96 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 97, iters: 336, time: 0.030, data: 0.003) G_GAN: 3.369 G_L1: 35.541 D_real: 0.095 D_fake: 1.513 \n",
      "(epoch: 97, iters: 736, time: 0.036, data: 0.003) G_GAN: 1.427 G_L1: 29.010 D_real: 0.375 D_fake: 0.247 \n",
      "End of epoch 97 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 98, iters: 352, time: 0.029, data: 0.004) G_GAN: 1.309 G_L1: 31.034 D_real: 0.407 D_fake: 0.645 \n",
      "(epoch: 98, iters: 752, time: 0.022, data: 0.003) G_GAN: 0.638 G_L1: 30.024 D_real: 1.184 D_fake: 0.587 \n",
      "End of epoch 98 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 99, iters: 368, time: 0.031, data: 0.003) G_GAN: 2.521 G_L1: 31.148 D_real: 0.162 D_fake: 0.306 \n",
      "(epoch: 99, iters: 768, time: 0.022, data: 0.003) G_GAN: 2.353 G_L1: 32.767 D_real: 0.022 D_fake: 0.407 \n",
      "End of epoch 99 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0001980\n",
      "(epoch: 100, iters: 384, time: 0.031, data: 0.003) G_GAN: 1.378 G_L1: 28.805 D_real: 1.094 D_fake: 0.096 \n",
      "(epoch: 100, iters: 784, time: 0.016, data: 0.003) G_GAN: 2.527 G_L1: 25.765 D_real: 0.004 D_fake: 0.577 \n",
      "saving the model at the end of epoch 100, iters 78400\n",
      "End of epoch 100 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001980 -> 0.0001960\n",
      "(epoch: 101, iters: 400, time: 0.030, data: 0.192) G_GAN: 0.415 G_L1: 27.357 D_real: 1.335 D_fake: 0.105 \n",
      "End of epoch 101 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001960 -> 0.0001941\n",
      "(epoch: 102, iters: 16, time: 0.021, data: 0.009) G_GAN: 3.233 G_L1: 30.703 D_real: 0.011 D_fake: 0.149 \n",
      "(epoch: 102, iters: 416, time: 0.021, data: 0.002) G_GAN: 2.340 G_L1: 29.016 D_real: 0.177 D_fake: 0.136 \n",
      "End of epoch 102 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001941 -> 0.0001921\n",
      "(epoch: 103, iters: 32, time: 0.030, data: 0.003) G_GAN: 1.628 G_L1: 33.559 D_real: 0.117 D_fake: 1.081 \n",
      "saving the latest model (epoch 103, total_iters 80000)\n",
      "(epoch: 103, iters: 432, time: 0.022, data: 0.003) G_GAN: 0.937 G_L1: 29.855 D_real: 1.132 D_fake: 0.266 \n",
      "End of epoch 103 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001921 -> 0.0001901\n",
      "(epoch: 104, iters: 48, time: 0.030, data: 0.003) G_GAN: 1.246 G_L1: 29.290 D_real: 0.832 D_fake: 0.323 \n",
      "(epoch: 104, iters: 448, time: 0.023, data: 0.003) G_GAN: 2.159 G_L1: 32.684 D_real: 0.215 D_fake: 0.264 \n",
      "End of epoch 104 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001901 -> 0.0001881\n",
      "(epoch: 105, iters: 64, time: 0.034, data: 0.003) G_GAN: 1.192 G_L1: 29.071 D_real: 1.155 D_fake: 0.339 \n",
      "(epoch: 105, iters: 464, time: 0.032, data: 0.004) G_GAN: 1.554 G_L1: 29.700 D_real: 0.410 D_fake: 0.404 \n",
      "saving the model at the end of epoch 105, iters 82320\n",
      "End of epoch 105 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001881 -> 0.0001861\n",
      "(epoch: 106, iters: 80, time: 0.031, data: 0.003) G_GAN: 2.967 G_L1: 29.857 D_real: 0.032 D_fake: 1.331 \n",
      "(epoch: 106, iters: 480, time: 0.021, data: 0.003) G_GAN: 1.660 G_L1: 29.191 D_real: 0.448 D_fake: 0.138 \n",
      "End of epoch 106 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001861 -> 0.0001842\n",
      "(epoch: 107, iters: 96, time: 0.030, data: 0.003) G_GAN: 2.236 G_L1: 31.357 D_real: 0.063 D_fake: 1.272 \n",
      "(epoch: 107, iters: 496, time: 0.021, data: 0.002) G_GAN: 0.903 G_L1: 31.271 D_real: 0.850 D_fake: 0.211 \n",
      "End of epoch 107 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001842 -> 0.0001822\n",
      "(epoch: 108, iters: 112, time: 0.030, data: 0.003) G_GAN: 1.974 G_L1: 28.592 D_real: 0.052 D_fake: 0.387 \n",
      "(epoch: 108, iters: 512, time: 0.022, data: 0.003) G_GAN: 1.586 G_L1: 29.637 D_real: 0.548 D_fake: 0.154 \n",
      "End of epoch 108 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001822 -> 0.0001802\n",
      "(epoch: 109, iters: 128, time: 0.033, data: 0.003) G_GAN: 1.641 G_L1: 34.484 D_real: 0.040 D_fake: 0.894 \n",
      "(epoch: 109, iters: 528, time: 0.022, data: 0.003) G_GAN: 2.347 G_L1: 33.345 D_real: 0.034 D_fake: 0.333 \n",
      "End of epoch 109 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001802 -> 0.0001782\n",
      "(epoch: 110, iters: 144, time: 0.030, data: 0.003) G_GAN: 2.632 G_L1: 28.295 D_real: 0.366 D_fake: 0.074 \n",
      "(epoch: 110, iters: 544, time: 0.035, data: 0.003) G_GAN: 1.454 G_L1: 22.706 D_real: 0.646 D_fake: 0.119 \n",
      "saving the model at the end of epoch 110, iters 86240\n",
      "End of epoch 110 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001782 -> 0.0001762\n",
      "(epoch: 111, iters: 160, time: 0.031, data: 0.003) G_GAN: 2.061 G_L1: 29.058 D_real: 0.320 D_fake: 0.223 \n",
      "(epoch: 111, iters: 560, time: 0.023, data: 0.003) G_GAN: 2.187 G_L1: 27.866 D_real: 0.789 D_fake: 0.089 \n",
      "End of epoch 111 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001762 -> 0.0001743\n",
      "(epoch: 112, iters: 176, time: 0.030, data: 0.003) G_GAN: 2.820 G_L1: 23.216 D_real: 0.174 D_fake: 0.465 \n",
      "(epoch: 112, iters: 576, time: 0.021, data: 0.003) G_GAN: 1.268 G_L1: 26.897 D_real: 0.691 D_fake: 0.256 \n",
      "End of epoch 112 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001743 -> 0.0001723\n",
      "(epoch: 113, iters: 192, time: 0.033, data: 0.003) G_GAN: 2.411 G_L1: 24.334 D_real: 0.520 D_fake: 0.067 \n",
      "(epoch: 113, iters: 592, time: 0.021, data: 0.003) G_GAN: 1.275 G_L1: 28.512 D_real: 0.367 D_fake: 0.331 \n",
      "End of epoch 113 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001723 -> 0.0001703\n",
      "(epoch: 114, iters: 208, time: 0.030, data: 0.003) G_GAN: 2.219 G_L1: 35.347 D_real: 0.521 D_fake: 0.215 \n",
      "(epoch: 114, iters: 608, time: 0.022, data: 0.003) G_GAN: 1.958 G_L1: 27.188 D_real: 0.512 D_fake: 0.249 \n",
      "End of epoch 114 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001703 -> 0.0001683\n",
      "(epoch: 115, iters: 224, time: 0.031, data: 0.003) G_GAN: 2.137 G_L1: 24.905 D_real: 0.051 D_fake: 0.897 \n",
      "(epoch: 115, iters: 624, time: 0.033, data: 0.003) G_GAN: 2.318 G_L1: 26.699 D_real: 0.132 D_fake: 1.259 \n",
      "saving the latest model (epoch 115, total_iters 90000)\n",
      "saving the model at the end of epoch 115, iters 90160\n",
      "End of epoch 115 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001683 -> 0.0001663\n",
      "(epoch: 116, iters: 240, time: 0.030, data: 0.004) G_GAN: 0.479 G_L1: 29.408 D_real: 0.693 D_fake: 0.294 \n",
      "(epoch: 116, iters: 640, time: 0.021, data: 0.003) G_GAN: 1.833 G_L1: 30.949 D_real: 0.081 D_fake: 0.755 \n",
      "End of epoch 116 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001663 -> 0.0001644\n",
      "(epoch: 117, iters: 256, time: 0.031, data: 0.003) G_GAN: 1.602 G_L1: 30.410 D_real: 0.387 D_fake: 0.531 \n",
      "(epoch: 117, iters: 656, time: 0.021, data: 0.003) G_GAN: 0.494 G_L1: 24.475 D_real: 1.040 D_fake: 0.101 \n",
      "End of epoch 117 / 200 \t Time Taken: 9 sec\n",
      "learning rate 0.0001644 -> 0.0001624\n",
      "(epoch: 118, iters: 272, time: 0.030, data: 0.004) G_GAN: 1.690 G_L1: 27.730 D_real: 0.097 D_fake: 0.833 \n",
      "(epoch: 118, iters: 672, time: 0.021, data: 0.003) G_GAN: 0.912 G_L1: 30.102 D_real: 0.796 D_fake: 0.312 \n",
      "End of epoch 118 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001624 -> 0.0001604\n",
      "(epoch: 119, iters: 288, time: 0.031, data: 0.003) G_GAN: 0.767 G_L1: 28.860 D_real: 2.574 D_fake: 0.416 \n",
      "(epoch: 119, iters: 688, time: 0.021, data: 0.003) G_GAN: 1.426 G_L1: 24.315 D_real: 0.719 D_fake: 0.276 \n",
      "End of epoch 119 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001604 -> 0.0001584\n",
      "(epoch: 120, iters: 304, time: 0.030, data: 0.003) G_GAN: 1.112 G_L1: 26.498 D_real: 1.045 D_fake: 0.121 \n",
      "(epoch: 120, iters: 704, time: 0.030, data: 0.003) G_GAN: 0.611 G_L1: 35.164 D_real: 0.944 D_fake: 0.417 \n",
      "saving the model at the end of epoch 120, iters 94080\n",
      "End of epoch 120 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001584 -> 0.0001564\n",
      "(epoch: 121, iters: 320, time: 0.035, data: 0.003) G_GAN: 2.363 G_L1: 25.595 D_real: 0.030 D_fake: 1.805 \n",
      "(epoch: 121, iters: 720, time: 0.023, data: 0.003) G_GAN: 2.205 G_L1: 28.906 D_real: 0.168 D_fake: 0.382 \n",
      "End of epoch 121 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001564 -> 0.0001545\n",
      "(epoch: 122, iters: 336, time: 0.032, data: 0.003) G_GAN: 1.315 G_L1: 27.203 D_real: 0.261 D_fake: 0.345 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 122, iters: 736, time: 0.023, data: 0.003) G_GAN: 2.254 G_L1: 31.491 D_real: 0.157 D_fake: 0.879 \n",
      "End of epoch 122 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001545 -> 0.0001525\n",
      "(epoch: 123, iters: 352, time: 0.034, data: 0.003) G_GAN: 1.245 G_L1: 27.130 D_real: 1.854 D_fake: 0.115 \n",
      "(epoch: 123, iters: 752, time: 0.022, data: 0.004) G_GAN: 2.108 G_L1: 33.536 D_real: 0.340 D_fake: 0.226 \n",
      "End of epoch 123 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001525 -> 0.0001505\n",
      "(epoch: 124, iters: 368, time: 0.033, data: 0.004) G_GAN: 1.599 G_L1: 30.728 D_real: 0.213 D_fake: 0.460 \n",
      "(epoch: 124, iters: 768, time: 0.025, data: 0.003) G_GAN: 0.977 G_L1: 25.886 D_real: 0.457 D_fake: 0.332 \n",
      "End of epoch 124 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001505 -> 0.0001485\n",
      "(epoch: 125, iters: 384, time: 0.031, data: 0.003) G_GAN: 1.733 G_L1: 29.444 D_real: 0.256 D_fake: 0.547 \n",
      "(epoch: 125, iters: 784, time: 0.026, data: 0.003) G_GAN: 2.423 G_L1: 27.633 D_real: 0.010 D_fake: 0.960 \n",
      "saving the model at the end of epoch 125, iters 98000\n",
      "End of epoch 125 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001485 -> 0.0001465\n",
      "(epoch: 126, iters: 400, time: 0.037, data: 0.199) G_GAN: 2.269 G_L1: 29.153 D_real: 0.066 D_fake: 0.392 \n",
      "End of epoch 126 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001465 -> 0.0001446\n",
      "(epoch: 127, iters: 16, time: 0.022, data: 0.003) G_GAN: 1.410 G_L1: 27.825 D_real: 0.559 D_fake: 0.327 \n",
      "(epoch: 127, iters: 416, time: 0.022, data: 0.004) G_GAN: 2.354 G_L1: 30.008 D_real: 0.128 D_fake: 0.284 \n",
      "End of epoch 127 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001446 -> 0.0001426\n",
      "(epoch: 128, iters: 32, time: 0.033, data: 0.003) G_GAN: 1.826 G_L1: 32.534 D_real: 0.539 D_fake: 0.096 \n",
      "(epoch: 128, iters: 432, time: 0.032, data: 0.002) G_GAN: 0.620 G_L1: 27.752 D_real: 1.322 D_fake: 0.583 \n",
      "saving the latest model (epoch 128, total_iters 100000)\n",
      "End of epoch 128 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001426 -> 0.0001406\n",
      "(epoch: 129, iters: 48, time: 0.031, data: 0.004) G_GAN: 1.223 G_L1: 31.705 D_real: 0.187 D_fake: 1.453 \n",
      "(epoch: 129, iters: 448, time: 0.022, data: 0.003) G_GAN: 2.116 G_L1: 27.091 D_real: 0.323 D_fake: 0.175 \n",
      "End of epoch 129 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001406 -> 0.0001386\n",
      "(epoch: 130, iters: 64, time: 0.031, data: 0.003) G_GAN: 1.134 G_L1: 25.529 D_real: 0.392 D_fake: 0.382 \n",
      "(epoch: 130, iters: 464, time: 0.024, data: 0.004) G_GAN: 1.705 G_L1: 28.182 D_real: 0.063 D_fake: 0.886 \n",
      "saving the model at the end of epoch 130, iters 101920\n",
      "End of epoch 130 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001386 -> 0.0001366\n",
      "(epoch: 131, iters: 80, time: 0.031, data: 0.003) G_GAN: 1.352 G_L1: 25.047 D_real: 0.445 D_fake: 0.298 \n",
      "(epoch: 131, iters: 480, time: 0.023, data: 0.002) G_GAN: 1.353 G_L1: 25.942 D_real: 0.516 D_fake: 0.224 \n",
      "End of epoch 131 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001366 -> 0.0001347\n",
      "(epoch: 132, iters: 96, time: 0.033, data: 0.003) G_GAN: 2.689 G_L1: 28.256 D_real: 0.021 D_fake: 0.244 \n",
      "(epoch: 132, iters: 496, time: 0.022, data: 0.002) G_GAN: 1.487 G_L1: 26.103 D_real: 0.517 D_fake: 0.519 \n",
      "End of epoch 132 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001347 -> 0.0001327\n",
      "(epoch: 133, iters: 112, time: 0.032, data: 0.003) G_GAN: 1.910 G_L1: 25.058 D_real: 0.141 D_fake: 0.258 \n",
      "(epoch: 133, iters: 512, time: 0.032, data: 0.003) G_GAN: 0.759 G_L1: 29.202 D_real: 0.666 D_fake: 0.445 \n",
      "End of epoch 133 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001327 -> 0.0001307\n",
      "(epoch: 134, iters: 128, time: 0.032, data: 0.003) G_GAN: 0.481 G_L1: 24.053 D_real: 1.129 D_fake: 0.414 \n",
      "(epoch: 134, iters: 528, time: 0.023, data: 0.005) G_GAN: 1.227 G_L1: 31.666 D_real: 1.678 D_fake: 0.101 \n",
      "End of epoch 134 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001307 -> 0.0001287\n",
      "(epoch: 135, iters: 144, time: 0.035, data: 0.003) G_GAN: 1.415 G_L1: 25.066 D_real: 0.255 D_fake: 0.682 \n",
      "(epoch: 135, iters: 544, time: 0.021, data: 0.003) G_GAN: 1.600 G_L1: 31.392 D_real: 0.331 D_fake: 0.241 \n",
      "saving the model at the end of epoch 135, iters 105840\n",
      "End of epoch 135 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001287 -> 0.0001267\n",
      "(epoch: 136, iters: 160, time: 0.036, data: 0.003) G_GAN: 1.116 G_L1: 27.838 D_real: 0.661 D_fake: 0.854 \n",
      "(epoch: 136, iters: 560, time: 0.021, data: 0.004) G_GAN: 3.256 G_L1: 26.252 D_real: 0.043 D_fake: 0.188 \n",
      "End of epoch 136 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001267 -> 0.0001248\n",
      "(epoch: 137, iters: 176, time: 0.035, data: 0.004) G_GAN: 1.810 G_L1: 27.425 D_real: 0.291 D_fake: 0.133 \n",
      "(epoch: 137, iters: 576, time: 0.021, data: 0.003) G_GAN: 0.940 G_L1: 26.755 D_real: 1.172 D_fake: 0.218 \n",
      "End of epoch 137 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001248 -> 0.0001228\n",
      "(epoch: 138, iters: 192, time: 0.033, data: 0.005) G_GAN: 1.109 G_L1: 28.422 D_real: 0.255 D_fake: 0.901 \n",
      "(epoch: 138, iters: 592, time: 0.037, data: 0.004) G_GAN: 2.057 G_L1: 32.780 D_real: 0.459 D_fake: 0.156 \n",
      "End of epoch 138 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001228 -> 0.0001208\n",
      "(epoch: 139, iters: 208, time: 0.034, data: 0.003) G_GAN: 1.814 G_L1: 25.995 D_real: 0.454 D_fake: 0.120 \n",
      "(epoch: 139, iters: 608, time: 0.023, data: 0.003) G_GAN: 1.585 G_L1: 27.946 D_real: 0.227 D_fake: 0.181 \n",
      "End of epoch 139 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001208 -> 0.0001188\n",
      "(epoch: 140, iters: 224, time: 0.040, data: 0.003) G_GAN: 0.284 G_L1: 24.193 D_real: 2.057 D_fake: 0.331 \n",
      "(epoch: 140, iters: 624, time: 0.022, data: 0.004) G_GAN: 1.681 G_L1: 24.255 D_real: 0.163 D_fake: 0.334 \n",
      "saving the model at the end of epoch 140, iters 109760\n",
      "End of epoch 140 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001188 -> 0.0001168\n",
      "(epoch: 141, iters: 240, time: 0.036, data: 0.003) G_GAN: 1.041 G_L1: 27.418 D_real: 1.093 D_fake: 0.343 \n",
      "saving the latest model (epoch 141, total_iters 110000)\n",
      "(epoch: 141, iters: 640, time: 0.023, data: 0.003) G_GAN: 1.925 G_L1: 24.766 D_real: 0.027 D_fake: 0.300 \n",
      "End of epoch 141 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001168 -> 0.0001149\n",
      "(epoch: 142, iters: 256, time: 0.037, data: 0.003) G_GAN: 2.146 G_L1: 29.111 D_real: 0.234 D_fake: 0.539 \n",
      "(epoch: 142, iters: 656, time: 0.024, data: 0.004) G_GAN: 1.657 G_L1: 23.747 D_real: 0.309 D_fake: 0.485 \n",
      "End of epoch 142 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001149 -> 0.0001129\n",
      "(epoch: 143, iters: 272, time: 0.038, data: 0.003) G_GAN: 1.254 G_L1: 26.041 D_real: 1.862 D_fake: 0.084 \n",
      "(epoch: 143, iters: 672, time: 0.039, data: 0.003) G_GAN: 1.737 G_L1: 28.209 D_real: 0.026 D_fake: 0.571 \n",
      "End of epoch 143 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001129 -> 0.0001109\n",
      "(epoch: 144, iters: 288, time: 0.037, data: 0.004) G_GAN: 1.161 G_L1: 26.924 D_real: 0.135 D_fake: 0.396 \n",
      "(epoch: 144, iters: 688, time: 0.022, data: 0.003) G_GAN: 1.609 G_L1: 27.872 D_real: 0.267 D_fake: 0.301 \n",
      "End of epoch 144 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001109 -> 0.0001089\n",
      "(epoch: 145, iters: 304, time: 0.034, data: 0.004) G_GAN: 1.263 G_L1: 22.730 D_real: 1.586 D_fake: 0.158 \n",
      "(epoch: 145, iters: 704, time: 0.023, data: 0.003) G_GAN: 1.287 G_L1: 27.737 D_real: 0.235 D_fake: 0.692 \n",
      "saving the model at the end of epoch 145, iters 113680\n",
      "End of epoch 145 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001089 -> 0.0001069\n",
      "(epoch: 146, iters: 320, time: 0.033, data: 0.004) G_GAN: 1.803 G_L1: 25.177 D_real: 0.323 D_fake: 0.447 \n",
      "(epoch: 146, iters: 720, time: 0.024, data: 0.003) G_GAN: 1.604 G_L1: 25.592 D_real: 0.302 D_fake: 0.230 \n",
      "End of epoch 146 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001069 -> 0.0001050\n",
      "(epoch: 147, iters: 336, time: 0.034, data: 0.003) G_GAN: 1.768 G_L1: 25.375 D_real: 0.314 D_fake: 0.479 \n",
      "(epoch: 147, iters: 736, time: 0.024, data: 0.003) G_GAN: 2.019 G_L1: 24.999 D_real: 0.078 D_fake: 0.326 \n",
      "End of epoch 147 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001050 -> 0.0001030\n",
      "(epoch: 148, iters: 352, time: 0.034, data: 0.003) G_GAN: 1.729 G_L1: 31.074 D_real: 0.823 D_fake: 0.097 \n",
      "(epoch: 148, iters: 752, time: 0.038, data: 0.003) G_GAN: 2.124 G_L1: 23.802 D_real: 0.400 D_fake: 0.125 \n",
      "End of epoch 148 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001030 -> 0.0001010\n",
      "(epoch: 149, iters: 368, time: 0.033, data: 0.003) G_GAN: 2.114 G_L1: 26.007 D_real: 0.075 D_fake: 0.454 \n",
      "(epoch: 149, iters: 768, time: 0.022, data: 0.003) G_GAN: 0.551 G_L1: 24.109 D_real: 2.472 D_fake: 0.261 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 149 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001010 -> 0.0000990\n",
      "(epoch: 150, iters: 384, time: 0.033, data: 0.003) G_GAN: 1.853 G_L1: 26.616 D_real: 0.322 D_fake: 0.379 \n",
      "(epoch: 150, iters: 784, time: 0.016, data: 0.003) G_GAN: 2.066 G_L1: 27.863 D_real: 0.003 D_fake: 0.170 \n",
      "saving the model at the end of epoch 150, iters 117600\n",
      "End of epoch 150 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000990 -> 0.0000970\n",
      "(epoch: 151, iters: 400, time: 0.032, data: 0.191) G_GAN: 1.306 G_L1: 25.725 D_real: 0.133 D_fake: 0.950 \n",
      "End of epoch 151 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000970 -> 0.0000950\n",
      "(epoch: 152, iters: 16, time: 0.024, data: 0.003) G_GAN: 0.656 G_L1: 25.997 D_real: 0.826 D_fake: 0.205 \n",
      "(epoch: 152, iters: 416, time: 0.022, data: 0.002) G_GAN: 1.581 G_L1: 25.600 D_real: 0.584 D_fake: 0.206 \n",
      "End of epoch 152 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000950 -> 0.0000931\n",
      "(epoch: 153, iters: 32, time: 0.036, data: 0.003) G_GAN: 1.421 G_L1: 22.764 D_real: 0.274 D_fake: 0.623 \n",
      "(epoch: 153, iters: 432, time: 0.021, data: 0.003) G_GAN: 0.957 G_L1: 23.633 D_real: 1.483 D_fake: 0.276 \n",
      "End of epoch 153 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000931 -> 0.0000911\n",
      "(epoch: 154, iters: 48, time: 0.033, data: 0.003) G_GAN: 1.759 G_L1: 27.452 D_real: 0.354 D_fake: 0.299 \n",
      "saving the latest model (epoch 154, total_iters 120000)\n",
      "(epoch: 154, iters: 448, time: 0.024, data: 0.002) G_GAN: 1.973 G_L1: 27.144 D_real: 0.423 D_fake: 0.186 \n",
      "End of epoch 154 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000911 -> 0.0000891\n",
      "(epoch: 155, iters: 64, time: 0.033, data: 0.003) G_GAN: 0.914 G_L1: 24.155 D_real: 0.163 D_fake: 1.332 \n",
      "(epoch: 155, iters: 464, time: 0.023, data: 0.003) G_GAN: 1.876 G_L1: 29.985 D_real: 1.079 D_fake: 0.090 \n",
      "saving the model at the end of epoch 155, iters 121520\n",
      "End of epoch 155 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000891 -> 0.0000871\n",
      "(epoch: 156, iters: 80, time: 0.037, data: 0.003) G_GAN: 1.589 G_L1: 24.119 D_real: 0.271 D_fake: 0.334 \n",
      "(epoch: 156, iters: 480, time: 0.034, data: 0.003) G_GAN: 3.272 G_L1: 28.575 D_real: 0.138 D_fake: 0.043 \n",
      "End of epoch 156 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000871 -> 0.0000851\n",
      "(epoch: 157, iters: 96, time: 0.041, data: 0.003) G_GAN: 2.356 G_L1: 25.696 D_real: 0.039 D_fake: 0.426 \n",
      "(epoch: 157, iters: 496, time: 0.022, data: 0.003) G_GAN: 1.825 G_L1: 24.742 D_real: 0.272 D_fake: 0.403 \n",
      "End of epoch 157 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000851 -> 0.0000832\n",
      "(epoch: 158, iters: 112, time: 0.035, data: 0.003) G_GAN: 1.650 G_L1: 21.726 D_real: 1.388 D_fake: 0.065 \n",
      "(epoch: 158, iters: 512, time: 0.024, data: 0.003) G_GAN: 2.040 G_L1: 23.905 D_real: 0.059 D_fake: 0.412 \n",
      "End of epoch 158 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000832 -> 0.0000812\n",
      "(epoch: 159, iters: 128, time: 0.035, data: 0.003) G_GAN: 2.190 G_L1: 27.612 D_real: 0.160 D_fake: 0.157 \n",
      "(epoch: 159, iters: 528, time: 0.021, data: 0.003) G_GAN: 0.997 G_L1: 20.179 D_real: 0.672 D_fake: 0.520 \n",
      "End of epoch 159 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000812 -> 0.0000792\n",
      "(epoch: 160, iters: 144, time: 0.037, data: 0.002) G_GAN: 1.622 G_L1: 22.162 D_real: 0.056 D_fake: 0.469 \n",
      "(epoch: 160, iters: 544, time: 0.023, data: 0.002) G_GAN: 1.294 G_L1: 28.898 D_real: 0.952 D_fake: 0.371 \n",
      "saving the model at the end of epoch 160, iters 125440\n",
      "End of epoch 160 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000792 -> 0.0000772\n",
      "(epoch: 161, iters: 160, time: 0.035, data: 0.003) G_GAN: 2.104 G_L1: 25.927 D_real: 0.185 D_fake: 0.103 \n",
      "(epoch: 161, iters: 560, time: 0.036, data: 0.003) G_GAN: 1.661 G_L1: 29.571 D_real: 0.387 D_fake: 0.379 \n",
      "End of epoch 161 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000772 -> 0.0000752\n",
      "(epoch: 162, iters: 176, time: 0.033, data: 0.003) G_GAN: 2.324 G_L1: 26.160 D_real: 0.007 D_fake: 0.287 \n",
      "(epoch: 162, iters: 576, time: 0.022, data: 0.003) G_GAN: 1.433 G_L1: 28.567 D_real: 0.811 D_fake: 0.294 \n",
      "End of epoch 162 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000752 -> 0.0000733\n",
      "(epoch: 163, iters: 192, time: 0.034, data: 0.003) G_GAN: 1.774 G_L1: 23.317 D_real: 0.297 D_fake: 0.163 \n",
      "(epoch: 163, iters: 592, time: 0.021, data: 0.003) G_GAN: 0.494 G_L1: 27.321 D_real: 1.421 D_fake: 0.384 \n",
      "End of epoch 163 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000733 -> 0.0000713\n",
      "(epoch: 164, iters: 208, time: 0.032, data: 0.003) G_GAN: 1.838 G_L1: 24.828 D_real: 0.076 D_fake: 0.287 \n",
      "(epoch: 164, iters: 608, time: 0.022, data: 0.003) G_GAN: 1.654 G_L1: 21.237 D_real: 0.150 D_fake: 0.507 \n",
      "End of epoch 164 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000713 -> 0.0000693\n",
      "(epoch: 165, iters: 224, time: 0.037, data: 0.003) G_GAN: 2.270 G_L1: 21.789 D_real: 0.291 D_fake: 0.169 \n",
      "(epoch: 165, iters: 624, time: 0.022, data: 0.003) G_GAN: 1.460 G_L1: 24.057 D_real: 0.406 D_fake: 0.908 \n",
      "saving the model at the end of epoch 165, iters 129360\n",
      "End of epoch 165 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000693 -> 0.0000673\n",
      "(epoch: 166, iters: 240, time: 0.034, data: 0.003) G_GAN: 1.832 G_L1: 23.834 D_real: 0.091 D_fake: 0.331 \n",
      "(epoch: 166, iters: 640, time: 0.034, data: 0.003) G_GAN: 1.521 G_L1: 27.309 D_real: 0.891 D_fake: 0.165 \n",
      "saving the latest model (epoch 166, total_iters 130000)\n",
      "End of epoch 166 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000673 -> 0.0000653\n",
      "(epoch: 167, iters: 256, time: 0.033, data: 0.003) G_GAN: 1.524 G_L1: 25.971 D_real: 0.720 D_fake: 0.204 \n",
      "(epoch: 167, iters: 656, time: 0.025, data: 0.003) G_GAN: 0.805 G_L1: 23.373 D_real: 1.582 D_fake: 0.284 \n",
      "End of epoch 167 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000653 -> 0.0000634\n",
      "(epoch: 168, iters: 272, time: 0.035, data: 0.003) G_GAN: 1.652 G_L1: 24.878 D_real: 0.001 D_fake: 0.302 \n",
      "(epoch: 168, iters: 672, time: 0.022, data: 0.003) G_GAN: 1.855 G_L1: 22.056 D_real: 0.158 D_fake: 0.179 \n",
      "End of epoch 168 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000634 -> 0.0000614\n",
      "(epoch: 169, iters: 288, time: 0.045, data: 0.004) G_GAN: 1.728 G_L1: 28.740 D_real: 0.106 D_fake: 0.537 \n",
      "(epoch: 169, iters: 688, time: 0.021, data: 0.005) G_GAN: 1.561 G_L1: 26.797 D_real: 0.001 D_fake: 0.322 \n",
      "End of epoch 169 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000614 -> 0.0000594\n",
      "(epoch: 170, iters: 304, time: 0.041, data: 0.003) G_GAN: 1.991 G_L1: 23.874 D_real: 0.274 D_fake: 0.359 \n",
      "(epoch: 170, iters: 704, time: 0.023, data: 0.004) G_GAN: 2.031 G_L1: 26.365 D_real: 0.304 D_fake: 0.250 \n",
      "saving the model at the end of epoch 170, iters 133280\n",
      "End of epoch 170 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000594 -> 0.0000574\n",
      "(epoch: 171, iters: 320, time: 0.039, data: 0.003) G_GAN: 2.684 G_L1: 21.326 D_real: 0.087 D_fake: 0.179 \n",
      "(epoch: 171, iters: 720, time: 0.036, data: 0.004) G_GAN: 1.433 G_L1: 25.998 D_real: 0.218 D_fake: 0.874 \n",
      "End of epoch 171 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000574 -> 0.0000554\n",
      "(epoch: 172, iters: 336, time: 0.042, data: 0.004) G_GAN: 1.674 G_L1: 24.256 D_real: 0.476 D_fake: 0.227 \n",
      "(epoch: 172, iters: 736, time: 0.021, data: 0.003) G_GAN: 1.832 G_L1: 24.412 D_real: 0.036 D_fake: 0.441 \n",
      "End of epoch 172 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000554 -> 0.0000535\n",
      "(epoch: 173, iters: 352, time: 0.035, data: 0.003) G_GAN: 1.443 G_L1: 23.256 D_real: 0.238 D_fake: 0.427 \n",
      "(epoch: 173, iters: 752, time: 0.022, data: 0.003) G_GAN: 1.960 G_L1: 23.530 D_real: 0.135 D_fake: 0.202 \n",
      "End of epoch 173 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000535 -> 0.0000515\n",
      "(epoch: 174, iters: 368, time: 0.035, data: 0.003) G_GAN: 2.436 G_L1: 25.172 D_real: 0.606 D_fake: 0.080 \n",
      "(epoch: 174, iters: 768, time: 0.022, data: 0.003) G_GAN: 2.323 G_L1: 26.422 D_real: 0.342 D_fake: 0.099 \n",
      "End of epoch 174 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000515 -> 0.0000495\n",
      "(epoch: 175, iters: 384, time: 0.034, data: 0.003) G_GAN: 2.499 G_L1: 24.369 D_real: 0.026 D_fake: 0.163 \n",
      "(epoch: 175, iters: 784, time: 0.016, data: 0.003) G_GAN: 2.038 G_L1: 24.269 D_real: 0.110 D_fake: 0.598 \n",
      "saving the model at the end of epoch 175, iters 137200\n",
      "End of epoch 175 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000495 -> 0.0000475\n",
      "(epoch: 176, iters: 400, time: 0.037, data: 0.192) G_GAN: 2.901 G_L1: 22.274 D_real: 0.000 D_fake: 0.174 \n",
      "End of epoch 176 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000475 -> 0.0000455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 177, iters: 16, time: 0.025, data: 0.003) G_GAN: 1.703 G_L1: 21.025 D_real: 1.054 D_fake: 0.129 \n",
      "(epoch: 177, iters: 416, time: 0.022, data: 0.004) G_GAN: 1.780 G_L1: 22.205 D_real: 0.207 D_fake: 0.205 \n",
      "End of epoch 177 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000455 -> 0.0000436\n",
      "(epoch: 178, iters: 32, time: 0.033, data: 0.003) G_GAN: 1.564 G_L1: 24.146 D_real: 0.107 D_fake: 0.268 \n",
      "(epoch: 178, iters: 432, time: 0.022, data: 0.005) G_GAN: 0.925 G_L1: 23.868 D_real: 1.353 D_fake: 0.469 \n",
      "End of epoch 178 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000436 -> 0.0000416\n",
      "(epoch: 179, iters: 48, time: 0.033, data: 0.002) G_GAN: 2.575 G_L1: 24.169 D_real: 0.559 D_fake: 0.071 \n",
      "(epoch: 179, iters: 448, time: 0.034, data: 0.002) G_GAN: 1.416 G_L1: 25.732 D_real: 0.040 D_fake: 0.908 \n",
      "saving the latest model (epoch 179, total_iters 140000)\n",
      "End of epoch 179 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000416 -> 0.0000396\n",
      "(epoch: 180, iters: 64, time: 0.037, data: 0.003) G_GAN: 1.303 G_L1: 25.547 D_real: 0.291 D_fake: 0.457 \n",
      "(epoch: 180, iters: 464, time: 0.022, data: 0.004) G_GAN: 2.289 G_L1: 24.592 D_real: 0.009 D_fake: 0.174 \n",
      "saving the model at the end of epoch 180, iters 141120\n",
      "End of epoch 180 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000396 -> 0.0000376\n",
      "(epoch: 181, iters: 80, time: 0.034, data: 0.004) G_GAN: 2.333 G_L1: 25.240 D_real: 0.070 D_fake: 0.156 \n",
      "(epoch: 181, iters: 480, time: 0.021, data: 0.004) G_GAN: 2.214 G_L1: 25.147 D_real: 0.031 D_fake: 0.176 \n",
      "End of epoch 181 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000376 -> 0.0000356\n",
      "(epoch: 182, iters: 96, time: 0.034, data: 0.003) G_GAN: 2.399 G_L1: 21.671 D_real: 0.025 D_fake: 0.193 \n",
      "(epoch: 182, iters: 496, time: 0.022, data: 0.003) G_GAN: 2.394 G_L1: 22.056 D_real: 0.332 D_fake: 0.104 \n",
      "End of epoch 182 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000356 -> 0.0000337\n",
      "(epoch: 183, iters: 112, time: 0.035, data: 0.003) G_GAN: 2.003 G_L1: 26.455 D_real: 0.005 D_fake: 0.200 \n",
      "(epoch: 183, iters: 512, time: 0.021, data: 0.003) G_GAN: 2.446 G_L1: 24.411 D_real: 0.004 D_fake: 0.115 \n",
      "End of epoch 183 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000337 -> 0.0000317\n",
      "(epoch: 184, iters: 128, time: 0.038, data: 0.003) G_GAN: 1.688 G_L1: 25.038 D_real: 0.638 D_fake: 0.295 \n",
      "(epoch: 184, iters: 528, time: 0.034, data: 0.003) G_GAN: 2.150 G_L1: 23.318 D_real: 0.759 D_fake: 0.113 \n",
      "End of epoch 184 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000317 -> 0.0000297\n",
      "(epoch: 185, iters: 144, time: 0.035, data: 0.003) G_GAN: 2.451 G_L1: 23.671 D_real: 0.002 D_fake: 0.186 \n",
      "(epoch: 185, iters: 544, time: 0.021, data: 0.003) G_GAN: 1.518 G_L1: 25.214 D_real: 0.971 D_fake: 0.222 \n",
      "saving the model at the end of epoch 185, iters 145040\n",
      "End of epoch 185 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000297 -> 0.0000277\n",
      "(epoch: 186, iters: 160, time: 0.035, data: 0.003) G_GAN: 1.228 G_L1: 22.061 D_real: 0.190 D_fake: 0.690 \n",
      "(epoch: 186, iters: 560, time: 0.022, data: 0.003) G_GAN: 1.801 G_L1: 23.026 D_real: 0.033 D_fake: 0.254 \n",
      "End of epoch 186 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000277 -> 0.0000257\n",
      "(epoch: 187, iters: 176, time: 0.038, data: 0.003) G_GAN: 1.148 G_L1: 21.271 D_real: 0.081 D_fake: 0.884 \n",
      "(epoch: 187, iters: 576, time: 0.022, data: 0.003) G_GAN: 1.564 G_L1: 25.720 D_real: 0.474 D_fake: 0.340 \n",
      "End of epoch 187 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000257 -> 0.0000238\n",
      "(epoch: 188, iters: 192, time: 0.037, data: 0.003) G_GAN: 1.989 G_L1: 19.826 D_real: 0.289 D_fake: 0.156 \n",
      "(epoch: 188, iters: 592, time: 0.022, data: 0.003) G_GAN: 2.096 G_L1: 19.953 D_real: 0.099 D_fake: 0.120 \n",
      "End of epoch 188 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000238 -> 0.0000218\n",
      "(epoch: 189, iters: 208, time: 0.037, data: 0.003) G_GAN: 1.734 G_L1: 21.037 D_real: 0.013 D_fake: 0.319 \n",
      "(epoch: 189, iters: 608, time: 0.041, data: 0.003) G_GAN: 1.519 G_L1: 26.921 D_real: 0.138 D_fake: 0.351 \n",
      "End of epoch 189 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000218 -> 0.0000198\n",
      "(epoch: 190, iters: 224, time: 0.044, data: 0.004) G_GAN: 1.778 G_L1: 23.945 D_real: 0.743 D_fake: 0.136 \n",
      "(epoch: 190, iters: 624, time: 0.021, data: 0.005) G_GAN: 1.812 G_L1: 22.241 D_real: 0.202 D_fake: 0.195 \n",
      "saving the model at the end of epoch 190, iters 148960\n",
      "End of epoch 190 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000198 -> 0.0000178\n",
      "(epoch: 191, iters: 240, time: 0.042, data: 0.003) G_GAN: 2.013 G_L1: 27.713 D_real: 0.101 D_fake: 0.206 \n",
      "(epoch: 191, iters: 640, time: 0.022, data: 0.003) G_GAN: 1.701 G_L1: 21.921 D_real: 0.370 D_fake: 0.242 \n",
      "End of epoch 191 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000178 -> 0.0000158\n",
      "(epoch: 192, iters: 256, time: 0.035, data: 0.004) G_GAN: 1.268 G_L1: 21.128 D_real: 0.636 D_fake: 0.400 \n",
      "saving the latest model (epoch 192, total_iters 150000)\n",
      "(epoch: 192, iters: 656, time: 0.022, data: 0.003) G_GAN: 1.813 G_L1: 21.070 D_real: 0.476 D_fake: 0.181 \n",
      "End of epoch 192 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000158 -> 0.0000139\n",
      "(epoch: 193, iters: 272, time: 0.034, data: 0.003) G_GAN: 1.942 G_L1: 22.326 D_real: 0.796 D_fake: 0.171 \n",
      "(epoch: 193, iters: 672, time: 0.022, data: 0.003) G_GAN: 2.554 G_L1: 23.981 D_real: 0.026 D_fake: 0.100 \n",
      "End of epoch 193 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000139 -> 0.0000119\n",
      "(epoch: 194, iters: 288, time: 0.039, data: 0.003) G_GAN: 2.456 G_L1: 24.903 D_real: 0.003 D_fake: 0.107 \n",
      "(epoch: 194, iters: 688, time: 0.035, data: 0.006) G_GAN: 1.939 G_L1: 22.615 D_real: 0.029 D_fake: 0.189 \n",
      "End of epoch 194 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000119 -> 0.0000099\n",
      "(epoch: 195, iters: 304, time: 0.035, data: 0.003) G_GAN: 1.609 G_L1: 23.516 D_real: 0.290 D_fake: 0.277 \n",
      "(epoch: 195, iters: 704, time: 0.021, data: 0.004) G_GAN: 2.321 G_L1: 23.515 D_real: 0.235 D_fake: 0.118 \n",
      "saving the model at the end of epoch 195, iters 152880\n",
      "End of epoch 195 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000099 -> 0.0000079\n",
      "(epoch: 196, iters: 320, time: 0.035, data: 0.003) G_GAN: 2.168 G_L1: 23.275 D_real: 0.000 D_fake: 0.157 \n",
      "(epoch: 196, iters: 720, time: 0.022, data: 0.003) G_GAN: 1.601 G_L1: 22.804 D_real: 0.516 D_fake: 0.263 \n",
      "End of epoch 196 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000079 -> 0.0000059\n",
      "(epoch: 197, iters: 336, time: 0.048, data: 0.004) G_GAN: 2.377 G_L1: 20.392 D_real: 0.024 D_fake: 0.112 \n",
      "(epoch: 197, iters: 736, time: 0.021, data: 0.004) G_GAN: 2.723 G_L1: 23.666 D_real: 0.001 D_fake: 0.085 \n",
      "End of epoch 197 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000059 -> 0.0000040\n",
      "(epoch: 198, iters: 352, time: 0.038, data: 0.003) G_GAN: 2.801 G_L1: 23.490 D_real: 0.174 D_fake: 0.076 \n",
      "(epoch: 198, iters: 752, time: 0.022, data: 0.003) G_GAN: 2.367 G_L1: 21.385 D_real: 0.160 D_fake: 0.118 \n",
      "End of epoch 198 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000040 -> 0.0000020\n",
      "(epoch: 199, iters: 368, time: 0.043, data: 0.006) G_GAN: 2.185 G_L1: 22.808 D_real: 0.034 D_fake: 0.146 \n",
      "(epoch: 199, iters: 768, time: 0.040, data: 0.009) G_GAN: 2.033 G_L1: 23.730 D_real: 0.011 D_fake: 0.168 \n",
      "End of epoch 199 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000020 -> 0.0000000\n",
      "(epoch: 200, iters: 384, time: 0.041, data: 0.003) G_GAN: 2.150 G_L1: 27.548 D_real: 0.000 D_fake: 0.145 \n",
      "(epoch: 200, iters: 784, time: 0.016, data: 0.003) G_GAN: 0.997 G_L1: 27.850 D_real: 0.000 D_fake: 0.539 \n",
      "saving the model at the end of epoch 200, iters 156800\n",
      "End of epoch 200 / 200 \t Time Taken: 11 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/footulcer_multiclass_256 --name footulcer_multiclass_256 --model pix2pix --gpu_ids 0 --display_id 0 --batch_size 16 --netD n_layers --n_layers_D 4 --direction BtoA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_multiclass_256\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: footulcer_multiclass_256      \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 776                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/footulcer_multiclass_256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/footulcer_multiclass_256/test_latest\n",
      "processing (0000)-th image... ['./datasets/footulcer_multiclass_256/test/0020126b06a719c36fed196c2c71f2f0_0.png']\n",
      "processing (0005)-th image... ['./datasets/footulcer_multiclass_256/test/00d87e85e220404257d75a9c6d574e0b_0.png']\n",
      "processing (0010)-th image... ['./datasets/footulcer_multiclass_256/test/0272003ec882522e7bec012aac93cc26_2.png']\n",
      "processing (0015)-th image... ['./datasets/footulcer_multiclass_256/test/030f458bd12ad589f1c2d6ae4cc245e0_0.png']\n",
      "processing (0020)-th image... ['./datasets/footulcer_multiclass_256/test/03a29338d44c41efd1856034029cb9cb_1.png']\n",
      "processing (0025)-th image... ['./datasets/footulcer_multiclass_256/test/045069bee69b9a6b457a69c564589895_1.png']\n",
      "processing (0030)-th image... ['./datasets/footulcer_multiclass_256/test/051d7c68ec44d127707d220a2f8a6c09_0.png']\n",
      "processing (0035)-th image... ['./datasets/footulcer_multiclass_256/test/06d5643601a23d986ce7a24ca4bb2152_0.png']\n",
      "processing (0040)-th image... ['./datasets/footulcer_multiclass_256/test/07cd49d4077e7392d36501f291706ddb_1.png']\n",
      "processing (0045)-th image... ['./datasets/footulcer_multiclass_256/test/095919973cde59672f21c88850a4aa09_0.png']\n",
      "processing (0050)-th image... ['./datasets/footulcer_multiclass_256/test/0abb9eba5adac0db89364735c88860e4_0.png']\n",
      "processing (0055)-th image... ['./datasets/footulcer_multiclass_256/test/0b53daf814304dd0d74efb2fa052ef23_0.png']\n",
      "processing (0060)-th image... ['./datasets/footulcer_multiclass_256/test/0c2ef774c755a57b93845eed12e8029f_0.png']\n",
      "processing (0065)-th image... ['./datasets/footulcer_multiclass_256/test/0daab7087d28c5b067c891d170e302d3_0.png']\n",
      "processing (0070)-th image... ['./datasets/footulcer_multiclass_256/test/0e32f889d3f1b3f205184e4a78ea377e_0.png']\n",
      "processing (0075)-th image... ['./datasets/footulcer_multiclass_256/test/0f42ca66d0a67e868683aab958c70b70_0.png']\n",
      "processing (0080)-th image... ['./datasets/footulcer_multiclass_256/test/1154874ea6703d6d9fd28b81f9184684_0.png']\n",
      "processing (0085)-th image... ['./datasets/footulcer_multiclass_256/test/120ad0065480d41edfb123498de494d5_0.png']\n",
      "processing (0090)-th image... ['./datasets/footulcer_multiclass_256/test/160fcc9963c057d0a4754c8a39f87f1c_0.png']\n",
      "processing (0095)-th image... ['./datasets/footulcer_multiclass_256/test/167b854fa564c1b27e1950f82cb551e0_0.png']\n",
      "processing (0100)-th image... ['./datasets/footulcer_multiclass_256/test/18d60d8c820b5487f59dce1237f31f47_1.png']\n",
      "processing (0105)-th image... ['./datasets/footulcer_multiclass_256/test/19f4e5a4e1330b6cc307fc35c625f197_0.png']\n",
      "processing (0110)-th image... ['./datasets/footulcer_multiclass_256/test/1ad70e82589acbd9638b6e465366a7fe_0.png']\n",
      "processing (0115)-th image... ['./datasets/footulcer_multiclass_256/test/1bae2d0ed76c241570479a4490f9c2a5_0.png']\n",
      "processing (0120)-th image... ['./datasets/footulcer_multiclass_256/test/1c700b5e74caa409d88eb73957906b05_0.png']\n",
      "processing (0125)-th image... ['./datasets/footulcer_multiclass_256/test/1ca743bfb56654b11fca2b038d1cc682_0.png']\n",
      "processing (0130)-th image... ['./datasets/footulcer_multiclass_256/test/1d97ce42081182a66ace139dbcd83273_0.png']\n",
      "processing (0135)-th image... ['./datasets/footulcer_multiclass_256/test/1dbb00d92741863fcc6451afd48daf31_2.png']\n",
      "processing (0140)-th image... ['./datasets/footulcer_multiclass_256/test/1e172e50acdceb692355ba080e2146cc_1.png']\n",
      "processing (0145)-th image... ['./datasets/footulcer_multiclass_256/test/1ec8cc951c3bb8fdd532fa847c2f90d9_0.png']\n",
      "processing (0150)-th image... ['./datasets/footulcer_multiclass_256/test/217189be3ad182f170ec0e1b565a1a2a_0.png']\n",
      "processing (0155)-th image... ['./datasets/footulcer_multiclass_256/test/229f9949fc3ca248f91e54b11348e517_0.png']\n",
      "processing (0160)-th image... ['./datasets/footulcer_multiclass_256/test/23789535abbc5f81030070cd45a9cfde_0.png']\n",
      "processing (0165)-th image... ['./datasets/footulcer_multiclass_256/test/24597141d24289747225c61527d97cb4_0.png']\n",
      "processing (0170)-th image... ['./datasets/footulcer_multiclass_256/test/24d033a91d4fa6e1a8143d03229886fd_1.png']\n",
      "processing (0175)-th image... ['./datasets/footulcer_multiclass_256/test/25fbd4751a5aa2f7f5fa5fd4554b70a8_0.png']\n",
      "processing (0180)-th image... ['./datasets/footulcer_multiclass_256/test/26b0e1c37795cfb1b930a593165149c9_2.png']\n",
      "processing (0185)-th image... ['./datasets/footulcer_multiclass_256/test/28d3f7cdb7d3b68029a480498dfbc279_0.png']\n",
      "processing (0190)-th image... ['./datasets/footulcer_multiclass_256/test/29040e0c4889bd33bc4d18426675c6df_3.png']\n",
      "processing (0195)-th image... ['./datasets/footulcer_multiclass_256/test/2941779e77be521b284a6a9867ea5b56_0.png']\n",
      "processing (0200)-th image... ['./datasets/footulcer_multiclass_256/test/29a0841f35c311894f34a6e1fac1245b_0.png']\n",
      "processing (0205)-th image... ['./datasets/footulcer_multiclass_256/test/2a622fc070d8601c5b5ca71fd86f23c1_0.png']\n",
      "processing (0210)-th image... ['./datasets/footulcer_multiclass_256/test/2b76f204fc28ebbe6be635e099feb791_0.png']\n",
      "processing (0215)-th image... ['./datasets/footulcer_multiclass_256/test/2c6c04e7a70a7a5f46ccbdef1f176cb8_0.png']\n",
      "processing (0220)-th image... ['./datasets/footulcer_multiclass_256/test/2e2bc13c6bc904debc7460780a18c886_0.png']\n",
      "processing (0225)-th image... ['./datasets/footulcer_multiclass_256/test/2f1980e5fb29f92227e4dbc65d223c99_0.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0230)-th image... ['./datasets/footulcer_multiclass_256/test/302d6a35b8498b1e57120c3dc277b097_0.png']\n",
      "processing (0235)-th image... ['./datasets/footulcer_multiclass_256/test/32a49d5a9db69d378d35e3f38259730c_0.png']\n",
      "processing (0240)-th image... ['./datasets/footulcer_multiclass_256/test/336e44bfe352195e75636a12fa591d0e_0.png']\n",
      "processing (0245)-th image... ['./datasets/footulcer_multiclass_256/test/34891c5cba00d001b88b5b839a5465a6_0.png']\n",
      "processing (0250)-th image... ['./datasets/footulcer_multiclass_256/test/3582ff9e0a283e437f9fab59dbf14ea4_0.png']\n",
      "processing (0255)-th image... ['./datasets/footulcer_multiclass_256/test/375d35f02627909d4d85f10ecaa59fb8_0.png']\n",
      "processing (0260)-th image... ['./datasets/footulcer_multiclass_256/test/3883a34afe518fa69342d9535029f724_0.png']\n",
      "processing (0265)-th image... ['./datasets/footulcer_multiclass_256/test/3900ade34a1c3ae5071e61635b15c41e_2.png']\n",
      "processing (0270)-th image... ['./datasets/footulcer_multiclass_256/test/39c3a9ffab05344b8f61460e02b94a1e_0.png']\n",
      "processing (0275)-th image... ['./datasets/footulcer_multiclass_256/test/3a880cf13e68b254e13e8ee8d737f7d9_0.png']\n",
      "processing (0280)-th image... ['./datasets/footulcer_multiclass_256/test/3b579e8d9843f801293962cd9dc5cf66_0.png']\n",
      "processing (0285)-th image... ['./datasets/footulcer_multiclass_256/test/3cc16605bf9d9873debeec4fc90999a0_0.png']\n",
      "processing (0290)-th image... ['./datasets/footulcer_multiclass_256/test/3d471880a73b751ffb76906fe7191184_0.png']\n",
      "processing (0295)-th image... ['./datasets/footulcer_multiclass_256/test/3eef4daad81edeb5e367e1c564221d6e_0.png']\n",
      "processing (0300)-th image... ['./datasets/footulcer_multiclass_256/test/405c6fd83be329ebd1f9add6e58def0c_0.png']\n",
      "processing (0305)-th image... ['./datasets/footulcer_multiclass_256/test/41ee08289fc69cb37694df30a64a8fd0_0.png']\n",
      "processing (0310)-th image... ['./datasets/footulcer_multiclass_256/test/42f929bf3341f8a1f04690762786ae49_0.png']\n",
      "processing (0315)-th image... ['./datasets/footulcer_multiclass_256/test/440078c6936219a7a496ebc67228d5d5_0.png']\n",
      "processing (0320)-th image... ['./datasets/footulcer_multiclass_256/test/45fb5f2db8202432f78f9862336cdf14_1.png']\n",
      "processing (0325)-th image... ['./datasets/footulcer_multiclass_256/test/47713ebf42e1606ebb9167b04fc9c937_0.png']\n",
      "processing (0330)-th image... ['./datasets/footulcer_multiclass_256/test/481213086b8ad2a1c15cfbffec5eea98_0.png']\n",
      "processing (0335)-th image... ['./datasets/footulcer_multiclass_256/test/492e076e2b1bba7e8773bfce280a4b96_0.png']\n",
      "processing (0340)-th image... ['./datasets/footulcer_multiclass_256/test/4aba7d3760fc14cf1963e09fe2a591bb_0.png']\n",
      "processing (0345)-th image... ['./datasets/footulcer_multiclass_256/test/4c188ad2db9f8935d319b2ad6007f3a1_1.png']\n",
      "processing (0350)-th image... ['./datasets/footulcer_multiclass_256/test/4d0ae09266e45178c65b2c217d2ccd43_0.png']\n",
      "processing (0355)-th image... ['./datasets/footulcer_multiclass_256/test/4ec3e802c98a70cf04f0f23b0869c1b9_0.png']\n",
      "processing (0360)-th image... ['./datasets/footulcer_multiclass_256/test/4fff394b855d2d3c86469e487132e55c_0.png']\n",
      "processing (0365)-th image... ['./datasets/footulcer_multiclass_256/test/51d7a79d227f81fe4b9f114254c180f9_0.png']\n",
      "processing (0370)-th image... ['./datasets/footulcer_multiclass_256/test/53179510fe106a3768a6789418fc2dcb_0.png']\n",
      "processing (0375)-th image... ['./datasets/footulcer_multiclass_256/test/5492fe099502ce4c418e8d6686fac07d_2.png']\n",
      "processing (0380)-th image... ['./datasets/footulcer_multiclass_256/test/5636e9466f61ac6d2f0ad22f626e55c7_0.png']\n",
      "processing (0385)-th image... ['./datasets/footulcer_multiclass_256/test/56bafc3eafc552f2f0c4568baa31cc83_0.png']\n",
      "processing (0390)-th image... ['./datasets/footulcer_multiclass_256/test/570a4fd65570badcf863addb1c465e9e_0.png']\n",
      "processing (0395)-th image... ['./datasets/footulcer_multiclass_256/test/57cb332cf7723fa2b843bc413c44d328_0.png']\n",
      "processing (0400)-th image... ['./datasets/footulcer_multiclass_256/test/595332a890e442b8f02265bd3c905491_0.png']\n",
      "processing (0405)-th image... ['./datasets/footulcer_multiclass_256/test/5ba3ae56f8359fe0858e7c377c0f851c_0.png']\n",
      "processing (0410)-th image... ['./datasets/footulcer_multiclass_256/test/5c6cbbbd21476ddcd9e65d9af64d3ca0_0.png']\n",
      "processing (0415)-th image... ['./datasets/footulcer_multiclass_256/test/5db20f5af988d46bac432db183d2b2ad_0.png']\n",
      "processing (0420)-th image... ['./datasets/footulcer_multiclass_256/test/5e5942e7ea78db4e9f0a6bdf8304421b_0.png']\n",
      "processing (0425)-th image... ['./datasets/footulcer_multiclass_256/test/5ef13b806c0d5da68c9ba3b3d6ba9021_0.png']\n",
      "processing (0430)-th image... ['./datasets/footulcer_multiclass_256/test/5f48b9f2e78eba692c1de5c8bfb95231_1.png']\n",
      "processing (0435)-th image... ['./datasets/footulcer_multiclass_256/test/6083797b961a5fc82b84d609faebbb0b_0.png']\n",
      "processing (0440)-th image... ['./datasets/footulcer_multiclass_256/test/61dfd31019c941d34b7661056af0a125_0.png']\n",
      "processing (0445)-th image... ['./datasets/footulcer_multiclass_256/test/62a5926e5ed687aa3d4de06ae2ab1ec9_0.png']\n",
      "processing (0450)-th image... ['./datasets/footulcer_multiclass_256/test/6525910e4e101ca0d804423b635844fc_0.png']\n",
      "processing (0455)-th image... ['./datasets/footulcer_multiclass_256/test/667a4eea3933cbb713a966e4bfeda385_0.png']\n",
      "processing (0460)-th image... ['./datasets/footulcer_multiclass_256/test/6823af2c6a6af36150b0c92336beaaf6_0.png']\n",
      "processing (0465)-th image... ['./datasets/footulcer_multiclass_256/test/69fcf456381561c8dacb1f27223661bf_0.png']\n",
      "processing (0470)-th image... ['./datasets/footulcer_multiclass_256/test/6ae0729fa22bba50c7b8aff237cf502b_2.png']\n",
      "processing (0475)-th image... ['./datasets/footulcer_multiclass_256/test/6bcc1caf975bc9701b5610df670cb11f_0.png']\n",
      "processing (0480)-th image... ['./datasets/footulcer_multiclass_256/test/6c58d20b99df1c5eed126bf5e5686696_0.png']\n",
      "processing (0485)-th image... ['./datasets/footulcer_multiclass_256/test/6d19f77c47cc9606c7b8a5de35ee432a_1.png']\n",
      "processing (0490)-th image... ['./datasets/footulcer_multiclass_256/test/6ee9006e981a0fdbd3af39335617fde0_0.png']\n",
      "processing (0495)-th image... ['./datasets/footulcer_multiclass_256/test/70a364cdbff361ee4a7885ceb1792e5d_0.png']\n",
      "processing (0500)-th image... ['./datasets/footulcer_multiclass_256/test/721f045a58f30c133f65a2baab901491_0.png']\n",
      "processing (0505)-th image... ['./datasets/footulcer_multiclass_256/test/73ca74fd4878a32f647035c9d8009b32_0.png']\n",
      "processing (0510)-th image... ['./datasets/footulcer_multiclass_256/test/74ec1ea5ef38de4666d5031d0b9f4c26_0.png']\n",
      "processing (0515)-th image... ['./datasets/footulcer_multiclass_256/test/754479624f175e6635dd8bf1a4ee50d7_2.png']\n",
      "processing (0520)-th image... ['./datasets/footulcer_multiclass_256/test/75bf12b779263ac07eb74fe3baa755bf_3.png']\n",
      "processing (0525)-th image... ['./datasets/footulcer_multiclass_256/test/769701bddfae87e276736e4a3048fab6_0.png']\n",
      "processing (0530)-th image... ['./datasets/footulcer_multiclass_256/test/776777c6bbe90594211bfca081d7a365_0.png']\n",
      "processing (0535)-th image... ['./datasets/footulcer_multiclass_256/test/78c5be8a07ce437c3df17acfc16d567e_0.png']\n",
      "processing (0540)-th image... ['./datasets/footulcer_multiclass_256/test/7a66638547495b66262715828c8afcd0_0.png']\n",
      "processing (0545)-th image... ['./datasets/footulcer_multiclass_256/test/7c2b933bc1a51ded68a617a410335e25_1.png']\n",
      "processing (0550)-th image... ['./datasets/footulcer_multiclass_256/test/7e306a1fb449a2631edc1850facefb82_0.png']\n",
      "processing (0555)-th image... ['./datasets/footulcer_multiclass_256/test/8044c4db4e766825d0b10fbdc724b297_0.png']\n",
      "processing (0560)-th image... ['./datasets/footulcer_multiclass_256/test/816b2c8cbdaa48026c25f79587082816_0.png']\n",
      "processing (0565)-th image... ['./datasets/footulcer_multiclass_256/test/822cbb86d197f0a99536c8f74a4d6ce2_0.png']\n",
      "processing (0570)-th image... ['./datasets/footulcer_multiclass_256/test/8452f3abc9d20898ef6de9edf95c3963_0.png']\n",
      "processing (0575)-th image... ['./datasets/footulcer_multiclass_256/test/855067521b74ba3f3affc8ef4e61323f_0.png']\n",
      "processing (0580)-th image... ['./datasets/footulcer_multiclass_256/test/870b7ea6239da9887f77682c5eb2ad51_0.png']\n",
      "processing (0585)-th image... ['./datasets/footulcer_multiclass_256/test/87832ce91343423b474ffbcc7c3e7cf5_1.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0590)-th image... ['./datasets/footulcer_multiclass_256/test/87f9643ecf1e1dcc23293137f4623a4f_2.png']\n",
      "processing (0595)-th image... ['./datasets/footulcer_multiclass_256/test/88c8b5c16aecd4a78d2ac5869e6fedd8_0.png']\n",
      "processing (0600)-th image... ['./datasets/footulcer_multiclass_256/test/8934505da06ec4abfdf59a81a2f831f4_0.png']\n",
      "processing (0605)-th image... ['./datasets/footulcer_multiclass_256/test/8ac79cecafc3a0a99896e8c36f6bac3e_1.png']\n",
      "processing (0610)-th image... ['./datasets/footulcer_multiclass_256/test/8c621970fe7ed9d5b563e4097d31d609_0.png']\n",
      "processing (0615)-th image... ['./datasets/footulcer_multiclass_256/test/8e3c87493da30f92bf75fb7ea9c04786_0.png']\n",
      "processing (0620)-th image... ['./datasets/footulcer_multiclass_256/test/8f941aa493291b5dc76fec6f6caf898b_0.png']\n",
      "processing (0625)-th image... ['./datasets/footulcer_multiclass_256/test/917bc443be555adfdf9d0be213118859_0.png']\n",
      "processing (0630)-th image... ['./datasets/footulcer_multiclass_256/test/92d95396a8ca72d19cbdf1e8366740c8_1.png']\n",
      "processing (0635)-th image... ['./datasets/footulcer_multiclass_256/test/9448d85caa0130c2119e93c749c363cc_0.png']\n",
      "processing (0640)-th image... ['./datasets/footulcer_multiclass_256/test/95c84a41ef9a4494f2bab8c4bf6f70dc_0.png']\n",
      "processing (0645)-th image... ['./datasets/footulcer_multiclass_256/test/97afdc101911ffc33d0fc166cacbaf1b_0.png']\n",
      "processing (0650)-th image... ['./datasets/footulcer_multiclass_256/test/9925404b06cae3cfd54b664dce4e2fd6_0.png']\n",
      "processing (0655)-th image... ['./datasets/footulcer_multiclass_256/test/9ad1690c57ec153a1980f3038acfe2b4_0.png']\n",
      "processing (0660)-th image... ['./datasets/footulcer_multiclass_256/test/9c53151d5b81f24e23043907203a0d43_0.png']\n",
      "processing (0665)-th image... ['./datasets/footulcer_multiclass_256/test/9de367378901a65e663fd696aa3eacf3_0.png']\n",
      "processing (0670)-th image... ['./datasets/footulcer_multiclass_256/test/a0e95454d864462189e0e6810dbd041d_0.png']\n",
      "processing (0675)-th image... ['./datasets/footulcer_multiclass_256/test/a1b5a42de7bd6eaedb86479520262687_2.png']\n",
      "processing (0680)-th image... ['./datasets/footulcer_multiclass_256/test/a23fa00a3aae6b6f3da31c6157aeb670_3.png']\n",
      "processing (0685)-th image... ['./datasets/footulcer_multiclass_256/test/a35853832ecc9a6b25154b9bd5cf6cf3_0.png']\n",
      "processing (0690)-th image... ['./datasets/footulcer_multiclass_256/test/a3cb46f154a3e5c032405492a1f6369f_0.png']\n",
      "processing (0695)-th image... ['./datasets/footulcer_multiclass_256/test/a4d2dc260c443317ba9517905cbf3803_0.png']\n",
      "processing (0700)-th image... ['./datasets/footulcer_multiclass_256/test/a51bb17b140b4ff5b03da4bc4538a986_0.png']\n",
      "processing (0705)-th image... ['./datasets/footulcer_multiclass_256/test/a63bb932fece9695681b2e6f1ee0bd05_0.png']\n",
      "processing (0710)-th image... ['./datasets/footulcer_multiclass_256/test/a77c969895b566672fccaad9ed45037f_0.png']\n",
      "processing (0715)-th image... ['./datasets/footulcer_multiclass_256/test/a87e022359340a7a46b849c473fe12ef_1.png']\n",
      "processing (0720)-th image... ['./datasets/footulcer_multiclass_256/test/a9359659e9c8cb5a59429e057979b52f_2.png']\n",
      "processing (0725)-th image... ['./datasets/footulcer_multiclass_256/test/a9b83f354ab887edc10ddb9ef19cc5d9_0.png']\n",
      "processing (0730)-th image... ['./datasets/footulcer_multiclass_256/test/aa59d5b6f186b8046603defb1a3afa42_0.png']\n",
      "processing (0735)-th image... ['./datasets/footulcer_multiclass_256/test/aafb2fc42b97b1d9c4908400fb4e4fff_0.png']\n",
      "processing (0740)-th image... ['./datasets/footulcer_multiclass_256/test/ab78761c202d21872f1d9b3e3d0c2e5f_1.png']\n",
      "processing (0745)-th image... ['./datasets/footulcer_multiclass_256/test/ac7e55f1332c4e37bcefe76f1c4e79e4_0.png']\n",
      "processing (0750)-th image... ['./datasets/footulcer_multiclass_256/test/ade0de677bf619050b77f4efe3ad5878_0.png']\n",
      "processing (0755)-th image... ['./datasets/footulcer_multiclass_256/test/b08c34d9e82b6af851bbbac6461870ff_0.png']\n",
      "processing (0760)-th image... ['./datasets/footulcer_multiclass_256/test/b40bb91be02f2b7c20e0046b450e7276_2.png']\n",
      "processing (0765)-th image... ['./datasets/footulcer_multiclass_256/test/b56853a2c67fa5838a8ae06b4b4d92f3_0.png']\n",
      "processing (0770)-th image... ['./datasets/footulcer_multiclass_256/test/b6ecf50bfbf4e36d6d9f0c240adf79b7_1.png']\n",
      "processing (0775)-th image... ['./datasets/footulcer_multiclass_256/test/b9fff21bebb15ba7d8c3f54063e37799_0.png']\n"
     ]
    }
   ],
   "source": [
    "# testing script\n",
    "\n",
    "!python test.py --dataroot ./datasets/footulcer_multiclass_256 --model pix2pix --name footulcer_multiclass_256 --gpu_ids -1 --num_test 776 --direction BtoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_multiclass_256\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: footulcer_multiclass_256      \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 342                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/footulcer_multiclass_256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/footulcer_multiclass_256/0_test\n",
      "processing (0000)-th image... ['./datasets/footulcer_multiclass_256/test/blue0010.png']\n",
      "processing (0005)-th image... ['./datasets/footulcer_multiclass_256/test/blue0050.png']\n",
      "processing (0010)-th image... ['./datasets/footulcer_multiclass_256/test/blue0074.png']\n",
      "processing (0015)-th image... ['./datasets/footulcer_multiclass_256/test/blue0122.png']\n",
      "processing (0020)-th image... ['./datasets/footulcer_multiclass_256/test/blue0143.png']\n",
      "processing (0025)-th image... ['./datasets/footulcer_multiclass_256/test/blue0185.png']\n",
      "processing (0030)-th image... ['./datasets/footulcer_multiclass_256/test/blue0228.png']\n",
      "processing (0035)-th image... ['./datasets/footulcer_multiclass_256/test/blue0259.png']\n",
      "processing (0040)-th image... ['./datasets/footulcer_multiclass_256/test/green0035.png']\n",
      "processing (0045)-th image... ['./datasets/footulcer_multiclass_256/test/green0062.png']\n",
      "processing (0050)-th image... ['./datasets/footulcer_multiclass_256/test/green0096.png']\n",
      "processing (0055)-th image... ['./datasets/footulcer_multiclass_256/test/green0132.png']\n",
      "processing (0060)-th image... ['./datasets/footulcer_multiclass_256/test/green0162.png']\n",
      "processing (0065)-th image... ['./datasets/footulcer_multiclass_256/test/green0190.png']\n",
      "processing (0070)-th image... ['./datasets/footulcer_multiclass_256/test/green0242.png']\n",
      "processing (0075)-th image... ['./datasets/footulcer_multiclass_256/test/green0264.png']\n",
      "processing (0080)-th image... ['./datasets/footulcer_multiclass_256/test/red0040.png']\n",
      "processing (0085)-th image... ['./datasets/footulcer_multiclass_256/test/red0073.png']\n",
      "processing (0090)-th image... ['./datasets/footulcer_multiclass_256/test/red0108.png']\n",
      "processing (0095)-th image... ['./datasets/footulcer_multiclass_256/test/red0135.png']\n",
      "processing (0100)-th image... ['./datasets/footulcer_multiclass_256/test/red0169.png']\n",
      "processing (0105)-th image... ['./datasets/footulcer_multiclass_256/test/red0218.png']\n",
      "processing (0110)-th image... ['./datasets/footulcer_multiclass_256/test/red0246.png']\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_multiclass_256\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: footulcer_multiclass_256      \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 342                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/footulcer_multiclass_256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/footulcer_multiclass_256/1_test\n",
      "processing (0000)-th image... ['./datasets/footulcer_multiclass_256/test/blue0010.png']\n",
      "processing (0005)-th image... ['./datasets/footulcer_multiclass_256/test/blue0050.png']\n",
      "processing (0010)-th image... ['./datasets/footulcer_multiclass_256/test/blue0074.png']\n",
      "processing (0015)-th image... ['./datasets/footulcer_multiclass_256/test/blue0122.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0020)-th image... ['./datasets/footulcer_multiclass_256/test/blue0143.png']\n",
      "processing (0025)-th image... ['./datasets/footulcer_multiclass_256/test/blue0185.png']\n",
      "processing (0030)-th image... ['./datasets/footulcer_multiclass_256/test/blue0228.png']\n",
      "processing (0035)-th image... ['./datasets/footulcer_multiclass_256/test/blue0259.png']\n",
      "processing (0040)-th image... ['./datasets/footulcer_multiclass_256/test/green0035.png']\n",
      "processing (0045)-th image... ['./datasets/footulcer_multiclass_256/test/green0062.png']\n",
      "processing (0050)-th image... ['./datasets/footulcer_multiclass_256/test/green0096.png']\n",
      "processing (0055)-th image... ['./datasets/footulcer_multiclass_256/test/green0132.png']\n",
      "processing (0060)-th image... ['./datasets/footulcer_multiclass_256/test/green0162.png']\n",
      "processing (0065)-th image... ['./datasets/footulcer_multiclass_256/test/green0190.png']\n",
      "processing (0070)-th image... ['./datasets/footulcer_multiclass_256/test/green0242.png']\n",
      "processing (0075)-th image... ['./datasets/footulcer_multiclass_256/test/green0264.png']\n",
      "processing (0080)-th image... ['./datasets/footulcer_multiclass_256/test/red0040.png']\n",
      "processing (0085)-th image... ['./datasets/footulcer_multiclass_256/test/red0073.png']\n",
      "processing (0090)-th image... ['./datasets/footulcer_multiclass_256/test/red0108.png']\n",
      "processing (0095)-th image... ['./datasets/footulcer_multiclass_256/test/red0135.png']\n",
      "processing (0100)-th image... ['./datasets/footulcer_multiclass_256/test/red0169.png']\n",
      "processing (0105)-th image... ['./datasets/footulcer_multiclass_256/test/red0218.png']\n",
      "processing (0110)-th image... ['./datasets/footulcer_multiclass_256/test/red0246.png']\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_multiclass_256\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: footulcer_multiclass_256      \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 342                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/footulcer_multiclass_256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/footulcer_multiclass_256/2_test\n",
      "processing (0000)-th image... ['./datasets/footulcer_multiclass_256/test/blue0010.png']\n",
      "processing (0005)-th image... ['./datasets/footulcer_multiclass_256/test/blue0050.png']\n",
      "processing (0010)-th image... ['./datasets/footulcer_multiclass_256/test/blue0074.png']\n",
      "processing (0015)-th image... ['./datasets/footulcer_multiclass_256/test/blue0122.png']\n",
      "processing (0020)-th image... ['./datasets/footulcer_multiclass_256/test/blue0143.png']\n",
      "processing (0025)-th image... ['./datasets/footulcer_multiclass_256/test/blue0185.png']\n",
      "processing (0030)-th image... ['./datasets/footulcer_multiclass_256/test/blue0228.png']\n",
      "processing (0035)-th image... ['./datasets/footulcer_multiclass_256/test/blue0259.png']\n",
      "processing (0040)-th image... ['./datasets/footulcer_multiclass_256/test/green0035.png']\n",
      "processing (0045)-th image... ['./datasets/footulcer_multiclass_256/test/green0062.png']\n",
      "processing (0050)-th image... ['./datasets/footulcer_multiclass_256/test/green0096.png']\n",
      "processing (0055)-th image... ['./datasets/footulcer_multiclass_256/test/green0132.png']\n",
      "processing (0060)-th image... ['./datasets/footulcer_multiclass_256/test/green0162.png']\n",
      "processing (0065)-th image... ['./datasets/footulcer_multiclass_256/test/green0190.png']\n",
      "processing (0070)-th image... ['./datasets/footulcer_multiclass_256/test/green0242.png']\n",
      "processing (0075)-th image... ['./datasets/footulcer_multiclass_256/test/green0264.png']\n",
      "processing (0080)-th image... ['./datasets/footulcer_multiclass_256/test/red0040.png']\n",
      "processing (0085)-th image... ['./datasets/footulcer_multiclass_256/test/red0073.png']\n",
      "processing (0090)-th image... ['./datasets/footulcer_multiclass_256/test/red0108.png']\n",
      "processing (0095)-th image... ['./datasets/footulcer_multiclass_256/test/red0135.png']\n",
      "processing (0100)-th image... ['./datasets/footulcer_multiclass_256/test/red0169.png']\n",
      "processing (0105)-th image... ['./datasets/footulcer_multiclass_256/test/red0218.png']\n",
      "processing (0110)-th image... ['./datasets/footulcer_multiclass_256/test/red0246.png']\n"
     ]
    }
   ],
   "source": [
    "!python test_aug.py --dataroot ./datasets/footulcer_multiclass_256 --model pix2pix --name footulcer_multiclass_256 --gpu_ids -1 --num_test 342 --direction AtoB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test_aug.py --dataroot ./datasets/footulcer_multiclass_256 --model pix2pix --name footulcer_multiclass_256 --gpu_ids -1 --num_test 776 --direction BtoA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
