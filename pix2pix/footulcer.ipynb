{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/intern1/pixgan'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.chdir('pytorch-CycleGAN-and-pix2pix/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "----------------- Options ---------------\n",
      "               batch_size: 16                            \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_256      \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 0                             \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 4                             \t[default: 3]\n",
      "                     name: footulcer_resized_256         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: n_layers                      \t[default: basic]\n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 776\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/footulcer_256 --name footulcer_resized_256 --model pix2pix --gpu_ids 0 --display_id 0 --batch_size 16 --netD n_layers --n_layers_D 4 --direction BtoA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "----------------- Options ---------------\n",
      "               batch_size: 16                            \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_256      \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 0                             \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: footulcer_resized_256_3layer  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 776\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "create web directory ./checkpoints/footulcer_resized_256_3layer/web...\n",
      "/home/intern1/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 400, time: 0.024, data: 0.182) G_GAN: 1.414 G_L1: 34.614 D_real: 0.448 D_fake: 0.443 \n",
      "End of epoch 1 / 200 \t Time Taken: 13 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 16, time: 0.014, data: 0.003) G_GAN: 1.931 G_L1: 32.497 D_real: 0.270 D_fake: 0.715 \n",
      "(epoch: 2, iters: 416, time: 0.023, data: 0.004) G_GAN: 2.575 G_L1: 26.785 D_real: 0.206 D_fake: 0.100 \n",
      "End of epoch 2 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 32, time: 0.024, data: 0.003) G_GAN: 3.001 G_L1: 28.902 D_real: 0.057 D_fake: 0.091 \n",
      "(epoch: 3, iters: 432, time: 0.026, data: 0.003) G_GAN: 3.165 G_L1: 28.777 D_real: 0.114 D_fake: 0.069 \n",
      "End of epoch 3 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 48, time: 0.025, data: 0.003) G_GAN: 3.158 G_L1: 36.104 D_real: 0.092 D_fake: 0.091 \n",
      "(epoch: 4, iters: 448, time: 0.023, data: 0.004) G_GAN: 3.777 G_L1: 36.527 D_real: 0.046 D_fake: 0.042 \n",
      "End of epoch 4 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 64, time: 0.026, data: 0.003) G_GAN: 3.281 G_L1: 37.490 D_real: 0.046 D_fake: 0.084 \n",
      "(epoch: 5, iters: 464, time: 0.024, data: 0.004) G_GAN: 3.150 G_L1: 36.343 D_real: 0.049 D_fake: 0.096 \n",
      "saving the model at the end of epoch 5, iters 3920\n",
      "End of epoch 5 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 80, time: 0.027, data: 0.003) G_GAN: 2.909 G_L1: 32.869 D_real: 0.138 D_fake: 0.050 \n",
      "(epoch: 6, iters: 480, time: 0.023, data: 0.003) G_GAN: 2.606 G_L1: 33.586 D_real: 0.672 D_fake: 1.136 \n",
      "End of epoch 6 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 96, time: 0.029, data: 0.003) G_GAN: 3.258 G_L1: 31.130 D_real: 0.031 D_fake: 0.318 \n",
      "(epoch: 7, iters: 496, time: 0.026, data: 0.003) G_GAN: 3.842 G_L1: 26.993 D_real: 0.164 D_fake: 0.047 \n",
      "End of epoch 7 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 112, time: 0.026, data: 0.003) G_GAN: 0.591 G_L1: 31.064 D_real: 0.788 D_fake: 0.106 \n",
      "(epoch: 8, iters: 512, time: 0.026, data: 0.002) G_GAN: 3.536 G_L1: 32.194 D_real: 0.054 D_fake: 0.092 \n",
      "End of epoch 8 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 128, time: 0.027, data: 0.003) G_GAN: 2.503 G_L1: 29.713 D_real: 0.275 D_fake: 0.097 \n",
      "(epoch: 9, iters: 528, time: 0.024, data: 0.002) G_GAN: 0.405 G_L1: 35.177 D_real: 1.029 D_fake: 0.016 \n",
      "End of epoch 9 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 144, time: 0.031, data: 0.003) G_GAN: 3.582 G_L1: 34.719 D_real: 0.022 D_fake: 0.730 \n",
      "(epoch: 10, iters: 544, time: 0.024, data: 0.002) G_GAN: 2.610 G_L1: 33.785 D_real: 0.015 D_fake: 1.658 \n",
      "saving the model at the end of epoch 10, iters 7840\n",
      "End of epoch 10 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 160, time: 0.027, data: 0.003) G_GAN: 0.192 G_L1: 27.323 D_real: 1.220 D_fake: 0.067 \n",
      "(epoch: 11, iters: 560, time: 0.027, data: 0.003) G_GAN: 2.818 G_L1: 34.528 D_real: 0.057 D_fake: 1.034 \n",
      "End of epoch 11 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 176, time: 0.026, data: 0.003) G_GAN: 1.726 G_L1: 40.536 D_real: 0.828 D_fake: 0.153 \n",
      "(epoch: 12, iters: 576, time: 0.024, data: 0.003) G_GAN: 1.866 G_L1: 35.127 D_real: 0.294 D_fake: 0.070 \n",
      "End of epoch 12 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 192, time: 0.027, data: 0.003) G_GAN: 2.146 G_L1: 34.762 D_real: 0.182 D_fake: 0.212 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 13, iters: 592, time: 0.027, data: 0.003) G_GAN: 3.326 G_L1: 36.179 D_real: 0.019 D_fake: 0.612 \n",
      "saving the latest model (epoch 13, total_iters 10000)\n",
      "End of epoch 13 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 208, time: 0.026, data: 0.003) G_GAN: 2.645 G_L1: 26.672 D_real: 0.024 D_fake: 1.944 \n",
      "(epoch: 14, iters: 608, time: 0.024, data: 0.003) G_GAN: 3.289 G_L1: 35.958 D_real: 0.033 D_fake: 0.077 \n",
      "End of epoch 14 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 15, iters: 224, time: 0.026, data: 0.003) G_GAN: 2.467 G_L1: 40.232 D_real: 0.031 D_fake: 0.734 \n",
      "(epoch: 15, iters: 624, time: 0.024, data: 0.004) G_GAN: 3.582 G_L1: 35.559 D_real: 0.017 D_fake: 0.258 \n",
      "saving the model at the end of epoch 15, iters 11760\n",
      "End of epoch 15 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 16, iters: 240, time: 0.026, data: 0.003) G_GAN: 4.424 G_L1: 32.938 D_real: 0.029 D_fake: 0.683 \n",
      "(epoch: 16, iters: 640, time: 0.024, data: 0.002) G_GAN: 0.888 G_L1: 32.800 D_real: 0.647 D_fake: 0.024 \n",
      "End of epoch 16 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 17, iters: 256, time: 0.026, data: 0.003) G_GAN: 1.537 G_L1: 33.312 D_real: 0.597 D_fake: 0.058 \n",
      "(epoch: 17, iters: 656, time: 0.024, data: 0.003) G_GAN: 1.513 G_L1: 35.307 D_real: 0.184 D_fake: 1.262 \n",
      "End of epoch 17 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 18, iters: 272, time: 0.026, data: 0.003) G_GAN: 2.412 G_L1: 31.924 D_real: 0.199 D_fake: 0.137 \n",
      "(epoch: 18, iters: 672, time: 0.026, data: 0.003) G_GAN: 3.081 G_L1: 35.368 D_real: 0.053 D_fake: 0.141 \n",
      "End of epoch 18 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 19, iters: 288, time: 0.026, data: 0.002) G_GAN: 2.232 G_L1: 37.471 D_real: 0.397 D_fake: 0.097 \n",
      "(epoch: 19, iters: 688, time: 0.024, data: 0.003) G_GAN: 2.908 G_L1: 38.549 D_real: 0.130 D_fake: 0.084 \n",
      "End of epoch 19 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 20, iters: 304, time: 0.028, data: 0.003) G_GAN: 0.150 G_L1: 35.040 D_real: 1.386 D_fake: 0.078 \n",
      "(epoch: 20, iters: 704, time: 0.025, data: 0.003) G_GAN: 2.404 G_L1: 40.416 D_real: 0.054 D_fake: 1.550 \n",
      "saving the model at the end of epoch 20, iters 15680\n",
      "End of epoch 20 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 21, iters: 320, time: 0.027, data: 0.003) G_GAN: 3.471 G_L1: 36.734 D_real: 0.174 D_fake: 0.095 \n",
      "(epoch: 21, iters: 720, time: 0.026, data: 0.003) G_GAN: 1.866 G_L1: 34.828 D_real: 0.268 D_fake: 0.171 \n",
      "End of epoch 21 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 22, iters: 336, time: 0.030, data: 0.004) G_GAN: 2.142 G_L1: 37.664 D_real: 0.017 D_fake: 1.043 \n",
      "(epoch: 22, iters: 736, time: 0.024, data: 0.003) G_GAN: 1.711 G_L1: 34.618 D_real: 0.298 D_fake: 0.115 \n",
      "End of epoch 22 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 23, iters: 352, time: 0.026, data: 0.004) G_GAN: 2.342 G_L1: 39.332 D_real: 0.252 D_fake: 0.208 \n",
      "(epoch: 23, iters: 752, time: 0.027, data: 0.004) G_GAN: 0.761 G_L1: 35.277 D_real: 1.178 D_fake: 0.050 \n",
      "End of epoch 23 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 24, iters: 368, time: 0.031, data: 0.004) G_GAN: 1.544 G_L1: 33.172 D_real: 0.997 D_fake: 0.091 \n",
      "(epoch: 24, iters: 768, time: 0.024, data: 0.003) G_GAN: 1.204 G_L1: 33.553 D_real: 0.187 D_fake: 0.652 \n",
      "End of epoch 24 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 25, iters: 384, time: 0.027, data: 0.004) G_GAN: 2.776 G_L1: 31.283 D_real: 0.098 D_fake: 1.205 \n",
      "(epoch: 25, iters: 784, time: 0.022, data: 0.004) G_GAN: 1.356 G_L1: 32.710 D_real: 0.565 D_fake: 0.116 \n",
      "saving the model at the end of epoch 25, iters 19600\n",
      "End of epoch 25 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 26, iters: 400, time: 0.026, data: 0.251) G_GAN: 2.265 G_L1: 33.448 D_real: 0.314 D_fake: 0.497 \n",
      "saving the latest model (epoch 26, total_iters 20000)\n",
      "End of epoch 26 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 27, iters: 16, time: 0.016, data: 0.003) G_GAN: 2.429 G_L1: 35.242 D_real: 0.087 D_fake: 1.404 \n",
      "(epoch: 27, iters: 416, time: 0.024, data: 0.004) G_GAN: 0.989 G_L1: 36.085 D_real: 0.509 D_fake: 0.171 \n",
      "End of epoch 27 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 28, iters: 32, time: 0.027, data: 0.003) G_GAN: 2.057 G_L1: 32.665 D_real: 0.118 D_fake: 0.160 \n",
      "(epoch: 28, iters: 432, time: 0.024, data: 0.003) G_GAN: 2.266 G_L1: 39.167 D_real: 0.014 D_fake: 0.633 \n",
      "End of epoch 28 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 29, iters: 48, time: 0.027, data: 0.003) G_GAN: 2.933 G_L1: 32.817 D_real: 0.026 D_fake: 0.260 \n",
      "(epoch: 29, iters: 448, time: 0.024, data: 0.004) G_GAN: 1.513 G_L1: 34.386 D_real: 0.936 D_fake: 0.126 \n",
      "End of epoch 29 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 30, iters: 64, time: 0.027, data: 0.004) G_GAN: 0.443 G_L1: 40.695 D_real: 1.154 D_fake: 0.211 \n",
      "(epoch: 30, iters: 464, time: 0.024, data: 0.004) G_GAN: 3.373 G_L1: 38.915 D_real: 0.058 D_fake: 0.089 \n",
      "saving the model at the end of epoch 30, iters 23520\n",
      "End of epoch 30 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 31, iters: 80, time: 0.035, data: 0.003) G_GAN: 2.467 G_L1: 34.023 D_real: 0.079 D_fake: 0.420 \n",
      "(epoch: 31, iters: 480, time: 0.027, data: 0.002) G_GAN: 1.207 G_L1: 30.227 D_real: 0.349 D_fake: 0.130 \n",
      "End of epoch 31 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 32, iters: 96, time: 0.032, data: 0.003) G_GAN: 2.615 G_L1: 30.504 D_real: 0.012 D_fake: 0.656 \n",
      "(epoch: 32, iters: 496, time: 0.027, data: 0.002) G_GAN: 1.820 G_L1: 34.642 D_real: 0.581 D_fake: 0.396 \n",
      "End of epoch 32 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 33, iters: 112, time: 0.028, data: 0.003) G_GAN: 1.431 G_L1: 32.467 D_real: 0.585 D_fake: 0.079 \n",
      "(epoch: 33, iters: 512, time: 0.024, data: 0.002) G_GAN: 1.443 G_L1: 35.719 D_real: 0.259 D_fake: 0.352 \n",
      "End of epoch 33 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 34, iters: 128, time: 0.027, data: 0.003) G_GAN: 3.575 G_L1: 39.890 D_real: 0.058 D_fake: 0.036 \n",
      "(epoch: 34, iters: 528, time: 0.026, data: 0.003) G_GAN: 1.174 G_L1: 34.846 D_real: 0.394 D_fake: 0.818 \n",
      "End of epoch 34 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 35, iters: 144, time: 0.030, data: 0.003) G_GAN: 2.882 G_L1: 38.873 D_real: 0.009 D_fake: 0.411 \n",
      "(epoch: 35, iters: 544, time: 0.024, data: 0.002) G_GAN: 1.987 G_L1: 32.708 D_real: 0.082 D_fake: 0.866 \n",
      "saving the model at the end of epoch 35, iters 27440\n",
      "End of epoch 35 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 36, iters: 160, time: 0.028, data: 0.003) G_GAN: 1.914 G_L1: 30.807 D_real: 0.028 D_fake: 0.875 \n",
      "(epoch: 36, iters: 560, time: 0.030, data: 0.003) G_GAN: 2.901 G_L1: 31.845 D_real: 0.014 D_fake: 0.362 \n",
      "End of epoch 36 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 37, iters: 176, time: 0.032, data: 0.003) G_GAN: 1.498 G_L1: 31.225 D_real: 1.042 D_fake: 0.059 \n",
      "(epoch: 37, iters: 576, time: 0.024, data: 0.003) G_GAN: 2.704 G_L1: 38.270 D_real: 0.073 D_fake: 0.186 \n",
      "End of epoch 37 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 38, iters: 192, time: 0.028, data: 0.003) G_GAN: 2.068 G_L1: 32.284 D_real: 0.537 D_fake: 0.066 \n",
      "(epoch: 38, iters: 592, time: 0.027, data: 0.003) G_GAN: 1.697 G_L1: 37.224 D_real: 0.326 D_fake: 0.260 \n",
      "End of epoch 38 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 39, iters: 208, time: 0.033, data: 0.003) G_GAN: 1.969 G_L1: 34.615 D_real: 0.359 D_fake: 0.577 \n",
      "saving the latest model (epoch 39, total_iters 30000)\n",
      "(epoch: 39, iters: 608, time: 0.025, data: 0.004) G_GAN: 2.009 G_L1: 37.099 D_real: 0.058 D_fake: 0.547 \n",
      "End of epoch 39 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 40, iters: 224, time: 0.029, data: 0.003) G_GAN: 1.179 G_L1: 33.781 D_real: 1.666 D_fake: 0.040 \n",
      "(epoch: 40, iters: 624, time: 0.024, data: 0.004) G_GAN: 1.887 G_L1: 30.867 D_real: 0.157 D_fake: 0.367 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model at the end of epoch 40, iters 31360\n",
      "End of epoch 40 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 41, iters: 240, time: 0.028, data: 0.003) G_GAN: 1.873 G_L1: 30.421 D_real: 0.295 D_fake: 0.365 \n",
      "(epoch: 41, iters: 640, time: 0.030, data: 0.003) G_GAN: 0.756 G_L1: 34.340 D_real: 0.766 D_fake: 0.294 \n",
      "End of epoch 41 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 42, iters: 256, time: 0.028, data: 0.003) G_GAN: 1.537 G_L1: 36.855 D_real: 0.327 D_fake: 0.693 \n",
      "(epoch: 42, iters: 656, time: 0.026, data: 0.003) G_GAN: 0.872 G_L1: 37.282 D_real: 0.830 D_fake: 0.189 \n",
      "End of epoch 42 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 43, iters: 272, time: 0.028, data: 0.003) G_GAN: 0.948 G_L1: 36.572 D_real: 0.502 D_fake: 0.944 \n",
      "(epoch: 43, iters: 672, time: 0.024, data: 0.003) G_GAN: 2.375 G_L1: 38.033 D_real: 0.260 D_fake: 0.169 \n",
      "End of epoch 43 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 44, iters: 288, time: 0.028, data: 0.003) G_GAN: 2.424 G_L1: 31.606 D_real: 0.054 D_fake: 0.658 \n",
      "(epoch: 44, iters: 688, time: 0.024, data: 0.003) G_GAN: 1.063 G_L1: 38.707 D_real: 0.801 D_fake: 0.264 \n",
      "End of epoch 44 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 45, iters: 304, time: 0.029, data: 0.003) G_GAN: 1.611 G_L1: 34.601 D_real: 0.107 D_fake: 1.267 \n",
      "(epoch: 45, iters: 704, time: 0.024, data: 0.003) G_GAN: 1.622 G_L1: 38.471 D_real: 0.226 D_fake: 0.482 \n",
      "saving the model at the end of epoch 45, iters 35280\n",
      "End of epoch 45 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 46, iters: 320, time: 0.030, data: 0.003) G_GAN: 3.120 G_L1: 33.210 D_real: 0.181 D_fake: 0.087 \n",
      "(epoch: 46, iters: 720, time: 0.033, data: 0.004) G_GAN: 1.368 G_L1: 32.753 D_real: 0.190 D_fake: 0.445 \n",
      "End of epoch 46 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 47, iters: 336, time: 0.028, data: 0.003) G_GAN: 1.190 G_L1: 35.271 D_real: 3.523 D_fake: 0.087 \n",
      "(epoch: 47, iters: 736, time: 0.024, data: 0.003) G_GAN: 1.469 G_L1: 34.621 D_real: 0.027 D_fake: 0.509 \n",
      "End of epoch 47 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 48, iters: 352, time: 0.028, data: 0.003) G_GAN: 0.453 G_L1: 34.710 D_real: 2.359 D_fake: 0.175 \n",
      "(epoch: 48, iters: 752, time: 0.024, data: 0.003) G_GAN: 2.170 G_L1: 39.416 D_real: 0.167 D_fake: 0.114 \n",
      "End of epoch 48 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 49, iters: 368, time: 0.031, data: 0.003) G_GAN: 2.350 G_L1: 43.475 D_real: 0.066 D_fake: 0.448 \n",
      "(epoch: 49, iters: 768, time: 0.026, data: 0.003) G_GAN: 1.152 G_L1: 34.726 D_real: 1.039 D_fake: 0.222 \n",
      "End of epoch 49 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 50, iters: 384, time: 0.029, data: 0.003) G_GAN: 1.308 G_L1: 40.197 D_real: 0.090 D_fake: 0.252 \n",
      "(epoch: 50, iters: 784, time: 0.018, data: 0.003) G_GAN: 1.706 G_L1: 33.560 D_real: 0.002 D_fake: 0.947 \n",
      "saving the model at the end of epoch 50, iters 39200\n",
      "End of epoch 50 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 51, iters: 400, time: 0.029, data: 0.244) G_GAN: 2.805 G_L1: 35.459 D_real: 0.020 D_fake: 0.624 \n",
      "End of epoch 51 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 52, iters: 16, time: 0.018, data: 0.003) G_GAN: 3.327 G_L1: 41.640 D_real: 0.114 D_fake: 0.147 \n",
      "saving the latest model (epoch 52, total_iters 40000)\n",
      "(epoch: 52, iters: 416, time: 0.024, data: 0.005) G_GAN: 2.313 G_L1: 33.875 D_real: 0.067 D_fake: 0.225 \n",
      "End of epoch 52 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 53, iters: 32, time: 0.033, data: 0.003) G_GAN: 2.203 G_L1: 36.058 D_real: 0.060 D_fake: 0.564 \n",
      "(epoch: 53, iters: 432, time: 0.024, data: 0.003) G_GAN: 1.648 G_L1: 30.109 D_real: 0.054 D_fake: 0.786 \n",
      "End of epoch 53 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 54, iters: 48, time: 0.029, data: 0.003) G_GAN: 1.480 G_L1: 27.013 D_real: 0.385 D_fake: 0.356 \n",
      "(epoch: 54, iters: 448, time: 0.029, data: 0.003) G_GAN: 0.479 G_L1: 27.885 D_real: 1.412 D_fake: 0.817 \n",
      "End of epoch 54 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 55, iters: 64, time: 0.029, data: 0.003) G_GAN: 1.801 G_L1: 29.216 D_real: 0.038 D_fake: 0.512 \n",
      "(epoch: 55, iters: 464, time: 0.024, data: 0.005) G_GAN: 0.896 G_L1: 31.892 D_real: 0.713 D_fake: 0.168 \n",
      "saving the model at the end of epoch 55, iters 43120\n",
      "End of epoch 55 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 56, iters: 80, time: 0.029, data: 0.003) G_GAN: 1.412 G_L1: 32.204 D_real: 0.080 D_fake: 1.276 \n",
      "(epoch: 56, iters: 480, time: 0.024, data: 0.002) G_GAN: 1.159 G_L1: 33.633 D_real: 0.419 D_fake: 0.338 \n",
      "End of epoch 56 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 57, iters: 96, time: 0.029, data: 0.003) G_GAN: 0.715 G_L1: 32.938 D_real: 1.151 D_fake: 0.133 \n",
      "(epoch: 57, iters: 496, time: 0.024, data: 0.003) G_GAN: 2.721 G_L1: 33.993 D_real: 0.229 D_fake: 0.251 \n",
      "End of epoch 57 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 58, iters: 112, time: 0.029, data: 0.003) G_GAN: 1.055 G_L1: 34.946 D_real: 2.734 D_fake: 0.134 \n",
      "(epoch: 58, iters: 512, time: 0.024, data: 0.002) G_GAN: 0.452 G_L1: 29.941 D_real: 2.757 D_fake: 0.132 \n",
      "End of epoch 58 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 59, iters: 128, time: 0.032, data: 0.003) G_GAN: 0.916 G_L1: 32.435 D_real: 0.256 D_fake: 0.323 \n",
      "(epoch: 59, iters: 528, time: 0.029, data: 0.004) G_GAN: 2.192 G_L1: 33.786 D_real: 0.278 D_fake: 0.612 \n",
      "End of epoch 59 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 60, iters: 144, time: 0.029, data: 0.003) G_GAN: 2.052 G_L1: 38.211 D_real: 0.085 D_fake: 0.230 \n",
      "(epoch: 60, iters: 544, time: 0.024, data: 0.003) G_GAN: 0.266 G_L1: 36.991 D_real: 1.453 D_fake: 0.414 \n",
      "saving the model at the end of epoch 60, iters 47040\n",
      "End of epoch 60 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 61, iters: 160, time: 0.030, data: 0.003) G_GAN: 1.051 G_L1: 37.582 D_real: 0.416 D_fake: 0.963 \n",
      "(epoch: 61, iters: 560, time: 0.024, data: 0.003) G_GAN: 1.052 G_L1: 32.254 D_real: 0.416 D_fake: 0.522 \n",
      "End of epoch 61 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 62, iters: 176, time: 0.030, data: 0.003) G_GAN: 1.581 G_L1: 31.794 D_real: 0.136 D_fake: 1.418 \n",
      "(epoch: 62, iters: 576, time: 0.024, data: 0.003) G_GAN: 1.960 G_L1: 32.843 D_real: 0.268 D_fake: 0.882 \n",
      "End of epoch 62 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 63, iters: 192, time: 0.029, data: 0.003) G_GAN: 1.675 G_L1: 34.964 D_real: 0.149 D_fake: 0.619 \n",
      "(epoch: 63, iters: 592, time: 0.024, data: 0.003) G_GAN: 0.347 G_L1: 38.300 D_real: 1.569 D_fake: 0.212 \n",
      "End of epoch 63 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 64, iters: 208, time: 0.030, data: 0.003) G_GAN: 1.440 G_L1: 37.217 D_real: 0.459 D_fake: 0.211 \n",
      "(epoch: 64, iters: 608, time: 0.031, data: 0.003) G_GAN: 1.301 G_L1: 29.209 D_real: 0.836 D_fake: 0.255 \n",
      "saving the latest model (epoch 64, total_iters 50000)\n",
      "End of epoch 64 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 65, iters: 224, time: 0.030, data: 0.003) G_GAN: 1.951 G_L1: 34.286 D_real: 0.286 D_fake: 0.175 \n",
      "(epoch: 65, iters: 624, time: 0.024, data: 0.003) G_GAN: 0.664 G_L1: 29.901 D_real: 1.070 D_fake: 0.473 \n",
      "saving the model at the end of epoch 65, iters 50960\n",
      "End of epoch 65 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 66, iters: 240, time: 0.031, data: 0.003) G_GAN: 1.587 G_L1: 40.142 D_real: 0.068 D_fake: 0.722 \n",
      "(epoch: 66, iters: 640, time: 0.024, data: 0.003) G_GAN: 2.680 G_L1: 28.451 D_real: 0.083 D_fake: 0.282 \n",
      "End of epoch 66 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 67, iters: 256, time: 0.030, data: 0.003) G_GAN: 1.885 G_L1: 40.157 D_real: 0.215 D_fake: 0.325 \n",
      "(epoch: 67, iters: 656, time: 0.024, data: 0.003) G_GAN: 1.811 G_L1: 36.116 D_real: 0.059 D_fake: 0.635 \n",
      "End of epoch 67 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 68, iters: 272, time: 0.034, data: 0.003) G_GAN: 0.355 G_L1: 33.695 D_real: 1.386 D_fake: 1.408 \n",
      "(epoch: 68, iters: 672, time: 0.024, data: 0.003) G_GAN: 1.610 G_L1: 25.971 D_real: 0.232 D_fake: 0.586 \n",
      "End of epoch 68 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 69, iters: 288, time: 0.033, data: 0.003) G_GAN: 2.099 G_L1: 36.394 D_real: 0.215 D_fake: 0.303 \n",
      "(epoch: 69, iters: 688, time: 0.030, data: 0.003) G_GAN: 1.744 G_L1: 35.653 D_real: 0.196 D_fake: 0.649 \n",
      "End of epoch 69 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 70, iters: 304, time: 0.030, data: 0.003) G_GAN: 1.116 G_L1: 27.774 D_real: 0.516 D_fake: 0.217 \n",
      "(epoch: 70, iters: 704, time: 0.027, data: 0.003) G_GAN: 1.899 G_L1: 40.071 D_real: 0.003 D_fake: 0.641 \n",
      "saving the model at the end of epoch 70, iters 54880\n",
      "End of epoch 70 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 71, iters: 320, time: 0.031, data: 0.003) G_GAN: 2.143 G_L1: 39.938 D_real: 0.108 D_fake: 0.169 \n",
      "(epoch: 71, iters: 720, time: 0.024, data: 0.003) G_GAN: 1.524 G_L1: 32.211 D_real: 0.075 D_fake: 0.879 \n",
      "End of epoch 71 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 72, iters: 336, time: 0.030, data: 0.003) G_GAN: 1.375 G_L1: 28.796 D_real: 0.584 D_fake: 0.127 \n",
      "(epoch: 72, iters: 736, time: 0.024, data: 0.003) G_GAN: 1.683 G_L1: 37.208 D_real: 0.403 D_fake: 0.366 \n",
      "End of epoch 72 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 73, iters: 352, time: 0.030, data: 0.004) G_GAN: 1.700 G_L1: 37.149 D_real: 0.557 D_fake: 0.208 \n",
      "(epoch: 73, iters: 752, time: 0.024, data: 0.003) G_GAN: 1.467 G_L1: 27.790 D_real: 0.471 D_fake: 0.191 \n",
      "End of epoch 73 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 74, iters: 368, time: 0.030, data: 0.003) G_GAN: 1.443 G_L1: 30.615 D_real: 0.572 D_fake: 0.319 \n",
      "(epoch: 74, iters: 768, time: 0.030, data: 0.003) G_GAN: 1.202 G_L1: 35.341 D_real: 0.648 D_fake: 0.310 \n",
      "End of epoch 74 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 75, iters: 384, time: 0.030, data: 0.003) G_GAN: 1.614 G_L1: 36.715 D_real: 0.436 D_fake: 0.233 \n",
      "(epoch: 75, iters: 784, time: 0.020, data: 0.003) G_GAN: 1.217 G_L1: 27.892 D_real: 0.996 D_fake: 0.201 \n",
      "saving the model at the end of epoch 75, iters 58800\n",
      "End of epoch 75 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 76, iters: 400, time: 0.033, data: 0.252) G_GAN: 0.963 G_L1: 30.637 D_real: 0.992 D_fake: 0.175 \n",
      "End of epoch 76 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 77, iters: 16, time: 0.022, data: 0.003) G_GAN: 0.442 G_L1: 34.322 D_real: 2.246 D_fake: 0.145 \n",
      "(epoch: 77, iters: 416, time: 0.030, data: 0.003) G_GAN: 1.318 G_L1: 28.704 D_real: 0.467 D_fake: 0.263 \n",
      "saving the latest model (epoch 77, total_iters 60000)\n",
      "End of epoch 77 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 78, iters: 32, time: 0.030, data: 0.003) G_GAN: 1.386 G_L1: 25.842 D_real: 1.344 D_fake: 0.102 \n",
      "(epoch: 78, iters: 432, time: 0.024, data: 0.003) G_GAN: 2.488 G_L1: 35.021 D_real: 0.138 D_fake: 0.161 \n",
      "End of epoch 78 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 79, iters: 48, time: 0.030, data: 0.003) G_GAN: 1.566 G_L1: 33.331 D_real: 0.217 D_fake: 0.323 \n",
      "(epoch: 79, iters: 448, time: 0.024, data: 0.004) G_GAN: 1.675 G_L1: 28.413 D_real: 0.277 D_fake: 0.357 \n",
      "End of epoch 79 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 80, iters: 64, time: 0.030, data: 0.003) G_GAN: 2.496 G_L1: 37.616 D_real: 0.082 D_fake: 0.178 \n",
      "(epoch: 80, iters: 464, time: 0.024, data: 0.003) G_GAN: 1.796 G_L1: 33.974 D_real: 0.018 D_fake: 0.391 \n",
      "saving the model at the end of epoch 80, iters 62720\n",
      "End of epoch 80 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 81, iters: 80, time: 0.031, data: 0.003) G_GAN: 1.662 G_L1: 34.308 D_real: 0.437 D_fake: 0.292 \n",
      "(epoch: 81, iters: 480, time: 0.024, data: 0.003) G_GAN: 1.021 G_L1: 27.982 D_real: 2.696 D_fake: 0.098 \n",
      "End of epoch 81 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 82, iters: 96, time: 0.031, data: 0.003) G_GAN: 0.949 G_L1: 29.965 D_real: 0.969 D_fake: 0.280 \n",
      "(epoch: 82, iters: 496, time: 0.031, data: 0.003) G_GAN: 0.862 G_L1: 29.309 D_real: 0.295 D_fake: 0.414 \n",
      "End of epoch 82 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 83, iters: 112, time: 0.031, data: 0.003) G_GAN: 0.704 G_L1: 36.285 D_real: 2.090 D_fake: 0.296 \n",
      "(epoch: 83, iters: 512, time: 0.024, data: 0.003) G_GAN: 0.978 G_L1: 32.569 D_real: 1.080 D_fake: 0.141 \n",
      "End of epoch 83 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 84, iters: 128, time: 0.034, data: 0.003) G_GAN: 1.297 G_L1: 33.907 D_real: 0.711 D_fake: 0.263 \n",
      "(epoch: 84, iters: 528, time: 0.024, data: 0.003) G_GAN: 1.741 G_L1: 29.461 D_real: 0.267 D_fake: 0.525 \n",
      "End of epoch 84 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 85, iters: 144, time: 0.031, data: 0.003) G_GAN: 0.870 G_L1: 33.202 D_real: 1.349 D_fake: 0.425 \n",
      "(epoch: 85, iters: 544, time: 0.026, data: 0.003) G_GAN: 1.572 G_L1: 29.009 D_real: 0.982 D_fake: 0.094 \n",
      "saving the model at the end of epoch 85, iters 66640\n",
      "End of epoch 85 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 86, iters: 160, time: 0.031, data: 0.003) G_GAN: 1.489 G_L1: 26.298 D_real: 0.259 D_fake: 0.184 \n",
      "(epoch: 86, iters: 560, time: 0.024, data: 0.003) G_GAN: 1.039 G_L1: 38.180 D_real: 0.188 D_fake: 0.508 \n",
      "End of epoch 86 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 87, iters: 176, time: 0.032, data: 0.003) G_GAN: 0.839 G_L1: 32.071 D_real: 0.454 D_fake: 0.388 \n",
      "(epoch: 87, iters: 576, time: 0.031, data: 0.003) G_GAN: 0.598 G_L1: 32.564 D_real: 1.772 D_fake: 0.235 \n",
      "End of epoch 87 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 88, iters: 192, time: 0.031, data: 0.006) G_GAN: 0.803 G_L1: 32.700 D_real: 0.362 D_fake: 1.618 \n",
      "(epoch: 88, iters: 592, time: 0.024, data: 0.003) G_GAN: 1.201 G_L1: 29.469 D_real: 0.734 D_fake: 0.106 \n",
      "End of epoch 88 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 89, iters: 208, time: 0.031, data: 0.003) G_GAN: 1.913 G_L1: 25.607 D_real: 0.810 D_fake: 0.062 \n",
      "(epoch: 89, iters: 608, time: 0.024, data: 0.003) G_GAN: 1.789 G_L1: 28.980 D_real: 0.015 D_fake: 0.641 \n",
      "End of epoch 89 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 90, iters: 224, time: 0.031, data: 0.003) G_GAN: 1.354 G_L1: 27.507 D_real: 0.379 D_fake: 0.325 \n",
      "saving the latest model (epoch 90, total_iters 70000)\n",
      "(epoch: 90, iters: 624, time: 0.024, data: 0.003) G_GAN: 0.578 G_L1: 31.878 D_real: 1.053 D_fake: 0.173 \n",
      "saving the model at the end of epoch 90, iters 70560\n",
      "End of epoch 90 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 91, iters: 240, time: 0.035, data: 0.003) G_GAN: 1.511 G_L1: 34.152 D_real: 0.593 D_fake: 0.200 \n",
      "(epoch: 91, iters: 640, time: 0.024, data: 0.003) G_GAN: 0.516 G_L1: 30.626 D_real: 1.315 D_fake: 0.239 \n",
      "End of epoch 91 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 92, iters: 256, time: 0.033, data: 0.003) G_GAN: 1.450 G_L1: 32.403 D_real: 0.944 D_fake: 0.236 \n",
      "(epoch: 92, iters: 656, time: 0.032, data: 0.003) G_GAN: 1.081 G_L1: 33.471 D_real: 0.818 D_fake: 0.308 \n",
      "End of epoch 92 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 93, iters: 272, time: 0.034, data: 0.003) G_GAN: 1.469 G_L1: 24.834 D_real: 1.591 D_fake: 0.125 \n",
      "(epoch: 93, iters: 672, time: 0.024, data: 0.003) G_GAN: 0.724 G_L1: 33.529 D_real: 0.432 D_fake: 0.938 \n",
      "End of epoch 93 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 94, iters: 288, time: 0.031, data: 0.003) G_GAN: 2.285 G_L1: 31.336 D_real: 0.294 D_fake: 0.208 \n",
      "(epoch: 94, iters: 688, time: 0.024, data: 0.003) G_GAN: 2.417 G_L1: 33.806 D_real: 0.020 D_fake: 0.311 \n",
      "End of epoch 94 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 95, iters: 304, time: 0.037, data: 0.003) G_GAN: 1.440 G_L1: 33.271 D_real: 0.354 D_fake: 0.461 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 95, iters: 704, time: 0.024, data: 0.003) G_GAN: 2.471 G_L1: 28.925 D_real: 0.017 D_fake: 0.431 \n",
      "saving the model at the end of epoch 95, iters 74480\n",
      "End of epoch 95 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 96, iters: 320, time: 0.032, data: 0.003) G_GAN: 1.471 G_L1: 29.899 D_real: 0.273 D_fake: 0.384 \n",
      "(epoch: 96, iters: 720, time: 0.024, data: 0.003) G_GAN: 2.432 G_L1: 32.348 D_real: 0.017 D_fake: 0.417 \n",
      "End of epoch 96 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 97, iters: 336, time: 0.033, data: 0.003) G_GAN: 0.866 G_L1: 29.479 D_real: 1.030 D_fake: 0.087 \n",
      "(epoch: 97, iters: 736, time: 0.035, data: 0.003) G_GAN: 1.908 G_L1: 30.891 D_real: 0.039 D_fake: 1.105 \n",
      "End of epoch 97 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 98, iters: 352, time: 0.031, data: 0.003) G_GAN: 2.931 G_L1: 31.516 D_real: 0.030 D_fake: 0.131 \n",
      "(epoch: 98, iters: 752, time: 0.029, data: 0.003) G_GAN: 1.061 G_L1: 37.876 D_real: 0.642 D_fake: 0.432 \n",
      "End of epoch 98 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 99, iters: 368, time: 0.032, data: 0.003) G_GAN: 0.227 G_L1: 31.685 D_real: 1.341 D_fake: 0.451 \n",
      "(epoch: 99, iters: 768, time: 0.024, data: 0.003) G_GAN: 2.326 G_L1: 29.515 D_real: 0.206 D_fake: 0.566 \n",
      "End of epoch 99 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0001980\n",
      "(epoch: 100, iters: 384, time: 0.033, data: 0.003) G_GAN: 1.038 G_L1: 26.063 D_real: 1.909 D_fake: 0.112 \n",
      "(epoch: 100, iters: 784, time: 0.019, data: 0.003) G_GAN: 3.258 G_L1: 31.258 D_real: 0.021 D_fake: 0.067 \n",
      "saving the model at the end of epoch 100, iters 78400\n",
      "End of epoch 100 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001980 -> 0.0001960\n",
      "(epoch: 101, iters: 400, time: 0.034, data: 0.248) G_GAN: 2.117 G_L1: 35.857 D_real: 0.007 D_fake: 1.166 \n",
      "End of epoch 101 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001960 -> 0.0001941\n",
      "(epoch: 102, iters: 16, time: 0.022, data: 0.004) G_GAN: 0.954 G_L1: 27.662 D_real: 1.111 D_fake: 0.177 \n",
      "(epoch: 102, iters: 416, time: 0.024, data: 0.002) G_GAN: 1.327 G_L1: 29.228 D_real: 0.886 D_fake: 0.545 \n",
      "End of epoch 102 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001941 -> 0.0001921\n",
      "(epoch: 103, iters: 32, time: 0.033, data: 0.003) G_GAN: 2.239 G_L1: 30.654 D_real: 0.146 D_fake: 0.487 \n",
      "saving the latest model (epoch 103, total_iters 80000)\n",
      "(epoch: 103, iters: 432, time: 0.024, data: 0.003) G_GAN: 1.288 G_L1: 30.474 D_real: 1.312 D_fake: 0.130 \n",
      "End of epoch 103 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001921 -> 0.0001901\n",
      "(epoch: 104, iters: 48, time: 0.033, data: 0.003) G_GAN: 2.248 G_L1: 29.615 D_real: 0.081 D_fake: 0.492 \n",
      "(epoch: 104, iters: 448, time: 0.024, data: 0.004) G_GAN: 1.149 G_L1: 31.686 D_real: 0.989 D_fake: 0.409 \n",
      "End of epoch 104 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001901 -> 0.0001881\n",
      "(epoch: 105, iters: 64, time: 0.038, data: 0.003) G_GAN: 2.531 G_L1: 30.138 D_real: 0.081 D_fake: 0.212 \n",
      "(epoch: 105, iters: 464, time: 0.033, data: 0.004) G_GAN: 1.025 G_L1: 31.011 D_real: 1.018 D_fake: 0.220 \n",
      "saving the model at the end of epoch 105, iters 82320\n",
      "End of epoch 105 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001881 -> 0.0001861\n",
      "(epoch: 106, iters: 80, time: 0.037, data: 0.004) G_GAN: 1.285 G_L1: 29.427 D_real: 0.173 D_fake: 0.687 \n",
      "(epoch: 106, iters: 480, time: 0.024, data: 0.002) G_GAN: 0.560 G_L1: 32.855 D_real: 1.784 D_fake: 0.302 \n",
      "End of epoch 106 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001861 -> 0.0001842\n",
      "(epoch: 107, iters: 96, time: 0.035, data: 0.003) G_GAN: 1.129 G_L1: 29.142 D_real: 0.482 D_fake: 0.500 \n",
      "(epoch: 107, iters: 496, time: 0.024, data: 0.002) G_GAN: 0.886 G_L1: 32.750 D_real: 1.447 D_fake: 0.209 \n",
      "End of epoch 107 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001842 -> 0.0001822\n",
      "(epoch: 108, iters: 112, time: 0.034, data: 0.003) G_GAN: 1.303 G_L1: 28.968 D_real: 0.396 D_fake: 0.303 \n",
      "(epoch: 108, iters: 512, time: 0.027, data: 0.003) G_GAN: 0.762 G_L1: 30.551 D_real: 0.614 D_fake: 0.516 \n",
      "End of epoch 108 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001822 -> 0.0001802\n",
      "(epoch: 109, iters: 128, time: 0.034, data: 0.004) G_GAN: 1.742 G_L1: 35.319 D_real: 0.741 D_fake: 0.224 \n",
      "(epoch: 109, iters: 528, time: 0.026, data: 0.004) G_GAN: 2.314 G_L1: 32.741 D_real: 0.004 D_fake: 0.202 \n",
      "End of epoch 109 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001802 -> 0.0001782\n",
      "(epoch: 110, iters: 144, time: 0.032, data: 0.003) G_GAN: 1.915 G_L1: 27.292 D_real: 0.179 D_fake: 0.267 \n",
      "(epoch: 110, iters: 544, time: 0.036, data: 0.002) G_GAN: 1.067 G_L1: 29.180 D_real: 0.352 D_fake: 0.436 \n",
      "saving the model at the end of epoch 110, iters 86240\n",
      "End of epoch 110 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001782 -> 0.0001762\n",
      "(epoch: 111, iters: 160, time: 0.033, data: 0.003) G_GAN: 0.498 G_L1: 29.678 D_real: 1.498 D_fake: 0.203 \n",
      "(epoch: 111, iters: 560, time: 0.025, data: 0.003) G_GAN: 1.948 G_L1: 35.301 D_real: 0.080 D_fake: 0.430 \n",
      "End of epoch 111 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001762 -> 0.0001743\n",
      "(epoch: 112, iters: 176, time: 0.036, data: 0.003) G_GAN: 1.031 G_L1: 27.114 D_real: 1.335 D_fake: 0.143 \n",
      "(epoch: 112, iters: 576, time: 0.024, data: 0.003) G_GAN: 1.331 G_L1: 26.347 D_real: 0.231 D_fake: 0.266 \n",
      "End of epoch 112 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001743 -> 0.0001723\n",
      "(epoch: 113, iters: 192, time: 0.035, data: 0.004) G_GAN: 0.948 G_L1: 29.026 D_real: 1.385 D_fake: 0.275 \n",
      "(epoch: 113, iters: 592, time: 0.025, data: 0.005) G_GAN: 1.097 G_L1: 30.589 D_real: 0.747 D_fake: 0.261 \n",
      "End of epoch 113 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001723 -> 0.0001703\n",
      "(epoch: 114, iters: 208, time: 0.037, data: 0.004) G_GAN: 0.823 G_L1: 28.971 D_real: 1.479 D_fake: 0.269 \n",
      "(epoch: 114, iters: 608, time: 0.024, data: 0.005) G_GAN: 1.455 G_L1: 29.046 D_real: 0.305 D_fake: 0.207 \n",
      "End of epoch 114 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001703 -> 0.0001683\n",
      "(epoch: 115, iters: 224, time: 0.034, data: 0.004) G_GAN: 1.571 G_L1: 27.643 D_real: 0.140 D_fake: 0.222 \n",
      "(epoch: 115, iters: 624, time: 0.040, data: 0.003) G_GAN: 1.399 G_L1: 26.927 D_real: 0.251 D_fake: 0.339 \n",
      "saving the latest model (epoch 115, total_iters 90000)\n",
      "saving the model at the end of epoch 115, iters 90160\n",
      "End of epoch 115 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0001683 -> 0.0001663\n",
      "(epoch: 116, iters: 240, time: 0.036, data: 0.005) G_GAN: 1.203 G_L1: 35.675 D_real: 0.379 D_fake: 0.921 \n",
      "(epoch: 116, iters: 640, time: 0.025, data: 0.003) G_GAN: 2.819 G_L1: 23.807 D_real: 0.062 D_fake: 0.168 \n",
      "End of epoch 116 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001663 -> 0.0001644\n",
      "(epoch: 117, iters: 256, time: 0.035, data: 0.003) G_GAN: 1.289 G_L1: 34.887 D_real: 0.121 D_fake: 0.484 \n",
      "(epoch: 117, iters: 656, time: 0.024, data: 0.003) G_GAN: 1.725 G_L1: 26.567 D_real: 0.283 D_fake: 0.300 \n",
      "End of epoch 117 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001644 -> 0.0001624\n",
      "(epoch: 118, iters: 272, time: 0.036, data: 0.003) G_GAN: 0.654 G_L1: 29.972 D_real: 0.928 D_fake: 0.629 \n",
      "(epoch: 118, iters: 672, time: 0.025, data: 0.004) G_GAN: 0.614 G_L1: 27.959 D_real: 1.094 D_fake: 0.586 \n",
      "End of epoch 118 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001624 -> 0.0001604\n",
      "(epoch: 119, iters: 288, time: 0.035, data: 0.004) G_GAN: 0.646 G_L1: 31.247 D_real: 0.609 D_fake: 1.247 \n",
      "(epoch: 119, iters: 688, time: 0.025, data: 0.004) G_GAN: 1.428 G_L1: 33.220 D_real: 0.999 D_fake: 0.221 \n",
      "End of epoch 119 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001604 -> 0.0001584\n",
      "(epoch: 120, iters: 304, time: 0.036, data: 0.003) G_GAN: 0.968 G_L1: 27.768 D_real: 0.592 D_fake: 0.367 \n",
      "(epoch: 120, iters: 704, time: 0.036, data: 0.003) G_GAN: 0.995 G_L1: 30.504 D_real: 0.279 D_fake: 0.745 \n",
      "saving the model at the end of epoch 120, iters 94080\n",
      "End of epoch 120 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001584 -> 0.0001564\n",
      "(epoch: 121, iters: 320, time: 0.040, data: 0.003) G_GAN: 0.799 G_L1: 27.641 D_real: 0.496 D_fake: 0.319 \n",
      "(epoch: 121, iters: 720, time: 0.025, data: 0.003) G_GAN: 1.495 G_L1: 33.679 D_real: 0.528 D_fake: 0.279 \n",
      "End of epoch 121 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001564 -> 0.0001545\n",
      "(epoch: 122, iters: 336, time: 0.035, data: 0.004) G_GAN: 0.902 G_L1: 32.678 D_real: 1.159 D_fake: 0.363 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 122, iters: 736, time: 0.025, data: 0.004) G_GAN: 1.476 G_L1: 31.645 D_real: 0.750 D_fake: 0.738 \n",
      "End of epoch 122 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001545 -> 0.0001525\n",
      "(epoch: 123, iters: 352, time: 0.033, data: 0.003) G_GAN: 0.890 G_L1: 34.730 D_real: 0.619 D_fake: 0.426 \n",
      "(epoch: 123, iters: 752, time: 0.024, data: 0.003) G_GAN: 1.322 G_L1: 29.238 D_real: 1.409 D_fake: 0.169 \n",
      "End of epoch 123 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001525 -> 0.0001505\n",
      "(epoch: 124, iters: 368, time: 0.035, data: 0.003) G_GAN: 1.182 G_L1: 30.245 D_real: 0.606 D_fake: 0.279 \n",
      "(epoch: 124, iters: 768, time: 0.024, data: 0.003) G_GAN: 1.742 G_L1: 25.165 D_real: 0.119 D_fake: 0.399 \n",
      "End of epoch 124 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001505 -> 0.0001485\n",
      "(epoch: 125, iters: 384, time: 0.033, data: 0.003) G_GAN: 0.762 G_L1: 26.341 D_real: 0.621 D_fake: 0.298 \n",
      "(epoch: 125, iters: 784, time: 0.027, data: 0.003) G_GAN: 1.427 G_L1: 25.131 D_real: 0.398 D_fake: 0.329 \n",
      "saving the model at the end of epoch 125, iters 98000\n",
      "End of epoch 125 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001485 -> 0.0001465\n",
      "(epoch: 126, iters: 400, time: 0.036, data: 0.247) G_GAN: 1.246 G_L1: 29.969 D_real: 0.437 D_fake: 0.397 \n",
      "End of epoch 126 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001465 -> 0.0001446\n",
      "(epoch: 127, iters: 16, time: 0.022, data: 0.003) G_GAN: 1.245 G_L1: 25.141 D_real: 1.394 D_fake: 0.261 \n",
      "(epoch: 127, iters: 416, time: 0.025, data: 0.002) G_GAN: 1.412 G_L1: 27.485 D_real: 0.177 D_fake: 0.747 \n",
      "End of epoch 127 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001446 -> 0.0001426\n",
      "(epoch: 128, iters: 32, time: 0.033, data: 0.003) G_GAN: 1.650 G_L1: 29.878 D_real: 2.285 D_fake: 0.135 \n",
      "(epoch: 128, iters: 432, time: 0.035, data: 0.002) G_GAN: 2.058 G_L1: 28.176 D_real: 0.034 D_fake: 0.744 \n",
      "saving the latest model (epoch 128, total_iters 100000)\n",
      "End of epoch 128 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001426 -> 0.0001406\n",
      "(epoch: 129, iters: 48, time: 0.033, data: 0.003) G_GAN: 0.412 G_L1: 32.309 D_real: 1.329 D_fake: 0.636 \n",
      "(epoch: 129, iters: 448, time: 0.025, data: 0.003) G_GAN: 1.695 G_L1: 31.127 D_real: 0.021 D_fake: 0.348 \n",
      "End of epoch 129 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001406 -> 0.0001386\n",
      "(epoch: 130, iters: 64, time: 0.037, data: 0.004) G_GAN: 1.916 G_L1: 29.658 D_real: 0.332 D_fake: 0.285 \n",
      "(epoch: 130, iters: 464, time: 0.025, data: 0.005) G_GAN: 1.960 G_L1: 23.730 D_real: 0.025 D_fake: 0.173 \n",
      "saving the model at the end of epoch 130, iters 101920\n",
      "End of epoch 130 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001386 -> 0.0001366\n",
      "(epoch: 131, iters: 80, time: 0.037, data: 0.004) G_GAN: 1.644 G_L1: 27.448 D_real: 0.108 D_fake: 0.628 \n",
      "(epoch: 131, iters: 480, time: 0.027, data: 0.003) G_GAN: 1.069 G_L1: 26.408 D_real: 0.274 D_fake: 0.597 \n",
      "End of epoch 131 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001366 -> 0.0001347\n",
      "(epoch: 132, iters: 96, time: 0.035, data: 0.003) G_GAN: 0.880 G_L1: 31.138 D_real: 0.537 D_fake: 0.497 \n",
      "(epoch: 132, iters: 496, time: 0.025, data: 0.002) G_GAN: 1.073 G_L1: 26.760 D_real: 0.341 D_fake: 0.322 \n",
      "End of epoch 132 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001347 -> 0.0001327\n",
      "(epoch: 133, iters: 112, time: 0.034, data: 0.003) G_GAN: 1.702 G_L1: 28.066 D_real: 0.085 D_fake: 0.191 \n",
      "(epoch: 133, iters: 512, time: 0.034, data: 0.003) G_GAN: 0.487 G_L1: 26.223 D_real: 1.430 D_fake: 0.287 \n",
      "End of epoch 133 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001327 -> 0.0001307\n",
      "(epoch: 134, iters: 128, time: 0.035, data: 0.003) G_GAN: 2.421 G_L1: 34.919 D_real: 0.025 D_fake: 0.120 \n",
      "(epoch: 134, iters: 528, time: 0.024, data: 0.003) G_GAN: 1.029 G_L1: 25.136 D_real: 2.287 D_fake: 0.141 \n",
      "End of epoch 134 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001307 -> 0.0001287\n",
      "(epoch: 135, iters: 144, time: 0.038, data: 0.003) G_GAN: 2.241 G_L1: 28.016 D_real: 0.059 D_fake: 0.682 \n",
      "(epoch: 135, iters: 544, time: 0.024, data: 0.002) G_GAN: 1.300 G_L1: 29.988 D_real: 0.083 D_fake: 1.035 \n",
      "saving the model at the end of epoch 135, iters 105840\n",
      "End of epoch 135 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001287 -> 0.0001267\n",
      "(epoch: 136, iters: 160, time: 0.034, data: 0.003) G_GAN: 1.777 G_L1: 27.638 D_real: 0.471 D_fake: 0.193 \n",
      "(epoch: 136, iters: 560, time: 0.025, data: 0.003) G_GAN: 1.436 G_L1: 25.992 D_real: 0.163 D_fake: 0.257 \n",
      "End of epoch 136 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001267 -> 0.0001248\n",
      "(epoch: 137, iters: 176, time: 0.035, data: 0.003) G_GAN: 0.942 G_L1: 27.528 D_real: 2.557 D_fake: 0.143 \n",
      "(epoch: 137, iters: 576, time: 0.024, data: 0.004) G_GAN: 0.976 G_L1: 29.926 D_real: 0.777 D_fake: 0.446 \n",
      "End of epoch 137 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001248 -> 0.0001228\n",
      "(epoch: 138, iters: 192, time: 0.034, data: 0.003) G_GAN: 0.608 G_L1: 29.871 D_real: 0.861 D_fake: 0.368 \n",
      "(epoch: 138, iters: 592, time: 0.037, data: 0.004) G_GAN: 1.647 G_L1: 25.035 D_real: 0.966 D_fake: 0.145 \n",
      "End of epoch 138 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001228 -> 0.0001208\n",
      "(epoch: 139, iters: 208, time: 0.038, data: 0.004) G_GAN: 2.232 G_L1: 26.580 D_real: 0.096 D_fake: 0.169 \n",
      "(epoch: 139, iters: 608, time: 0.024, data: 0.005) G_GAN: 1.095 G_L1: 29.583 D_real: 0.504 D_fake: 0.260 \n",
      "End of epoch 139 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001208 -> 0.0001188\n",
      "(epoch: 140, iters: 224, time: 0.045, data: 0.003) G_GAN: 1.152 G_L1: 24.641 D_real: 0.261 D_fake: 0.571 \n",
      "(epoch: 140, iters: 624, time: 0.024, data: 0.005) G_GAN: 1.055 G_L1: 24.053 D_real: 0.610 D_fake: 0.492 \n",
      "saving the model at the end of epoch 140, iters 109760\n",
      "End of epoch 140 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001188 -> 0.0001168\n",
      "(epoch: 141, iters: 240, time: 0.036, data: 0.005) G_GAN: 2.205 G_L1: 27.731 D_real: 0.030 D_fake: 0.241 \n",
      "saving the latest model (epoch 141, total_iters 110000)\n",
      "(epoch: 141, iters: 640, time: 0.025, data: 0.005) G_GAN: 1.092 G_L1: 30.120 D_real: 0.254 D_fake: 0.611 \n",
      "End of epoch 141 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001168 -> 0.0001149\n",
      "(epoch: 142, iters: 256, time: 0.037, data: 0.003) G_GAN: 0.841 G_L1: 30.319 D_real: 0.480 D_fake: 0.378 \n",
      "(epoch: 142, iters: 656, time: 0.025, data: 0.003) G_GAN: 1.331 G_L1: 23.330 D_real: 0.387 D_fake: 0.527 \n",
      "End of epoch 142 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0001149 -> 0.0001129\n",
      "(epoch: 143, iters: 272, time: 0.041, data: 0.004) G_GAN: 0.969 G_L1: 23.918 D_real: 1.387 D_fake: 0.243 \n",
      "(epoch: 143, iters: 672, time: 0.038, data: 0.003) G_GAN: 1.550 G_L1: 28.284 D_real: 0.429 D_fake: 0.243 \n",
      "End of epoch 143 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001129 -> 0.0001109\n",
      "(epoch: 144, iters: 288, time: 0.043, data: 0.003) G_GAN: 1.115 G_L1: 27.018 D_real: 0.353 D_fake: 0.333 \n",
      "(epoch: 144, iters: 688, time: 0.025, data: 0.003) G_GAN: 0.652 G_L1: 24.703 D_real: 0.632 D_fake: 0.978 \n",
      "End of epoch 144 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001109 -> 0.0001089\n",
      "(epoch: 145, iters: 304, time: 0.038, data: 0.003) G_GAN: 2.048 G_L1: 29.364 D_real: 0.250 D_fake: 0.187 \n",
      "(epoch: 145, iters: 704, time: 0.027, data: 0.004) G_GAN: 1.252 G_L1: 25.356 D_real: 0.566 D_fake: 0.687 \n",
      "saving the model at the end of epoch 145, iters 113680\n",
      "End of epoch 145 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0001089 -> 0.0001069\n",
      "(epoch: 146, iters: 320, time: 0.040, data: 0.004) G_GAN: 0.869 G_L1: 28.141 D_real: 0.774 D_fake: 0.252 \n",
      "(epoch: 146, iters: 720, time: 0.025, data: 0.003) G_GAN: 1.735 G_L1: 22.544 D_real: 0.264 D_fake: 0.195 \n",
      "End of epoch 146 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001069 -> 0.0001050\n",
      "(epoch: 147, iters: 336, time: 0.046, data: 0.004) G_GAN: 1.085 G_L1: 28.582 D_real: 0.959 D_fake: 0.350 \n",
      "(epoch: 147, iters: 736, time: 0.026, data: 0.003) G_GAN: 0.833 G_L1: 24.491 D_real: 1.192 D_fake: 0.296 \n",
      "End of epoch 147 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001050 -> 0.0001030\n",
      "(epoch: 148, iters: 352, time: 0.041, data: 0.003) G_GAN: 1.174 G_L1: 28.094 D_real: 1.250 D_fake: 0.274 \n",
      "(epoch: 148, iters: 752, time: 0.047, data: 0.003) G_GAN: 2.669 G_L1: 30.106 D_real: 0.006 D_fake: 0.136 \n",
      "End of epoch 148 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0001030 -> 0.0001010\n",
      "(epoch: 149, iters: 368, time: 0.040, data: 0.004) G_GAN: 2.376 G_L1: 28.935 D_real: 0.007 D_fake: 0.278 \n",
      "(epoch: 149, iters: 768, time: 0.027, data: 0.004) G_GAN: 2.394 G_L1: 23.386 D_real: 0.091 D_fake: 0.082 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 149 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0001010 -> 0.0000990\n",
      "(epoch: 150, iters: 384, time: 0.041, data: 0.004) G_GAN: 0.982 G_L1: 27.350 D_real: 0.351 D_fake: 0.443 \n",
      "(epoch: 150, iters: 784, time: 0.020, data: 0.004) G_GAN: 1.299 G_L1: 27.985 D_real: 0.076 D_fake: 0.760 \n",
      "saving the model at the end of epoch 150, iters 117600\n",
      "End of epoch 150 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0000990 -> 0.0000970\n",
      "(epoch: 151, iters: 400, time: 0.039, data: 0.349) G_GAN: 2.215 G_L1: 24.729 D_real: 0.005 D_fake: 0.261 \n",
      "End of epoch 151 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000970 -> 0.0000950\n",
      "(epoch: 152, iters: 16, time: 0.029, data: 0.003) G_GAN: 1.508 G_L1: 22.491 D_real: 1.144 D_fake: 1.217 \n",
      "(epoch: 152, iters: 416, time: 0.025, data: 0.004) G_GAN: 1.368 G_L1: 31.142 D_real: 0.630 D_fake: 0.236 \n",
      "End of epoch 152 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000950 -> 0.0000931\n",
      "(epoch: 153, iters: 32, time: 0.040, data: 0.003) G_GAN: 1.176 G_L1: 25.551 D_real: 0.439 D_fake: 0.197 \n",
      "(epoch: 153, iters: 432, time: 0.026, data: 0.003) G_GAN: 1.403 G_L1: 29.858 D_real: 0.883 D_fake: 0.267 \n",
      "End of epoch 153 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000931 -> 0.0000911\n",
      "(epoch: 154, iters: 48, time: 0.036, data: 0.003) G_GAN: 1.989 G_L1: 28.049 D_real: 0.000 D_fake: 0.319 \n",
      "saving the latest model (epoch 154, total_iters 120000)\n",
      "(epoch: 154, iters: 448, time: 0.026, data: 0.006) G_GAN: 1.516 G_L1: 26.815 D_real: 0.139 D_fake: 0.618 \n",
      "End of epoch 154 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000911 -> 0.0000891\n",
      "(epoch: 155, iters: 64, time: 0.040, data: 0.003) G_GAN: 0.993 G_L1: 23.167 D_real: 0.777 D_fake: 0.312 \n",
      "(epoch: 155, iters: 464, time: 0.025, data: 0.004) G_GAN: 0.991 G_L1: 24.881 D_real: 0.617 D_fake: 0.410 \n",
      "saving the model at the end of epoch 155, iters 121520\n",
      "End of epoch 155 / 200 \t Time Taken: 12 sec\n",
      "learning rate 0.0000891 -> 0.0000871\n",
      "(epoch: 156, iters: 80, time: 0.041, data: 0.004) G_GAN: 2.614 G_L1: 21.638 D_real: 0.020 D_fake: 0.185 \n",
      "(epoch: 156, iters: 480, time: 0.038, data: 0.002) G_GAN: 1.409 G_L1: 24.120 D_real: 0.225 D_fake: 0.370 \n",
      "End of epoch 156 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000871 -> 0.0000851\n",
      "(epoch: 157, iters: 96, time: 0.045, data: 0.003) G_GAN: 1.507 G_L1: 22.847 D_real: 0.728 D_fake: 0.289 \n",
      "(epoch: 157, iters: 496, time: 0.027, data: 0.004) G_GAN: 2.051 G_L1: 26.032 D_real: 0.649 D_fake: 0.129 \n",
      "End of epoch 157 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000851 -> 0.0000832\n",
      "(epoch: 158, iters: 112, time: 0.038, data: 0.003) G_GAN: 0.805 G_L1: 22.080 D_real: 0.688 D_fake: 0.985 \n",
      "(epoch: 158, iters: 512, time: 0.026, data: 0.004) G_GAN: 1.294 G_L1: 26.064 D_real: 0.004 D_fake: 0.726 \n",
      "End of epoch 158 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000832 -> 0.0000812\n",
      "(epoch: 159, iters: 128, time: 0.039, data: 0.003) G_GAN: 1.023 G_L1: 23.681 D_real: 0.292 D_fake: 0.590 \n",
      "(epoch: 159, iters: 528, time: 0.026, data: 0.004) G_GAN: 1.376 G_L1: 27.508 D_real: 0.444 D_fake: 0.230 \n",
      "End of epoch 159 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000812 -> 0.0000792\n",
      "(epoch: 160, iters: 144, time: 0.036, data: 0.003) G_GAN: 1.918 G_L1: 25.124 D_real: 0.060 D_fake: 0.190 \n",
      "(epoch: 160, iters: 544, time: 0.025, data: 0.004) G_GAN: 1.825 G_L1: 25.847 D_real: 0.121 D_fake: 0.293 \n",
      "saving the model at the end of epoch 160, iters 125440\n",
      "End of epoch 160 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000792 -> 0.0000772\n",
      "(epoch: 161, iters: 160, time: 0.035, data: 0.003) G_GAN: 1.876 G_L1: 24.363 D_real: 0.018 D_fake: 0.310 \n",
      "(epoch: 161, iters: 560, time: 0.046, data: 0.003) G_GAN: 1.904 G_L1: 24.589 D_real: 0.308 D_fake: 0.125 \n",
      "End of epoch 161 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000772 -> 0.0000752\n",
      "(epoch: 162, iters: 176, time: 0.039, data: 0.004) G_GAN: 1.528 G_L1: 22.838 D_real: 0.189 D_fake: 0.322 \n",
      "(epoch: 162, iters: 576, time: 0.026, data: 0.003) G_GAN: 1.792 G_L1: 27.140 D_real: 0.038 D_fake: 0.298 \n",
      "End of epoch 162 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000752 -> 0.0000733\n",
      "(epoch: 163, iters: 192, time: 0.040, data: 0.003) G_GAN: 1.347 G_L1: 31.094 D_real: 0.559 D_fake: 0.226 \n",
      "(epoch: 163, iters: 592, time: 0.024, data: 0.004) G_GAN: 1.772 G_L1: 27.060 D_real: 1.235 D_fake: 0.167 \n",
      "End of epoch 163 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000733 -> 0.0000713\n",
      "(epoch: 164, iters: 208, time: 0.036, data: 0.003) G_GAN: 1.356 G_L1: 31.167 D_real: 0.006 D_fake: 0.405 \n",
      "(epoch: 164, iters: 608, time: 0.025, data: 0.003) G_GAN: 0.809 G_L1: 25.804 D_real: 0.298 D_fake: 0.877 \n",
      "End of epoch 164 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000713 -> 0.0000693\n",
      "(epoch: 165, iters: 224, time: 0.039, data: 0.003) G_GAN: 1.318 G_L1: 25.956 D_real: 0.328 D_fake: 0.343 \n",
      "(epoch: 165, iters: 624, time: 0.025, data: 0.003) G_GAN: 1.051 G_L1: 25.298 D_real: 0.164 D_fake: 0.753 \n",
      "saving the model at the end of epoch 165, iters 129360\n",
      "End of epoch 165 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000693 -> 0.0000673\n",
      "(epoch: 166, iters: 240, time: 0.036, data: 0.004) G_GAN: 1.123 G_L1: 24.240 D_real: 0.340 D_fake: 0.354 \n",
      "(epoch: 166, iters: 640, time: 0.036, data: 0.003) G_GAN: 1.024 G_L1: 24.324 D_real: 0.309 D_fake: 0.624 \n",
      "saving the latest model (epoch 166, total_iters 130000)\n",
      "End of epoch 166 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000673 -> 0.0000653\n",
      "(epoch: 167, iters: 256, time: 0.037, data: 0.003) G_GAN: 2.088 G_L1: 33.506 D_real: 0.006 D_fake: 0.274 \n",
      "(epoch: 167, iters: 656, time: 0.025, data: 0.003) G_GAN: 1.168 G_L1: 26.203 D_real: 0.078 D_fake: 0.580 \n",
      "End of epoch 167 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000653 -> 0.0000634\n",
      "(epoch: 168, iters: 272, time: 0.036, data: 0.003) G_GAN: 2.232 G_L1: 25.396 D_real: 0.020 D_fake: 0.213 \n",
      "(epoch: 168, iters: 672, time: 0.025, data: 0.003) G_GAN: 1.481 G_L1: 24.200 D_real: 1.265 D_fake: 0.190 \n",
      "End of epoch 168 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000634 -> 0.0000614\n",
      "(epoch: 169, iters: 288, time: 0.044, data: 0.003) G_GAN: 1.060 G_L1: 25.783 D_real: 0.014 D_fake: 0.873 \n",
      "(epoch: 169, iters: 688, time: 0.024, data: 0.004) G_GAN: 1.235 G_L1: 26.460 D_real: 0.298 D_fake: 0.398 \n",
      "End of epoch 169 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000614 -> 0.0000594\n",
      "(epoch: 170, iters: 304, time: 0.041, data: 0.003) G_GAN: 1.788 G_L1: 25.455 D_real: 0.065 D_fake: 0.233 \n",
      "(epoch: 170, iters: 704, time: 0.026, data: 0.003) G_GAN: 1.324 G_L1: 25.082 D_real: 0.183 D_fake: 0.483 \n",
      "saving the model at the end of epoch 170, iters 133280\n",
      "End of epoch 170 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000594 -> 0.0000574\n",
      "(epoch: 171, iters: 320, time: 0.036, data: 0.003) G_GAN: 1.789 G_L1: 24.629 D_real: 0.865 D_fake: 0.142 \n",
      "(epoch: 171, iters: 720, time: 0.036, data: 0.003) G_GAN: 0.704 G_L1: 26.444 D_real: 0.440 D_fake: 0.891 \n",
      "End of epoch 171 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000574 -> 0.0000554\n",
      "(epoch: 172, iters: 336, time: 0.042, data: 0.003) G_GAN: 1.830 G_L1: 25.648 D_real: 0.024 D_fake: 0.258 \n",
      "(epoch: 172, iters: 736, time: 0.025, data: 0.003) G_GAN: 1.105 G_L1: 23.738 D_real: 1.198 D_fake: 0.379 \n",
      "End of epoch 172 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000554 -> 0.0000535\n",
      "(epoch: 173, iters: 352, time: 0.039, data: 0.003) G_GAN: 1.613 G_L1: 26.439 D_real: 0.033 D_fake: 0.265 \n",
      "(epoch: 173, iters: 752, time: 0.024, data: 0.003) G_GAN: 1.101 G_L1: 28.340 D_real: 0.073 D_fake: 0.767 \n",
      "End of epoch 173 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000535 -> 0.0000515\n",
      "(epoch: 174, iters: 368, time: 0.037, data: 0.003) G_GAN: 1.572 G_L1: 23.621 D_real: 0.006 D_fake: 0.305 \n",
      "(epoch: 174, iters: 768, time: 0.026, data: 0.003) G_GAN: 1.615 G_L1: 24.367 D_real: 1.293 D_fake: 0.183 \n",
      "End of epoch 174 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000515 -> 0.0000495\n",
      "(epoch: 175, iters: 384, time: 0.037, data: 0.003) G_GAN: 1.825 G_L1: 23.109 D_real: 1.217 D_fake: 0.143 \n",
      "(epoch: 175, iters: 784, time: 0.021, data: 0.003) G_GAN: 2.118 G_L1: 27.048 D_real: 0.000 D_fake: 0.443 \n",
      "saving the model at the end of epoch 175, iters 137200\n",
      "End of epoch 175 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000495 -> 0.0000475\n",
      "(epoch: 176, iters: 400, time: 0.041, data: 0.262) G_GAN: 1.827 G_L1: 22.427 D_real: 0.505 D_fake: 0.210 \n",
      "End of epoch 176 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000475 -> 0.0000455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 177, iters: 16, time: 0.026, data: 0.003) G_GAN: 1.658 G_L1: 26.608 D_real: 0.027 D_fake: 0.407 \n",
      "(epoch: 177, iters: 416, time: 0.027, data: 0.004) G_GAN: 1.878 G_L1: 24.725 D_real: 0.105 D_fake: 0.196 \n",
      "End of epoch 177 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000455 -> 0.0000436\n",
      "(epoch: 178, iters: 32, time: 0.039, data: 0.003) G_GAN: 1.511 G_L1: 23.241 D_real: 0.286 D_fake: 0.293 \n",
      "(epoch: 178, iters: 432, time: 0.024, data: 0.002) G_GAN: 2.122 G_L1: 27.140 D_real: 0.036 D_fake: 0.144 \n",
      "End of epoch 178 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000436 -> 0.0000416\n",
      "(epoch: 179, iters: 48, time: 0.037, data: 0.003) G_GAN: 1.602 G_L1: 27.563 D_real: 0.019 D_fake: 0.331 \n",
      "(epoch: 179, iters: 448, time: 0.037, data: 0.003) G_GAN: 2.150 G_L1: 23.218 D_real: 1.207 D_fake: 0.120 \n",
      "saving the latest model (epoch 179, total_iters 140000)\n",
      "End of epoch 179 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000416 -> 0.0000396\n",
      "(epoch: 180, iters: 64, time: 0.041, data: 0.003) G_GAN: 1.815 G_L1: 28.055 D_real: 0.003 D_fake: 0.304 \n",
      "(epoch: 180, iters: 464, time: 0.027, data: 0.003) G_GAN: 1.287 G_L1: 27.982 D_real: 0.027 D_fake: 0.570 \n",
      "saving the model at the end of epoch 180, iters 141120\n",
      "End of epoch 180 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000396 -> 0.0000376\n",
      "(epoch: 181, iters: 80, time: 0.037, data: 0.004) G_GAN: 1.384 G_L1: 27.847 D_real: 0.189 D_fake: 0.383 \n",
      "(epoch: 181, iters: 480, time: 0.024, data: 0.002) G_GAN: 0.978 G_L1: 23.036 D_real: 0.002 D_fake: 0.941 \n",
      "End of epoch 181 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000376 -> 0.0000356\n",
      "(epoch: 182, iters: 96, time: 0.037, data: 0.003) G_GAN: 0.982 G_L1: 21.195 D_real: 0.771 D_fake: 0.524 \n",
      "(epoch: 182, iters: 496, time: 0.024, data: 0.002) G_GAN: 2.433 G_L1: 25.574 D_real: 0.350 D_fake: 0.098 \n",
      "End of epoch 182 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000356 -> 0.0000337\n",
      "(epoch: 183, iters: 112, time: 0.038, data: 0.003) G_GAN: 1.708 G_L1: 25.243 D_real: 1.399 D_fake: 0.185 \n",
      "(epoch: 183, iters: 512, time: 0.024, data: 0.003) G_GAN: 1.803 G_L1: 22.935 D_real: 0.084 D_fake: 0.189 \n",
      "End of epoch 183 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000337 -> 0.0000317\n",
      "(epoch: 184, iters: 128, time: 0.046, data: 0.003) G_GAN: 1.337 G_L1: 23.633 D_real: 0.001 D_fake: 0.433 \n",
      "(epoch: 184, iters: 528, time: 0.036, data: 0.004) G_GAN: 1.605 G_L1: 23.495 D_real: 0.245 D_fake: 0.293 \n",
      "End of epoch 184 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000317 -> 0.0000297\n",
      "(epoch: 185, iters: 144, time: 0.037, data: 0.003) G_GAN: 1.124 G_L1: 25.454 D_real: 0.007 D_fake: 0.586 \n",
      "(epoch: 185, iters: 544, time: 0.024, data: 0.003) G_GAN: 1.291 G_L1: 25.094 D_real: 0.333 D_fake: 0.392 \n",
      "saving the model at the end of epoch 185, iters 145040\n",
      "End of epoch 185 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000297 -> 0.0000277\n",
      "(epoch: 186, iters: 160, time: 0.044, data: 0.003) G_GAN: 1.901 G_L1: 24.406 D_real: 0.710 D_fake: 0.168 \n",
      "(epoch: 186, iters: 560, time: 0.025, data: 0.003) G_GAN: 1.384 G_L1: 23.224 D_real: 0.052 D_fake: 0.382 \n",
      "End of epoch 186 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000277 -> 0.0000257\n",
      "(epoch: 187, iters: 176, time: 0.048, data: 0.004) G_GAN: 1.139 G_L1: 26.657 D_real: 0.525 D_fake: 0.413 \n",
      "(epoch: 187, iters: 576, time: 0.025, data: 0.004) G_GAN: 1.634 G_L1: 24.267 D_real: 1.393 D_fake: 0.195 \n",
      "End of epoch 187 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000257 -> 0.0000238\n",
      "(epoch: 188, iters: 192, time: 0.041, data: 0.003) G_GAN: 1.647 G_L1: 24.659 D_real: 0.033 D_fake: 0.264 \n",
      "(epoch: 188, iters: 592, time: 0.025, data: 0.003) G_GAN: 1.226 G_L1: 20.998 D_real: 0.030 D_fake: 0.733 \n",
      "End of epoch 188 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000238 -> 0.0000218\n",
      "(epoch: 189, iters: 208, time: 0.043, data: 0.003) G_GAN: 1.195 G_L1: 33.453 D_real: 0.381 D_fake: 0.485 \n",
      "(epoch: 189, iters: 608, time: 0.041, data: 0.003) G_GAN: 1.735 G_L1: 25.329 D_real: 0.011 D_fake: 0.253 \n",
      "End of epoch 189 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000218 -> 0.0000198\n",
      "(epoch: 190, iters: 224, time: 0.045, data: 0.003) G_GAN: 1.600 G_L1: 28.284 D_real: 0.006 D_fake: 0.279 \n",
      "(epoch: 190, iters: 624, time: 0.026, data: 0.006) G_GAN: 1.253 G_L1: 24.978 D_real: 0.007 D_fake: 0.431 \n",
      "saving the model at the end of epoch 190, iters 148960\n",
      "End of epoch 190 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000198 -> 0.0000178\n",
      "(epoch: 191, iters: 240, time: 0.039, data: 0.004) G_GAN: 1.117 G_L1: 20.090 D_real: 0.003 D_fake: 0.646 \n",
      "(epoch: 191, iters: 640, time: 0.025, data: 0.003) G_GAN: 1.049 G_L1: 29.324 D_real: 0.621 D_fake: 0.541 \n",
      "End of epoch 191 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000178 -> 0.0000158\n",
      "(epoch: 192, iters: 256, time: 0.037, data: 0.003) G_GAN: 1.355 G_L1: 21.903 D_real: 0.000 D_fake: 0.386 \n",
      "saving the latest model (epoch 192, total_iters 150000)\n",
      "(epoch: 192, iters: 656, time: 0.026, data: 0.003) G_GAN: 2.425 G_L1: 25.587 D_real: 0.003 D_fake: 0.123 \n",
      "End of epoch 192 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000158 -> 0.0000139\n",
      "(epoch: 193, iters: 272, time: 0.039, data: 0.003) G_GAN: 1.279 G_L1: 23.897 D_real: 0.961 D_fake: 0.291 \n",
      "(epoch: 193, iters: 672, time: 0.029, data: 0.003) G_GAN: 1.855 G_L1: 22.254 D_real: 0.180 D_fake: 0.206 \n",
      "End of epoch 193 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000139 -> 0.0000119\n",
      "(epoch: 194, iters: 288, time: 0.041, data: 0.003) G_GAN: 1.385 G_L1: 24.560 D_real: 0.263 D_fake: 0.335 \n",
      "(epoch: 194, iters: 688, time: 0.038, data: 0.003) G_GAN: 1.919 G_L1: 28.845 D_real: 0.000 D_fake: 0.166 \n",
      "End of epoch 194 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000119 -> 0.0000099\n",
      "(epoch: 195, iters: 304, time: 0.038, data: 0.003) G_GAN: 1.267 G_L1: 24.000 D_real: 0.116 D_fake: 0.406 \n",
      "(epoch: 195, iters: 704, time: 0.025, data: 0.003) G_GAN: 1.637 G_L1: 25.833 D_real: 0.037 D_fake: 0.248 \n",
      "saving the model at the end of epoch 195, iters 152880\n",
      "End of epoch 195 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000099 -> 0.0000079\n",
      "(epoch: 196, iters: 320, time: 0.038, data: 0.003) G_GAN: 0.693 G_L1: 26.265 D_real: 0.036 D_fake: 0.828 \n",
      "(epoch: 196, iters: 720, time: 0.024, data: 0.004) G_GAN: 0.995 G_L1: 26.564 D_real: 0.022 D_fake: 0.539 \n",
      "End of epoch 196 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000079 -> 0.0000059\n",
      "(epoch: 197, iters: 336, time: 0.041, data: 0.003) G_GAN: 1.390 G_L1: 25.090 D_real: 0.005 D_fake: 0.324 \n",
      "(epoch: 197, iters: 736, time: 0.024, data: 0.004) G_GAN: 2.002 G_L1: 22.674 D_real: 0.168 D_fake: 0.159 \n",
      "End of epoch 197 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000059 -> 0.0000040\n",
      "(epoch: 198, iters: 352, time: 0.041, data: 0.003) G_GAN: 2.462 G_L1: 22.368 D_real: 0.312 D_fake: 0.099 \n",
      "(epoch: 198, iters: 752, time: 0.024, data: 0.003) G_GAN: 1.773 G_L1: 26.340 D_real: 1.415 D_fake: 0.202 \n",
      "End of epoch 198 / 200 \t Time Taken: 10 sec\n",
      "learning rate 0.0000040 -> 0.0000020\n",
      "(epoch: 199, iters: 368, time: 0.038, data: 0.003) G_GAN: 1.955 G_L1: 23.849 D_real: 0.887 D_fake: 0.167 \n",
      "(epoch: 199, iters: 768, time: 0.038, data: 0.003) G_GAN: 1.724 G_L1: 24.207 D_real: 0.250 D_fake: 0.215 \n",
      "End of epoch 199 / 200 \t Time Taken: 11 sec\n",
      "learning rate 0.0000020 -> 0.0000000\n",
      "(epoch: 200, iters: 384, time: 0.042, data: 0.003) G_GAN: 1.792 G_L1: 24.194 D_real: 0.000 D_fake: 0.202 \n",
      "(epoch: 200, iters: 784, time: 0.020, data: 0.003) G_GAN: 1.192 G_L1: 23.235 D_real: 0.034 D_fake: 0.393 \n",
      "saving the model at the end of epoch 200, iters 156800\n",
      "End of epoch 200 / 200 \t Time Taken: 11 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/footulcer_256 --name footulcer_resized_256_3layer --model pix2pix --gpu_ids 0 --display_id 0 --batch_size 16 --direction BtoA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_256      \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: footulcer_resized_256_3layer  \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 776                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/footulcer_resized_256_3layer/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/footulcer_resized_256_3layer/test_latest\n",
      "processing (0000)-th image... ['./datasets/footulcer_256/test/0020126b06a719c36fed196c2c71f2f0_0.png']\n",
      "processing (0005)-th image... ['./datasets/footulcer_256/test/00d87e85e220404257d75a9c6d574e0b_0.png']\n",
      "processing (0010)-th image... ['./datasets/footulcer_256/test/0272003ec882522e7bec012aac93cc26_2.png']\n",
      "processing (0015)-th image... ['./datasets/footulcer_256/test/030f458bd12ad589f1c2d6ae4cc245e0_0.png']\n",
      "processing (0020)-th image... ['./datasets/footulcer_256/test/03a29338d44c41efd1856034029cb9cb_1.png']\n",
      "processing (0025)-th image... ['./datasets/footulcer_256/test/045069bee69b9a6b457a69c564589895_1.png']\n",
      "processing (0030)-th image... ['./datasets/footulcer_256/test/051d7c68ec44d127707d220a2f8a6c09_0.png']\n",
      "processing (0035)-th image... ['./datasets/footulcer_256/test/06d5643601a23d986ce7a24ca4bb2152_0.png']\n",
      "processing (0040)-th image... ['./datasets/footulcer_256/test/07cd49d4077e7392d36501f291706ddb_1.png']\n",
      "processing (0045)-th image... ['./datasets/footulcer_256/test/095919973cde59672f21c88850a4aa09_0.png']\n",
      "processing (0050)-th image... ['./datasets/footulcer_256/test/0abb9eba5adac0db89364735c88860e4_0.png']\n",
      "processing (0055)-th image... ['./datasets/footulcer_256/test/0b53daf814304dd0d74efb2fa052ef23_0.png']\n",
      "processing (0060)-th image... ['./datasets/footulcer_256/test/0c2ef774c755a57b93845eed12e8029f_0.png']\n",
      "processing (0065)-th image... ['./datasets/footulcer_256/test/0daab7087d28c5b067c891d170e302d3_0.png']\n",
      "processing (0070)-th image... ['./datasets/footulcer_256/test/0e32f889d3f1b3f205184e4a78ea377e_0.png']\n",
      "processing (0075)-th image... ['./datasets/footulcer_256/test/0f42ca66d0a67e868683aab958c70b70_0.png']\n",
      "processing (0080)-th image... ['./datasets/footulcer_256/test/1154874ea6703d6d9fd28b81f9184684_0.png']\n",
      "processing (0085)-th image... ['./datasets/footulcer_256/test/120ad0065480d41edfb123498de494d5_0.png']\n",
      "processing (0090)-th image... ['./datasets/footulcer_256/test/160fcc9963c057d0a4754c8a39f87f1c_0.png']\n",
      "processing (0095)-th image... ['./datasets/footulcer_256/test/167b854fa564c1b27e1950f82cb551e0_0.png']\n",
      "processing (0100)-th image... ['./datasets/footulcer_256/test/18d60d8c820b5487f59dce1237f31f47_1.png']\n",
      "processing (0105)-th image... ['./datasets/footulcer_256/test/19f4e5a4e1330b6cc307fc35c625f197_0.png']\n",
      "processing (0110)-th image... ['./datasets/footulcer_256/test/1ad70e82589acbd9638b6e465366a7fe_0.png']\n",
      "processing (0115)-th image... ['./datasets/footulcer_256/test/1bae2d0ed76c241570479a4490f9c2a5_0.png']\n",
      "processing (0120)-th image... ['./datasets/footulcer_256/test/1c700b5e74caa409d88eb73957906b05_0.png']\n",
      "processing (0125)-th image... ['./datasets/footulcer_256/test/1ca743bfb56654b11fca2b038d1cc682_0.png']\n",
      "processing (0130)-th image... ['./datasets/footulcer_256/test/1d97ce42081182a66ace139dbcd83273_0.png']\n",
      "processing (0135)-th image... ['./datasets/footulcer_256/test/1dbb00d92741863fcc6451afd48daf31_2.png']\n",
      "processing (0140)-th image... ['./datasets/footulcer_256/test/1e172e50acdceb692355ba080e2146cc_1.png']\n",
      "processing (0145)-th image... ['./datasets/footulcer_256/test/1ec8cc951c3bb8fdd532fa847c2f90d9_0.png']\n",
      "processing (0150)-th image... ['./datasets/footulcer_256/test/217189be3ad182f170ec0e1b565a1a2a_0.png']\n",
      "processing (0155)-th image... ['./datasets/footulcer_256/test/229f9949fc3ca248f91e54b11348e517_0.png']\n",
      "processing (0160)-th image... ['./datasets/footulcer_256/test/23789535abbc5f81030070cd45a9cfde_0.png']\n",
      "processing (0165)-th image... ['./datasets/footulcer_256/test/24597141d24289747225c61527d97cb4_0.png']\n",
      "processing (0170)-th image... ['./datasets/footulcer_256/test/24d033a91d4fa6e1a8143d03229886fd_1.png']\n",
      "processing (0175)-th image... ['./datasets/footulcer_256/test/25fbd4751a5aa2f7f5fa5fd4554b70a8_0.png']\n",
      "processing (0180)-th image... ['./datasets/footulcer_256/test/26b0e1c37795cfb1b930a593165149c9_2.png']\n",
      "processing (0185)-th image... ['./datasets/footulcer_256/test/28d3f7cdb7d3b68029a480498dfbc279_0.png']\n",
      "processing (0190)-th image... ['./datasets/footulcer_256/test/29040e0c4889bd33bc4d18426675c6df_3.png']\n",
      "processing (0195)-th image... ['./datasets/footulcer_256/test/2941779e77be521b284a6a9867ea5b56_0.png']\n",
      "processing (0200)-th image... ['./datasets/footulcer_256/test/29a0841f35c311894f34a6e1fac1245b_0.png']\n",
      "processing (0205)-th image... ['./datasets/footulcer_256/test/2a622fc070d8601c5b5ca71fd86f23c1_0.png']\n",
      "processing (0210)-th image... ['./datasets/footulcer_256/test/2b76f204fc28ebbe6be635e099feb791_0.png']\n",
      "processing (0215)-th image... ['./datasets/footulcer_256/test/2c6c04e7a70a7a5f46ccbdef1f176cb8_0.png']\n",
      "processing (0220)-th image... ['./datasets/footulcer_256/test/2e2bc13c6bc904debc7460780a18c886_0.png']\n",
      "processing (0225)-th image... ['./datasets/footulcer_256/test/2f1980e5fb29f92227e4dbc65d223c99_0.png']\n",
      "processing (0230)-th image... ['./datasets/footulcer_256/test/302d6a35b8498b1e57120c3dc277b097_0.png']\n",
      "processing (0235)-th image... ['./datasets/footulcer_256/test/32a49d5a9db69d378d35e3f38259730c_0.png']\n",
      "processing (0240)-th image... ['./datasets/footulcer_256/test/336e44bfe352195e75636a12fa591d0e_0.png']\n",
      "processing (0245)-th image... ['./datasets/footulcer_256/test/34891c5cba00d001b88b5b839a5465a6_0.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0250)-th image... ['./datasets/footulcer_256/test/3582ff9e0a283e437f9fab59dbf14ea4_0.png']\n",
      "processing (0255)-th image... ['./datasets/footulcer_256/test/375d35f02627909d4d85f10ecaa59fb8_0.png']\n",
      "processing (0260)-th image... ['./datasets/footulcer_256/test/3883a34afe518fa69342d9535029f724_0.png']\n",
      "processing (0265)-th image... ['./datasets/footulcer_256/test/3900ade34a1c3ae5071e61635b15c41e_2.png']\n",
      "processing (0270)-th image... ['./datasets/footulcer_256/test/39c3a9ffab05344b8f61460e02b94a1e_0.png']\n",
      "processing (0275)-th image... ['./datasets/footulcer_256/test/3a880cf13e68b254e13e8ee8d737f7d9_0.png']\n",
      "processing (0280)-th image... ['./datasets/footulcer_256/test/3b579e8d9843f801293962cd9dc5cf66_0.png']\n",
      "processing (0285)-th image... ['./datasets/footulcer_256/test/3cc16605bf9d9873debeec4fc90999a0_0.png']\n",
      "processing (0290)-th image... ['./datasets/footulcer_256/test/3d471880a73b751ffb76906fe7191184_0.png']\n",
      "processing (0295)-th image... ['./datasets/footulcer_256/test/3eef4daad81edeb5e367e1c564221d6e_0.png']\n",
      "processing (0300)-th image... ['./datasets/footulcer_256/test/405c6fd83be329ebd1f9add6e58def0c_0.png']\n",
      "processing (0305)-th image... ['./datasets/footulcer_256/test/41ee08289fc69cb37694df30a64a8fd0_0.png']\n",
      "processing (0310)-th image... ['./datasets/footulcer_256/test/42f929bf3341f8a1f04690762786ae49_0.png']\n",
      "processing (0315)-th image... ['./datasets/footulcer_256/test/440078c6936219a7a496ebc67228d5d5_0.png']\n",
      "processing (0320)-th image... ['./datasets/footulcer_256/test/45fb5f2db8202432f78f9862336cdf14_1.png']\n",
      "processing (0325)-th image... ['./datasets/footulcer_256/test/47713ebf42e1606ebb9167b04fc9c937_0.png']\n",
      "processing (0330)-th image... ['./datasets/footulcer_256/test/481213086b8ad2a1c15cfbffec5eea98_0.png']\n",
      "processing (0335)-th image... ['./datasets/footulcer_256/test/492e076e2b1bba7e8773bfce280a4b96_0.png']\n",
      "processing (0340)-th image... ['./datasets/footulcer_256/test/4aba7d3760fc14cf1963e09fe2a591bb_0.png']\n",
      "processing (0345)-th image... ['./datasets/footulcer_256/test/4c188ad2db9f8935d319b2ad6007f3a1_1.png']\n",
      "processing (0350)-th image... ['./datasets/footulcer_256/test/4d0ae09266e45178c65b2c217d2ccd43_0.png']\n",
      "processing (0355)-th image... ['./datasets/footulcer_256/test/4ec3e802c98a70cf04f0f23b0869c1b9_0.png']\n",
      "processing (0360)-th image... ['./datasets/footulcer_256/test/4fff394b855d2d3c86469e487132e55c_0.png']\n",
      "processing (0365)-th image... ['./datasets/footulcer_256/test/51d7a79d227f81fe4b9f114254c180f9_0.png']\n",
      "processing (0370)-th image... ['./datasets/footulcer_256/test/53179510fe106a3768a6789418fc2dcb_0.png']\n",
      "processing (0375)-th image... ['./datasets/footulcer_256/test/5492fe099502ce4c418e8d6686fac07d_2.png']\n",
      "processing (0380)-th image... ['./datasets/footulcer_256/test/5636e9466f61ac6d2f0ad22f626e55c7_0.png']\n",
      "processing (0385)-th image... ['./datasets/footulcer_256/test/56bafc3eafc552f2f0c4568baa31cc83_0.png']\n",
      "processing (0390)-th image... ['./datasets/footulcer_256/test/570a4fd65570badcf863addb1c465e9e_0.png']\n",
      "processing (0395)-th image... ['./datasets/footulcer_256/test/57cb332cf7723fa2b843bc413c44d328_0.png']\n",
      "processing (0400)-th image... ['./datasets/footulcer_256/test/595332a890e442b8f02265bd3c905491_0.png']\n",
      "processing (0405)-th image... ['./datasets/footulcer_256/test/5ba3ae56f8359fe0858e7c377c0f851c_0.png']\n",
      "processing (0410)-th image... ['./datasets/footulcer_256/test/5c6cbbbd21476ddcd9e65d9af64d3ca0_0.png']\n",
      "processing (0415)-th image... ['./datasets/footulcer_256/test/5db20f5af988d46bac432db183d2b2ad_0.png']\n",
      "processing (0420)-th image... ['./datasets/footulcer_256/test/5e5942e7ea78db4e9f0a6bdf8304421b_0.png']\n",
      "processing (0425)-th image... ['./datasets/footulcer_256/test/5ef13b806c0d5da68c9ba3b3d6ba9021_0.png']\n",
      "processing (0430)-th image... ['./datasets/footulcer_256/test/5f48b9f2e78eba692c1de5c8bfb95231_1.png']\n",
      "processing (0435)-th image... ['./datasets/footulcer_256/test/6083797b961a5fc82b84d609faebbb0b_0.png']\n",
      "processing (0440)-th image... ['./datasets/footulcer_256/test/61dfd31019c941d34b7661056af0a125_0.png']\n",
      "processing (0445)-th image... ['./datasets/footulcer_256/test/62a5926e5ed687aa3d4de06ae2ab1ec9_0.png']\n",
      "processing (0450)-th image... ['./datasets/footulcer_256/test/6525910e4e101ca0d804423b635844fc_0.png']\n",
      "processing (0455)-th image... ['./datasets/footulcer_256/test/667a4eea3933cbb713a966e4bfeda385_0.png']\n",
      "processing (0460)-th image... ['./datasets/footulcer_256/test/6823af2c6a6af36150b0c92336beaaf6_0.png']\n",
      "processing (0465)-th image... ['./datasets/footulcer_256/test/69fcf456381561c8dacb1f27223661bf_0.png']\n",
      "processing (0470)-th image... ['./datasets/footulcer_256/test/6ae0729fa22bba50c7b8aff237cf502b_2.png']\n",
      "processing (0475)-th image... ['./datasets/footulcer_256/test/6bcc1caf975bc9701b5610df670cb11f_0.png']\n",
      "processing (0480)-th image... ['./datasets/footulcer_256/test/6c58d20b99df1c5eed126bf5e5686696_0.png']\n",
      "processing (0485)-th image... ['./datasets/footulcer_256/test/6d19f77c47cc9606c7b8a5de35ee432a_1.png']\n",
      "processing (0490)-th image... ['./datasets/footulcer_256/test/6ee9006e981a0fdbd3af39335617fde0_0.png']\n",
      "processing (0495)-th image... ['./datasets/footulcer_256/test/70a364cdbff361ee4a7885ceb1792e5d_0.png']\n",
      "processing (0500)-th image... ['./datasets/footulcer_256/test/721f045a58f30c133f65a2baab901491_0.png']\n",
      "processing (0505)-th image... ['./datasets/footulcer_256/test/73ca74fd4878a32f647035c9d8009b32_0.png']\n",
      "processing (0510)-th image... ['./datasets/footulcer_256/test/74ec1ea5ef38de4666d5031d0b9f4c26_0.png']\n",
      "processing (0515)-th image... ['./datasets/footulcer_256/test/754479624f175e6635dd8bf1a4ee50d7_2.png']\n",
      "processing (0520)-th image... ['./datasets/footulcer_256/test/75bf12b779263ac07eb74fe3baa755bf_3.png']\n",
      "processing (0525)-th image... ['./datasets/footulcer_256/test/769701bddfae87e276736e4a3048fab6_0.png']\n",
      "processing (0530)-th image... ['./datasets/footulcer_256/test/776777c6bbe90594211bfca081d7a365_0.png']\n",
      "processing (0535)-th image... ['./datasets/footulcer_256/test/78c5be8a07ce437c3df17acfc16d567e_0.png']\n",
      "processing (0540)-th image... ['./datasets/footulcer_256/test/7a66638547495b66262715828c8afcd0_0.png']\n",
      "processing (0545)-th image... ['./datasets/footulcer_256/test/7c2b933bc1a51ded68a617a410335e25_1.png']\n",
      "processing (0550)-th image... ['./datasets/footulcer_256/test/7e306a1fb449a2631edc1850facefb82_0.png']\n",
      "processing (0555)-th image... ['./datasets/footulcer_256/test/8044c4db4e766825d0b10fbdc724b297_0.png']\n",
      "processing (0560)-th image... ['./datasets/footulcer_256/test/816b2c8cbdaa48026c25f79587082816_0.png']\n",
      "processing (0565)-th image... ['./datasets/footulcer_256/test/822cbb86d197f0a99536c8f74a4d6ce2_0.png']\n",
      "processing (0570)-th image... ['./datasets/footulcer_256/test/8452f3abc9d20898ef6de9edf95c3963_0.png']\n",
      "processing (0575)-th image... ['./datasets/footulcer_256/test/855067521b74ba3f3affc8ef4e61323f_0.png']\n",
      "processing (0580)-th image... ['./datasets/footulcer_256/test/870b7ea6239da9887f77682c5eb2ad51_0.png']\n",
      "processing (0585)-th image... ['./datasets/footulcer_256/test/87832ce91343423b474ffbcc7c3e7cf5_1.png']\n",
      "processing (0590)-th image... ['./datasets/footulcer_256/test/87f9643ecf1e1dcc23293137f4623a4f_2.png']\n",
      "processing (0595)-th image... ['./datasets/footulcer_256/test/88c8b5c16aecd4a78d2ac5869e6fedd8_0.png']\n",
      "processing (0600)-th image... ['./datasets/footulcer_256/test/8934505da06ec4abfdf59a81a2f831f4_0.png']\n",
      "processing (0605)-th image... ['./datasets/footulcer_256/test/8ac79cecafc3a0a99896e8c36f6bac3e_1.png']\n",
      "processing (0610)-th image... ['./datasets/footulcer_256/test/8c621970fe7ed9d5b563e4097d31d609_0.png']\n",
      "processing (0615)-th image... ['./datasets/footulcer_256/test/8e3c87493da30f92bf75fb7ea9c04786_0.png']\n",
      "processing (0620)-th image... ['./datasets/footulcer_256/test/8f941aa493291b5dc76fec6f6caf898b_0.png']\n",
      "processing (0625)-th image... ['./datasets/footulcer_256/test/917bc443be555adfdf9d0be213118859_0.png']\n",
      "processing (0630)-th image... ['./datasets/footulcer_256/test/92d95396a8ca72d19cbdf1e8366740c8_1.png']\n",
      "processing (0635)-th image... ['./datasets/footulcer_256/test/9448d85caa0130c2119e93c749c363cc_0.png']\n",
      "processing (0640)-th image... ['./datasets/footulcer_256/test/95c84a41ef9a4494f2bab8c4bf6f70dc_0.png']\n",
      "processing (0645)-th image... ['./datasets/footulcer_256/test/97afdc101911ffc33d0fc166cacbaf1b_0.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0650)-th image... ['./datasets/footulcer_256/test/9925404b06cae3cfd54b664dce4e2fd6_0.png']\n",
      "processing (0655)-th image... ['./datasets/footulcer_256/test/9ad1690c57ec153a1980f3038acfe2b4_0.png']\n",
      "processing (0660)-th image... ['./datasets/footulcer_256/test/9c53151d5b81f24e23043907203a0d43_0.png']\n",
      "processing (0665)-th image... ['./datasets/footulcer_256/test/9de367378901a65e663fd696aa3eacf3_0.png']\n",
      "processing (0670)-th image... ['./datasets/footulcer_256/test/a0e95454d864462189e0e6810dbd041d_0.png']\n",
      "processing (0675)-th image... ['./datasets/footulcer_256/test/a1b5a42de7bd6eaedb86479520262687_2.png']\n",
      "processing (0680)-th image... ['./datasets/footulcer_256/test/a23fa00a3aae6b6f3da31c6157aeb670_3.png']\n",
      "processing (0685)-th image... ['./datasets/footulcer_256/test/a35853832ecc9a6b25154b9bd5cf6cf3_0.png']\n",
      "processing (0690)-th image... ['./datasets/footulcer_256/test/a3cb46f154a3e5c032405492a1f6369f_0.png']\n",
      "processing (0695)-th image... ['./datasets/footulcer_256/test/a4d2dc260c443317ba9517905cbf3803_0.png']\n",
      "processing (0700)-th image... ['./datasets/footulcer_256/test/a51bb17b140b4ff5b03da4bc4538a986_0.png']\n",
      "processing (0705)-th image... ['./datasets/footulcer_256/test/a63bb932fece9695681b2e6f1ee0bd05_0.png']\n",
      "processing (0710)-th image... ['./datasets/footulcer_256/test/a77c969895b566672fccaad9ed45037f_0.png']\n",
      "processing (0715)-th image... ['./datasets/footulcer_256/test/a87e022359340a7a46b849c473fe12ef_1.png']\n",
      "processing (0720)-th image... ['./datasets/footulcer_256/test/a9359659e9c8cb5a59429e057979b52f_2.png']\n",
      "processing (0725)-th image... ['./datasets/footulcer_256/test/a9b83f354ab887edc10ddb9ef19cc5d9_0.png']\n",
      "processing (0730)-th image... ['./datasets/footulcer_256/test/aa59d5b6f186b8046603defb1a3afa42_0.png']\n",
      "processing (0735)-th image... ['./datasets/footulcer_256/test/aafb2fc42b97b1d9c4908400fb4e4fff_0.png']\n",
      "processing (0740)-th image... ['./datasets/footulcer_256/test/ab78761c202d21872f1d9b3e3d0c2e5f_1.png']\n",
      "processing (0745)-th image... ['./datasets/footulcer_256/test/ac7e55f1332c4e37bcefe76f1c4e79e4_0.png']\n",
      "processing (0750)-th image... ['./datasets/footulcer_256/test/ade0de677bf619050b77f4efe3ad5878_0.png']\n",
      "processing (0755)-th image... ['./datasets/footulcer_256/test/b08c34d9e82b6af851bbbac6461870ff_0.png']\n",
      "processing (0760)-th image... ['./datasets/footulcer_256/test/b40bb91be02f2b7c20e0046b450e7276_2.png']\n",
      "processing (0765)-th image... ['./datasets/footulcer_256/test/b56853a2c67fa5838a8ae06b4b4d92f3_0.png']\n",
      "processing (0770)-th image... ['./datasets/footulcer_256/test/b6ecf50bfbf4e36d6d9f0c240adf79b7_1.png']\n",
      "processing (0775)-th image... ['./datasets/footulcer_256/test/b9fff21bebb15ba7d8c3f54063e37799_0.png']\n"
     ]
    }
   ],
   "source": [
    "# testing script\n",
    "\n",
    "!python test.py --dataroot ./datasets/footulcer_256 --model pix2pix --name footulcer_resized_256_3layer --gpu_ids -1 --num_test 776 --direction BtoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_256      \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: footulcer_resized_256         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 114                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/footulcer_resized_256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/footulcer_resized_256/0_test\n",
      "processing (0000)-th image... ['./datasets/footulcer_256/test/0010.png']\n",
      "processing (0005)-th image... ['./datasets/footulcer_256/test/0050.png']\n",
      "processing (0010)-th image... ['./datasets/footulcer_256/test/0074.png']\n",
      "processing (0015)-th image... ['./datasets/footulcer_256/test/0122.png']\n",
      "processing (0020)-th image... ['./datasets/footulcer_256/test/0143.png']\n",
      "processing (0025)-th image... ['./datasets/footulcer_256/test/0185.png']\n",
      "processing (0030)-th image... ['./datasets/footulcer_256/test/0228.png']\n",
      "processing (0035)-th image... ['./datasets/footulcer_256/test/0259.png']\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_256      \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: footulcer_resized_256         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 114                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/footulcer_resized_256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/footulcer_resized_256/1_test\n",
      "processing (0000)-th image... ['./datasets/footulcer_256/test/0010.png']\n",
      "processing (0005)-th image... ['./datasets/footulcer_256/test/0050.png']\n",
      "processing (0010)-th image... ['./datasets/footulcer_256/test/0074.png']\n",
      "processing (0015)-th image... ['./datasets/footulcer_256/test/0122.png']\n",
      "processing (0020)-th image... ['./datasets/footulcer_256/test/0143.png']\n",
      "processing (0025)-th image... ['./datasets/footulcer_256/test/0185.png']\n",
      "processing (0030)-th image... ['./datasets/footulcer_256/test/0228.png']\n",
      "processing (0035)-th image... ['./datasets/footulcer_256/test/0259.png']\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_256      \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: footulcer_resized_256         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 114                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/footulcer_resized_256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/footulcer_resized_256/2_test\n",
      "processing (0000)-th image... ['./datasets/footulcer_256/test/0010.png']\n",
      "processing (0005)-th image... ['./datasets/footulcer_256/test/0050.png']\n",
      "processing (0010)-th image... ['./datasets/footulcer_256/test/0074.png']\n",
      "processing (0015)-th image... ['./datasets/footulcer_256/test/0122.png']\n",
      "processing (0020)-th image... ['./datasets/footulcer_256/test/0143.png']\n",
      "processing (0025)-th image... ['./datasets/footulcer_256/test/0185.png']\n",
      "processing (0030)-th image... ['./datasets/footulcer_256/test/0228.png']\n",
      "processing (0035)-th image... ['./datasets/footulcer_256/test/0259.png']\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_256      \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: footulcer_resized_256         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 114                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/footulcer_resized_256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/footulcer_resized_256/3_test\n",
      "processing (0000)-th image... ['./datasets/footulcer_256/test/0010.png']\n",
      "processing (0005)-th image... ['./datasets/footulcer_256/test/0050.png']\n",
      "processing (0010)-th image... ['./datasets/footulcer_256/test/0074.png']\n",
      "processing (0015)-th image... ['./datasets/footulcer_256/test/0122.png']\n",
      "processing (0020)-th image... ['./datasets/footulcer_256/test/0143.png']\n",
      "processing (0025)-th image... ['./datasets/footulcer_256/test/0185.png']\n",
      "processing (0030)-th image... ['./datasets/footulcer_256/test/0228.png']\n",
      "processing (0035)-th image... ['./datasets/footulcer_256/test/0259.png']\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/footulcer_256      \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: footulcer_resized_256         \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 114                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/footulcer_resized_256/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/footulcer_resized_256/4_test\n",
      "processing (0000)-th image... ['./datasets/footulcer_256/test/0010.png']\n",
      "processing (0005)-th image... ['./datasets/footulcer_256/test/0050.png']\n",
      "processing (0010)-th image... ['./datasets/footulcer_256/test/0074.png']\n",
      "processing (0015)-th image... ['./datasets/footulcer_256/test/0122.png']\n",
      "processing (0020)-th image... ['./datasets/footulcer_256/test/0143.png']\n",
      "processing (0025)-th image... ['./datasets/footulcer_256/test/0185.png']\n",
      "processing (0030)-th image... ['./datasets/footulcer_256/test/0228.png']\n",
      "processing (0035)-th image... ['./datasets/footulcer_256/test/0259.png']\n"
     ]
    }
   ],
   "source": [
    "# generate five times \n",
    "\n",
    "# testing script\n",
    "\n",
    "!python test_aug.py --dataroot ./datasets/footulcer_256 --model pix2pix --name footulcer_resized_256 --gpu_ids -1 --num_test 114 --direction AtoB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move files over to same folder \n",
    "rootdir = os.path.join(os.getcwd(), 'results', 'footulcer_resized_256')\n",
    "destdir = os.path.join(os.getcwd(), 'results', 'footulcer_resized_256', 'small_results')\n",
    "\n",
    "# for i in range(5):\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
